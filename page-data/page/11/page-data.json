{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/11","result":{"data":{"allPost":{"edges":[{"node":{"ID":5475,"Title":"How we organize and get things done with SERVICEOWNERS","Description":"<p>Take CODEOWNERS and GitHub teams to the next level. Learn about how GitHub engineering solves the age old problem of who owns what.</p>\n<p>The post <a href=\"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/\">How we organize and get things done with SERVICEOWNERS</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>\n","PublishedAt":"2023-12-19 18:00:08+00:00","OriginURL":"https://github.blog/2023-12-19-how-we-organize-and-get-things-done-with-serviceowners/","SourceName":"GitHub"}},{"node":{"ID":5472,"Title":"How Meta built the infrastructure for Threads","Description":"<p>On July 5, 2023, Meta launched Threads, the newest product in our family of apps, to an unprecedented success that saw it garner over 100 million sign ups in its first five days. A small, nimble team of engineers built Threads over the course of only five months of technical work. While the app’s production [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/\">How Meta built the infrastructure for Threads</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n","PublishedAt":"2023-12-19 17:01:57+00:00","OriginURL":"https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/","SourceName":"Facebook"}},{"node":{"ID":5473,"Title":"AI debugging at Meta with HawkEye","Description":"<p>HawkEye is the powerful toolkit used internally at Meta for monitoring, observability, and debuggability of the end-to-end machine learning (ML) workflow that powers ML-based products. HawkEye supports recommendation and ranking models across several products at Meta. Over the past two years, it has facilitated order of magnitude improvements in the time spent debugging production issues. [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2023/12/19/data-infrastructure/hawkeye-ai-debugging-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2023/12/19/data-infrastructure/hawkeye-ai-debugging-meta/\">AI debugging at Meta with HawkEye</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n","PublishedAt":"2023-12-19 17:00:52+00:00","OriginURL":"https://engineering.fb.com/2023/12/19/data-infrastructure/hawkeye-ai-debugging-meta/","SourceName":"Facebook"}},{"node":{"ID":5477,"Title":"HashiCorp 2023 year in review: Product innovation","Description":"Looking back on a busy year, we’re proud of so many technical accomplishments. We’re even more excited about the future.","PublishedAt":"2023-12-19 17:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/hashicorp-2023-year-in-review-product-innovation","SourceName":"HashiCorp"}},{"node":{"ID":5470,"Title":"Optimizing the Value of AI Solutions for the Public Sector","Description":"<p>Without a doubt, 2023 has shaped up to be generative AI’s breakout year. Less than 12 months after the introduction of generative AI large language models such as ChatGPT and PaLM, image generators like Dall-E, Midjourney, and Stable Diffusion, and code generation tools like OpenAI Codex and GitHub CoPilot, organizations across every industry, including government, [&#8230;]</p>\n<p>The post <a href=\"https://blog.cloudera.com/optimizing-the-value-of-ai-solutions-for-the-public-sector/\">Optimizing the Value of AI Solutions for the Public Sector</a> appeared first on <a href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2023-12-19 13:49:20+00:00","OriginURL":"https://blog.cloudera.com/optimizing-the-value-of-ai-solutions-for-the-public-sector/","SourceName":"Cloudera"}},{"node":{"ID":5469,"Title":"Why do customers choose Elastic for logs?","Description":"","PublishedAt":"2023-12-19 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/why-do-customers-choose-elastic-for-logs","SourceName":"Elastic"}},{"node":{"ID":5471,"Title":"M-21-31 logging compliance: Overcoming the 3 top challenges","Description":"","PublishedAt":"2023-12-19 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/m-21-31-logging-compliance-challenges","SourceName":"Elastic"}},{"node":{"ID":5474,"Title":"The EU AI Act: What you need to know","Description":"","PublishedAt":"2023-12-19 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/eu-ai-act","SourceName":"Elastic"}},{"node":{"ID":5660,"Title":"Kubernetes 1.29: Decoupling taint-manager from node-lifecycle-controller","Description":"<p><strong>Authors:</strong> Yuan Chen (Apple), Andrea Tosatto (Apple)</p>\n<p>This blog discusses a new feature in Kubernetes 1.29 to improve the handling of taint-based pod eviction.</p>\n<h2 id=\"background\">Background</h2>\n<p>In Kubernetes 1.29, an improvement has been introduced to enhance the taint-based pod eviction handling on nodes.\nThis blog discusses the changes made to node-lifecycle-controller\nto separate its responsibilities and improve overall code maintainability.</p>\n<h2 id=\"summary-of-changes\">Summary of changes</h2>\n<p>node-lifecycle-controller previously combined two independent functions:</p>\n<ul>\n<li>Adding a pre-defined set of <code>NoExecute</code> taints to Node based on Node's condition.</li>\n<li>Performing pod eviction on <code>NoExecute</code> taint.</li>\n</ul>\n<p>With the Kubernetes 1.29 release, the taint-based eviction implementation has been\nmoved out of node-lifecycle-controller into a separate and independent component called taint-eviction-controller.\nThis separation aims to disentangle code, enhance code maintainability,\nand facilitate future extensions to either component.</p>\n<p>As part of the change, additional metrics were introduced to help you monitor taint-based pod evictions:</p>\n<ul>\n<li><code>pod_deletion_duration_seconds</code> measures the latency between the time when a taint effect\nhas been activated for the Pod and its deletion via taint-eviction-controller.</li>\n<li><code>pod_deletions_total</code> reports the total number of Pods deleted by taint-eviction-controller since its start.</li>\n</ul>\n<h2 id=\"how-to-use-the-new-feature\">How to use the new feature?</h2>\n<p>A new feature gate, <code>SeparateTaintEvictionController</code>, has been added. The feature is enabled by default as Beta in Kubernetes 1.29.\nPlease refer to the <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gate document</a>.</p>\n<p>When this feature is enabled, users can optionally disable taint-based eviction by setting <code>--controllers=-taint-eviction-controller</code>\nin kube-controller-manager.</p>\n<p>To disable the new feature and use the old taint-manager within node-lifecylecycle-controller , users can set the feature gate <code>SeparateTaintEvictionController=false</code>.</p>\n<h2 id=\"use-cases\">Use cases</h2>\n<p>This new feature will allow cluster administrators to extend and enhance the default\ntaint-eviction-controller and even replace the default taint-eviction-controller with a\ncustom implementation to meet different needs. An example is to better support\nstateful workloads that use PersistentVolume on local disks.</p>\n<h2 id=\"faq\">FAQ</h2>\n<p><strong>Does this feature change the existing behavior of taint-based pod evictions?</strong></p>\n<p>No, the taint-based pod eviction behavior remains unchanged. If the feature gate\n<code>SeparateTaintEvictionController</code> is turned off, the legacy node-lifecycle-controller with taint-manager will continue to be used.</p>\n<p><strong>Will enabling/using this feature result in an increase in the time taken by any operations covered by existing SLIs/SLOs?</strong></p>\n<p>No.</p>\n<p><strong>Will enabling/using this feature result in an increase in resource usage (CPU, RAM, disk, IO, ...)?</strong></p>\n<p>The increase in resource usage by running a separate <code>taint-eviction-controller</code> will be negligible.</p>\n<h2 id=\"learn-more\">Learn more</h2>\n<p>For more details, refer to the <a href=\"http://kep.k8s.io/3902\">KEP</a>.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>As with any Kubernetes feature, multiple community members have contributed, from\nwriting the KEP to implementing the new controller and reviewing the KEP and code. Special thanks to:</p>\n<ul>\n<li>Aldo Culquicondor (@alculquicondor)</li>\n<li>Maciej Szulik (@soltysh)</li>\n<li>Filip Křepinský (@atiratree)</li>\n<li>Han Kang (@logicalhan)</li>\n<li>Wei Huang (@Huang-Wei)</li>\n<li>Sergey Kanzhelevi (@SergeyKanzhelev)</li>\n<li>Ravi Gudimetla (@ravisantoshgudimetla)</li>\n<li>Deep Debroy (@ddebroy)</li>\n</ul>","PublishedAt":"2023-12-19 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/12/19/kubernetes-1-29-taint-eviction-controller/","SourceName":"Kubernetes"}},{"node":{"ID":5661,"Title":"Kubernetes 1.29: PodReadyToStartContainers Condition Moves to Beta","Description":"<p><strong>Authors</strong>: Zefeng Chen (independent), Kevin Hannon (Red Hat)</p>\n<p>With the recent release of Kubernetes 1.29, the <code>PodReadyToStartContainers</code>\n<a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions\">condition</a> is\navailable by default.\nThe kubelet manages the value for that condition throughout a Pod's lifecycle,\nin the status field of a Pod. The kubelet will use the <code>PodReadyToStartContainers</code>\ncondition to accurately surface the initialization state of a Pod,\nfrom the perspective of Pod sandbox creation and network configuration by a container runtime.</p>\n<h2 id=\"what-s-the-motivation-for-this-feature\">What's the motivation for this feature?</h2>\n<p>Cluster administrators did not have a clear and easily accessible way to view the completion of Pod's sandbox creation\nand initialization. As of 1.28, the <code>Initialized</code> condition in Pods tracks the execution of init containers.\nHowever, it has limitations in accurately reflecting the completion of sandbox creation and readiness to start containers for all Pods in a cluster.\nThis distinction is particularly important in multi-tenant clusters where tenants own the Pod specifications, including the set of init containers,\nwhile cluster administrators manage storage plugins, networking plugins, and container runtime handlers.\nTherefore, there is a need for an improved mechanism to provide cluster administrators with a clear and\ncomprehensive view of Pod sandbox creation completion and container readiness.</p>\n<h2 id=\"what-s-the-benefit\">What's the benefit?</h2>\n<ol>\n<li>Improved Visibility: Cluster administrators gain a clearer and more comprehensive view of Pod sandbox\ncreation completion and container readiness.\nThis enhanced visibility allows them to make better-informed decisions and troubleshoot issues more effectively.</li>\n<li>Metric Collection and Monitoring: Monitoring services can leverage the fields associated with\nthe <code>PodReadyToStartContainers</code> condition to report sandbox creation state and latency.\nMetrics can be collected at per-Pod cardinality or aggregated based on various\nproperties of the Pod, such as <code>volumes</code>, <code>runtimeClassName</code>, custom annotations for CNI\nand IPAM plugins or arbitrary labels and annotations, and <code>storageClassName</code> of\nPersistentVolumeClaims.\nThis enables comprehensive monitoring and analysis of Pod readiness across the cluster.</li>\n<li>Enhanced Troubleshooting: With a more accurate representation of Pod sandbox creation and container readiness,\ncluster administrators can quickly identify and address any issues that may arise during the initialization process.\nThis leads to improved troubleshooting capabilities and reduced downtime.</li>\n</ol>\n<h3 id=\"what-s-next\">What’s next?</h3>\n<p>Due to feedback and adoption, the Kubernetes team promoted <code>PodReadyToStartContainersCondition</code> to Beta in 1.29.\nYour comments will help determine if this condition continues forward to get promoted to GA,\nso please submit additional feedback on this feature!</p>\n<h3 id=\"how-can-i-learn-more\">How can I learn more?</h3>\n<p>Please check out the\n<a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/\">documentation</a> for the\n<code>PodReadyToStartContainersCondition</code> to learn more about it and how it fits in relation to\nother Pod conditions.</p>\n<h3 id=\"how-to-get-involved\">How to get involved?</h3>\n<p>This feature is driven by the SIG Node community. Please join us to connect with\nthe community and share your ideas and feedback around the above feature and\nbeyond. We look forward to hearing from you!</p>","PublishedAt":"2023-12-19 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/12/19/pod-ready-to-start-containers-condition-now-in-beta/","SourceName":"Kubernetes"}},{"node":{"ID":5468,"Title":"Australia’s cybersecurity strategy is here and Cloudflare is all in","Description":" In support of the Australian Cyber Security Strategy 2023-2030 (The Strategy), released on November 22, 2023, we want to share how we can help empower Australian organizations and individuals to become more secure ","PublishedAt":"2023-12-18 23:00:21+00:00","OriginURL":"https://blog.cloudflare.com/australia-cybersecurity-strategy-is-here-and-cloudflare-is-all-in","SourceName":"Cloudflare"}},{"node":{"ID":5467,"Title":"AWS Weekly Roundup — AWS Lambda, AWS Amplify, Amazon OpenSearch Service, Amazon Rekognition, and more — December 18, 2023","Description":"My memories of Amazon Web Services (AWS) re:Invent 2023 are still fresh even when I’m currently wrapping up my activities in Jakarta after participating in AWS Community Day Indonesia. It was a great experience, from delivering chalk talks and having thoughtful discussions with AWS service teams, to meeting with AWS Heroes, AWS Community Builders, and […]","PublishedAt":"2023-12-18 17:40:19+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-lambda-aws-amplify-amazon-opensearch-service-amazon-rekognition-and-more-december-18-2023/","SourceName":"AWS"}},{"node":{"ID":5465,"Title":"Integrating Turnstile with the Cloudflare WAF to challenge fetch requests","Description":" By editing or creating a new Turnstile widget with “Pre-Clearance” enabled, Cloudflare customers can now use Turnstile to issue a challenge when a page’s HTML loads, and enforce that all valid responses have a valid Turnstile token ","PublishedAt":"2023-12-18 14:00:17+00:00","OriginURL":"https://blog.cloudflare.com/integrating-turnstile-with-the-cloudflare-waf-to-challenge-fetch-requests","SourceName":"Cloudflare"}},{"node":{"ID":5463,"Title":"How we detect and notify users about leaked Datadog credentials","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/detecting-leaked-credentials/IL-1114_Datadog-detecting-and-notifying-leaked-tokens_231214_v1.png\" width=\"100%\"/>Applications frequently need to provide authentication credentials to gain access to cloud services and other resources. However, these credentials present a security risk because they are notoriously difficult to keep out of code. According to a GitGuardian report, 10 million credentials were publicly committed to GitHub in 2022. Leaked credentials such as these are a major cause of data breaches and account takeovers.Datadog has partnered with GitHub and GitGuardian to help protect our customers&rsquo; accounts from this risk.","PublishedAt":"2023-12-18 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/detecting-leaked-credentials/","SourceName":"Datadog"}},{"node":{"ID":5464,"Title":"The benefits of using a Verified MSP for your Elastic deployments","Description":"","PublishedAt":"2023-12-18 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/verified-msp-elastic-deployments-benefits","SourceName":"Elastic"}},{"node":{"ID":5466,"Title":"Monitor Ray applications and clusters with Datadog","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/monitor-ray-with-datadog/ray-hero.png\" width=\"100%\"/>Ray is an open source compute framework that simplifies the scaling of AI and Python workloads for on-premise and cloud clusters. Ray integrates with popular libraries, data stores, and tools within the machine learning (ML) ecosystem, including Scikit-learn, PyTorch, and TensorFlow. This gives developers the flexibility to scale complex AI applications without making changes to their existing workflows or AI stack.Datadog now integrates with Ray, enabling you to collect key metrics and logs that help you monitor the health of your Ray nodes as your AI applications scale.","PublishedAt":"2023-12-18 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/monitor-ray-with-datadog/","SourceName":"Datadog"}},{"node":{"ID":5662,"Title":"Kubernetes 1.29: New (alpha) Feature, Load Balancer IP Mode for Services","Description":"<p><strong>Author:</strong> <a href=\"https://github.com/RyanAoh\">Aohan Yang</a></p>\n<p>This blog introduces a new alpha feature in Kubernetes 1.29.\nIt provides a configurable approach to define how Service implementations,\nexemplified in this blog by kube-proxy,\nhandle traffic from pods to the Service, within the cluster.</p>\n<h2 id=\"background\">Background</h2>\n<p>In older Kubernetes releases, the kube-proxy would intercept traffic that was destined for the IP\naddress associated with a Service of <code>type: LoadBalancer</code>. This happened whatever mode you used\nfor <code>kube-proxy</code>.\nThe interception implemented the expected behavior (traffic eventually reaching the expected\nendpoints behind the Service). The mechanism to make that work depended on the mode for kube-proxy;\non Linux, kube-proxy in iptables mode would redirecting packets directly to the endpoint; in ipvs mode,\nkube-proxy would configure the load balancer's IP address to one interface on the node.\nThe motivation for implementing that interception was for two reasons:</p>\n<ol>\n<li>\n<p><strong>Traffic path optimization:</strong> Efficiently redirecting pod traffic - when a container in a pod sends an outbound\npacket that is destined for the load balancer's IP address -\ndirectly to the backend service by bypassing the load balancer.</p>\n</li>\n<li>\n<p><strong>Handling load balancer packets:</strong> Some load balancers send packets with the destination IP set to\nthe load balancer's IP address. As a result, these packets need to be routed directly to the correct backend (which\nmight not be local to that node), in order to avoid loops.</p>\n</li>\n</ol>\n<h2 id=\"problems\">Problems</h2>\n<p>However, there are several problems with the aforementioned behavior:</p>\n<ol>\n<li>\n<p><strong><a href=\"https://github.com/kubernetes/kubernetes/issues/79783\">Source IP</a>:</strong>\nSome cloud providers use the load balancer's IP as the source IP when\ntransmitting packets to the node. In the ipvs mode of kube-proxy,\nthere is a problem that health checks from the load balancer never return. This occurs because the reply packets\nwould be forward to the local interface <code>kube-ipvs0</code>(where the load balancer's IP is bound to)\nand be subsequently ignored.</p>\n</li>\n<li>\n<p><strong><a href=\"https://github.com/kubernetes/kubernetes/issues/66607\">Feature loss at load balancer level</a>:</strong>\nCertain cloud providers offer features(such as TLS termination, proxy protocol, etc.) at the\nload balancer level.\nBypassing the load balancer results in the loss of these features when the packet reaches the service\n(leading to protocol errors).</p>\n</li>\n</ol>\n<p>Even with the new alpha behaviour disabled (the default), there is a\n<a href=\"https://github.com/kubernetes/kubernetes/issues/66607#issuecomment-474513060\">workaround</a>\nthat involves setting <code>.status.loadBalancer.ingress.hostname</code> for the Service, in order\nto bypass kube-proxy binding.\nBut this is just a makeshift solution.</p>\n<h2 id=\"solution\">Solution</h2>\n<p>In summary, providing an option for cloud providers to disable the current behavior would be highly beneficial.</p>\n<p>To address this, Kubernetes v1.29 introduces a new (alpha) <code>.status.loadBalancer.ingress.ipMode</code>\nfield for a Service.\nThis field specifies how the load balancer IP behaves and can be specified only when\nthe <code>.status.loadBalancer.ingress.ip</code> field is also specified.</p>\n<p>Two values are possible for <code>.status.loadBalancer.ingress.ipMode</code>: <code>&quot;VIP&quot;</code> and <code>&quot;Proxy&quot;</code>.\nThe default value is &quot;VIP&quot;, meaning that traffic delivered to the node\nwith the destination set to the load balancer's IP and port will be redirected to the backend service by kube-proxy.\nThis preserves the existing behavior of kube-proxy.\nThe &quot;Proxy&quot; value is intended to prevent kube-proxy from binding the load balancer's IP address\nto the node in both ipvs and iptables modes.\nConsequently, traffic is sent directly to the load balancer and then forwarded to the destination node.\nThe destination setting for forwarded packets varies depending on how the cloud provider's load balancer delivers traffic:</p>\n<ul>\n<li>If the traffic is delivered to the node then DNATed to the pod, the destination would be set to the node's IP and node port;</li>\n<li>If the traffic is delivered directly to the pod, the destination would be set to the pod's IP and port.</li>\n</ul>\n<h2 id=\"usage\">Usage</h2>\n<p>Here are the necessary steps to enable this feature:</p>\n<ul>\n<li>Download the <a href=\"https://kubernetes.io/releases/download/\">latest Kubernetes project</a> (version <code>v1.29.0</code> or later).</li>\n<li>Enable the feature gate with the command line flag <code>--feature-gates=LoadBalancerIPMode=true</code>\non kube-proxy, kube-apiserver, and cloud-controller-manager.</li>\n<li>For Services with <code>type: LoadBalancer</code>, set <code>ipMode</code> to the appropriate value.\nThis step is likely handled by your chosen cloud-controller-manager during the <code>EnsureLoadBalancer</code> process.</li>\n</ul>\n<h2 id=\"more-information\">More information</h2>\n<ul>\n<li>Read <a href=\"https://kubernetes.io/docs/concepts/services-networking/service/#load-balancer-ip-mode\">Specifying IPMode of load balancer status</a>.</li>\n<li>Read <a href=\"https://kep.k8s.io/1860\">KEP-1860</a> - <a href=\"https://github.com/kubernetes/enhancements/tree/b103a6b0992439f996be4314caf3bf7b75652366/keps/sig-network/1860-kube-proxy-IP-node-binding#kep-1860-make-kubernetes-aware-of-the-loadbalancer-behaviour\">Make Kubernetes aware of the LoadBalancer behaviour</a> <em>(sic)</em>.</li>\n</ul>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p>Reach us on <a href=\"https://slack.k8s.io/\">Slack</a>: <a href=\"https://kubernetes.slack.com/messages/sig-network\">#sig-network</a>,\nor through the <a href=\"https://groups.google.com/forum/#!forum/kubernetes-sig-network\">mailing list</a>.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>Huge thanks to <a href=\"https://github.com/Sh4d1\">@Sh4d1</a> for the original KEP and initial implementation code.\nI took over midway and completed the work. Similarly, immense gratitude to other contributors\nwho have assisted in the design, implementation, and review of this feature (alphabetical order):</p>\n<ul>\n<li><a href=\"https://github.com/aojea\">@aojea</a></li>\n<li><a href=\"https://github.com/danwinship\">@danwinship</a></li>\n<li><a href=\"https://github.com/sftim\">@sftim</a></li>\n<li><a href=\"https://github.com/tengqm\">@tengqm</a></li>\n<li><a href=\"https://github.com/thockin\">@thockin</a></li>\n<li><a href=\"https://github.com/wojtek-t\">@wojtek-t</a></li>\n</ul>","PublishedAt":"2023-12-18 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/12/18/kubernetes-1-29-feature-loadbalancer-ip-mode-alpha/","SourceName":"Kubernetes"}},{"node":{"ID":5663,"Title":"Kubernetes 1.29: Single Pod Access Mode for PersistentVolumes Graduates to Stable","Description":"<p><strong>Author:</strong> Chris Henzie (Google)</p>\n<p>With the release of Kubernetes v1.29, the <code>ReadWriteOncePod</code> volume access mode\nhas graduated to general availability: it's part of Kubernetes' stable API. In\nthis blog post, I'll take a closer look at this access mode and what it does.</p>\n<h2 id=\"what-is-readwriteoncepod\">What is <code>ReadWriteOncePod</code>?</h2>\n<p><code>ReadWriteOncePod</code> is an access mode for\n<a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistent-volumes\">PersistentVolumes</a> (PVs)\nand <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims\">PersistentVolumeClaims</a> (PVCs)\nintroduced in Kubernetes v1.22. This access mode enables you to restrict volume\naccess to a single pod in the cluster, ensuring that only one pod can write to\nthe volume at a time. This can be particularly useful for stateful workloads\nthat require single-writer access to storage.</p>\n<p>For more context on access modes and how <code>ReadWriteOncePod</code> works read\n<a href=\"https://kubernetes.io/blog/2021/09/13/read-write-once-pod-access-mode-alpha/#what-are-access-modes-and-why-are-they-important\">What are access modes and why are they important?</a>\nin the <em>Introducing Single Pod Access Mode for PersistentVolumes</em> article from 2021.</p>\n<h2 id=\"how-can-i-start-using-readwriteoncepod\">How can I start using <code>ReadWriteOncePod</code>?</h2>\n<p>The <code>ReadWriteOncePod</code> volume access mode is available by default in Kubernetes\nversions v1.27 and beyond. In Kubernetes v1.29 and later, the Kubernetes API\nalways recognizes this access mode.</p>\n<p>Note that <code>ReadWriteOncePod</code> is\n<a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes\">only supported for CSI volumes</a>,\nand before using this feature, you will need to update the following\n<a href=\"https://kubernetes-csi.github.io/docs/sidecar-containers.html\">CSI sidecars</a>\nto these versions or greater:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes-csi/external-provisioner/releases/tag/v3.0.0\">csi-provisioner:v3.0.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-attacher/releases/tag/v3.3.0\">csi-attacher:v3.3.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-resizer/releases/tag/v1.3.0\">csi-resizer:v1.3.0+</a></li>\n</ul>\n<p>To start using <code>ReadWriteOncePod</code>, you need to create a PVC with the\n<code>ReadWriteOncePod</code> access mode:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>single-writer-only<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOncePod<span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># Allows only a single pod to access single-writer-only.</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>1Gi<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>If your storage plugin supports\n<a href=\"https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/\">Dynamic provisioning</a>, then\nnew PersistentVolumes will be created with the <code>ReadWriteOncePod</code> access mode\napplied.</p>\n<p>Read <a href=\"https://kubernetes.io/blog/2021/09/13/read-write-once-pod-access-mode-alpha/#migrating-existing-persistentvolumes\">Migrating existing PersistentVolumes</a>\nfor details on migrating existing volumes to use <code>ReadWriteOncePod</code>.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>Please see the blog posts <a href=\"https://kubernetes.io/blog/2021/09/13/read-write-once-pod-access-mode-alpha\">alpha</a>,\n<a href=\"https://kubernetes.io/blog/2023/04/20/read-write-once-pod-access-mode-beta\">beta</a>, and\n<a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/2485-read-write-once-pod-pv-access-mode/README.md\">KEP-2485</a>\nfor more details on the <code>ReadWriteOncePod</code> access mode and motivations for CSI\nspec changes.</p>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>The <a href=\"https://kubernetes.slack.com/messages/csi\">Kubernetes #csi Slack channel</a>\nand any of the standard\n<a href=\"https://github.com/kubernetes/community/blob/master/sig-storage/README.md#contact\">SIG Storage communication channels</a>\nare great methods to reach out to the SIG Storage and the CSI teams.</p>\n<p>Special thanks to the following people whose thoughtful reviews and feedback helped shape this feature:</p>\n<ul>\n<li>Abdullah Gharaibeh (ahg-g)</li>\n<li>Aldo Culquicondor (alculquicondor)</li>\n<li>Antonio Ojea (aojea)</li>\n<li>David Eads (deads2k)</li>\n<li>Jan Šafránek (jsafrane)</li>\n<li>Joe Betz (jpbetz)</li>\n<li>Kante Yin (kerthcet)</li>\n<li>Michelle Au (msau42)</li>\n<li>Tim Bannister (sftim)</li>\n<li>Xing Yang (xing-yang)</li>\n</ul>\n<p>If you’re interested in getting involved with the design and development of CSI\nor any part of the Kubernetes storage system, join the\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group</a> (SIG).\nWe’re rapidly growing and always welcome new contributors.</p>","PublishedAt":"2023-12-18 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/12/18/read-write-once-pod-access-mode-ga/","SourceName":"Kubernetes"}},{"node":{"ID":5460,"Title":"Decemberfest is here! How we celebrate the holidays at Elastic","Description":"","PublishedAt":"2023-12-15 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/culture-decemberfest-elastic-holiday-celebration","SourceName":"Elastic"}},{"node":{"ID":5461,"Title":"Track service provider outages with IsDown and Datadog","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/track-provider-outages-isdown-datadog/isdown-hero.png\" width=\"100%\"/>When your apps and infrastructure rely on dozens of third-party providers for key functionality, it’s important to closely track their outages. If a service you rely on goes down, you need to move quickly to limit the outage&rsquo;s impact on your users. IsDown provides a detailed status page aggregator and uptime monitoring for all your third-party dependencies. By using IsDown, you can monitor the availability of all these tools and services in one place, and receive instant alerts when one starts experiencing issues.","PublishedAt":"2023-12-15 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/track-provider-outages-isdown-datadog/","SourceName":"Datadog"}},{"node":{"ID":5462,"Title":"Secure your web apps running on Azure App Service with Datadog Application Security Management","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/secure-azure-app-service-apps-with-asm/azure-app-service-hero.png\" width=\"100%\"/>Azure App Service is a platform-as-a-service (PaaS) commonly used to deploy applications and APIs, as well as functions, mobile apps, and more. It provides flexibility and reliability when deploying new applications and infrastructure, but it also introduces new security risks to your system. In particular, reduced visibility into the infrastructure and deployment of your application leads to a greater chance of application vulnerabilities being exploited by an attacker.Datadog Application Security Management (ASM) now supports Azure App Service, enabling you to manage application security risk across even more of your system with continuous, real-time monitoring of vulnerabilities in and threats against your web applications and APIs.","PublishedAt":"2023-12-15 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/secure-azure-app-service-apps-with-asm/","SourceName":"Datadog"}},{"node":{"ID":5664,"Title":"Kubernetes 1.29: CSI Storage Resizing Authenticated and Generally Available in v1.29","Description":"<p><strong>Authors:</strong> Humble Chirammal (Vmware), Louis Koo (deeproute.ai)</p>\n<p>Kubernetes version v1.29 brings generally available support for authentication\nduring CSI (Container Storage Interface) storage resize operations.</p>\n<p>Let's embark on the evolution of this feature, initially introduced in alpha in\nKubernetes v1.25, and unravel the changes accompanying its transition to GA.</p>\n<h2 id=\"authenticated-csi-storage-resizing-unveiled\">Authenticated CSI storage resizing unveiled</h2>\n<p>Kubernetes harnesses the capabilities of CSI to seamlessly integrate with third-party\nstorage systems, empowering your cluster to seamlessly expand storage volumes\nmanaged by the CSI driver. The recent elevation of authentication secret support\nfor resizes from Beta to GA ushers in new horizons, enabling volume expansion in\nscenarios where the underlying storage operation demands credentials for backend\ncluster operations – such as accessing a SAN/NAS fabric. This enhancement addresses\na critical limitation for CSI drivers, allowing volume expansion at the node level,\nespecially in cases necessitating authentication for resize operations.</p>\n<p>The challenges extend beyond node-level expansion. Within the Special Interest\nGroup (SIG) Storage, use cases have surfaced, including scenarios where the\nCSI driver needs to validate the actual size of backend block storage before\ninitiating a node-level filesystem expand operation. This validation prevents\nfalse positive returns from the backend storage cluster during file system expansion.\nAdditionally, for PersistentVolumes representing encrypted block storage (e.g., using LUKS),\na passphrase is mandated to expand the device and grow the filesystem, underscoring\nthe necessity for authenticated resizing.</p>\n<h2 id=\"what-s-new-for-kubernetes-v1-29\">What's new for Kubernetes v1.29</h2>\n<p>With the graduation to GA, the feature remains enabled by default. Support for\nnode-level volume expansion secrets has been seamlessly integrated into the CSI\nexternal-provisioner sidecar controller. To take advantage, ensure your external\nCSI storage provisioner sidecar controller is operating at v3.3.0 or above.</p>\n<h2 id=\"navigating-authenticated-csi-storage-resizing\">Navigating Authenticated CSI Storage Resizing</h2>\n<p>Assuming all requisite components, including the CSI driver, are deployed and operational\non your cluster, and you have a CSI driver supporting resizing, you can initiate a\n<code>NodeExpand</code> operation on a CSI volume. Credentials for the CSI <code>NodeExpand</code> operation\ncan be conveniently provided as a Kubernetes Secret, specifying the Secret via the\nStorageClass. Here's an illustrative manifest for a Secret holding credentials:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#00f;font-weight:bold\">---</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Secret<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-secret<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>default<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">data</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">stringData</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">username</span>:<span style=\"color:#bbb\"> </span>admin<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">password</span>:<span style=\"color:#bbb\"> </span>t0p-Secret<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>And here's an example manifest for a StorageClass referencing those credentials:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#00f;font-weight:bold\">---</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>storage.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>StorageClass<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>csi-blockstorage-sc<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">parameters</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">csi.storage.k8s.io/node-expand-secret-name</span>:<span style=\"color:#bbb\"> </span>test-secret<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">csi.storage.k8s.io/node-expand-secret-namespace</span>:<span style=\"color:#bbb\"> </span>default<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">provisioner</span>:<span style=\"color:#bbb\"> </span>blockstorage.cloudprovider.example<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">reclaimPolicy</span>:<span style=\"color:#bbb\"> </span>Delete<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">volumeBindingMode</span>:<span style=\"color:#bbb\"> </span>Immediate<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">allowVolumeExpansion</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#a2f;font-weight:bold\">true</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Upon successful creation of the PersistentVolumeClaim (PVC), you can verify the\nconfiguration within the .spec.csi field of the PersistentVolume. To confirm,\nexecute <code>kubectl get persistentvolume &lt;pv_name&gt; -o yaml</code>.</p>\n<h2 id=\"engage-with-the-evolution\">Engage with the Evolution!</h2>\n<p>For those enthusiastic about contributing or delving deeper into the technical\nintricacies, the enhancement proposal comprises exhaustive details about the\nfeature's history and implementation. Explore the realms of StorageClass-based\ndynamic provisioning in Kubernetes by referring to the [storage class documentation]\n(<a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#class\">https://kubernetes.io/docs/concepts/storage/persistent-volumes/#class</a>)\nand the overarching <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/\">PersistentVolumes</a> documentation.</p>\n<p>Join the Kubernetes Storage SIG (Special Interest Group) to actively participate\nin elevating this feature. Your insights are invaluable, and we eagerly anticipate\nwelcoming more contributors to shape the future of Kubernetes storage!</p>","PublishedAt":"2023-12-15 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/12/15/csi-node-expand-secret-support-ga/","SourceName":"Kubernetes"}},{"node":{"ID":5665,"Title":"Kubernetes 1.29: VolumeAttributesClass for Volume Modification","Description":"<p><strong>Author</strong>: Sunny Song (Google)</p>\n<p>The v1.29 release of Kubernetes introduced an alpha feature to support modifying a volume\nby changing the <code>volumeAttributesClassName</code> that was specified for a PersistentVolumeClaim (PVC).\nWith the feature enabled, Kubernetes can handle updates of volume attributes other than capacity.\nAllowing volume attributes to be changed without managing it through different\nprovider's APIs directly simplifies the current flow.</p>\n<p>You can read about VolumeAttributesClass usage details in the Kubernetes documentation\nor you can read on to learn about why the Kubernetes project is supporting this feature.</p>\n<h2 id=\"volumeattributesclass\">VolumeAttributesClass</h2>\n<p>The new <code>storage.k8s.io/v1alpha1</code> API group provides two new types:</p>\n<p><strong>VolumeAttributesClass</strong></p>\n<p>Represents a specification of mutable volume attributes defined by the CSI driver.\nThe class can be specified during dynamic provisioning of PersistentVolumeClaims,\nand changed in the PersistentVolumeClaim spec after provisioning.</p>\n<p><strong>ModifyVolumeStatus</strong></p>\n<p>Represents the status object of <code>ControllerModifyVolume</code> operation.</p>\n<p>With this alpha feature enabled, the spec of PersistentVolumeClaim defines VolumeAttributesClassName\nthat is used in the PVC. At volume provisioning, the <code>CreateVolume</code> operation will apply the parameters in the\nVolumeAttributesClass along with the parameters in the StorageClass.</p>\n<p>When there is a change of volumeAttributesClassName in the PVC spec,\nthe external-resizer sidecar will get an informer event. Based on the current state of the configuration,\nthe resizer will trigger a CSI ControllerModifyVolume.\nMore details can be found in <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/3751-volume-attributes-class/README.md\">KEP-3751</a>.</p>\n<h2 id=\"how-to-use-it\">How to use it</h2>\n<p>If you want to test the feature whilst it's alpha, you need to enable the relevant feature gate\nin the <code>kube-controller-manager</code> and the <code>kube-apiserver</code>. Use the <code>--feature-gates</code> command line argument:</p>\n<pre tabindex=\"0\"><code>--feature-gates=&#34;...,VolumeAttributesClass=true&#34;\n</code></pre><p>It also requires that the CSI driver has implemented the ModifyVolume API.</p>\n<h3 id=\"user-flow\">User flow</h3>\n<p>If you would like to see the feature in action and verify it works fine in your cluster, here's what you can try:</p>\n<ol>\n<li>\n<p>Define a StorageClass and VolumeAttributesClass</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>storage.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>StorageClass<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>csi-sc-example<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">provisioner</span>:<span style=\"color:#bbb\"> </span>pd.csi.storage.gke.io<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">parameters</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">disk-type</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;hyperdisk-balanced&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">volumeBindingMode</span>:<span style=\"color:#bbb\"> </span>WaitForFirstConsumer<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>storage.k8s.io/v1alpha1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>VolumeAttributesClass<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>silver<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">driverName</span>:<span style=\"color:#bbb\"> </span>pd.csi.storage.gke.io<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">parameters</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">provisioned-iops</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;3000&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">provisioned-throughput</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;50&#34;</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div></li>\n<li>\n<p>Define and create the PersistentVolumeClaim</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-pv-claim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storageClassName</span>:<span style=\"color:#bbb\"> </span>csi-sc-example<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeAttributesClassName</span>:<span style=\"color:#bbb\"> </span>silver<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOnce<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>64Gi<span style=\"color:#bbb\">\n</span></span></span></code></pre></div></li>\n<li>\n<p>Verify that the PersistentVolumeClaim is now provisioned correctly with:</p>\n<pre tabindex=\"0\"><code>kubectl get pvc\n</code></pre></li>\n<li>\n<p>Create a new VolumeAttributesClass gold:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>storage.k8s.io/v1alpha1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>VolumeAttributesClass<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>gold<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">driverName</span>:<span style=\"color:#bbb\"> </span>pd.csi.storage.gke.io<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">parameters</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">iops</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;4000&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">throughput</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;60&#34;</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div></li>\n<li>\n<p>Update the PVC with the new VolumeAttributesClass and apply:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-pv-claim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storageClassName</span>:<span style=\"color:#bbb\"> </span>csi-sc-example<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeAttributesClassName</span>:<span style=\"color:#bbb\"> </span>gold<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOnce<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>64Gi<span style=\"color:#bbb\">\n</span></span></span></code></pre></div></li>\n<li>\n<p>Verify that PersistentVolumeClaims has the updated VolumeAttributesClass parameters with:</p>\n<pre tabindex=\"0\"><code>kubectl describe pvc &lt;PVC_NAME&gt;\n</code></pre></li>\n</ol>\n<h2 id=\"next-steps\">Next steps</h2>\n<ul>\n<li>See the <a href=\"https://kep.k8s.io/3751\">VolumeAttributesClass KEP</a> for more information on the design</li>\n<li>You can view or comment on the <a href=\"https://github.com/orgs/kubernetes-csi/projects/72\">project board</a> for VolumeAttributesClass</li>\n<li>In order to move this feature towards beta, we need feedback from the community,\nso here's a call to action: add support to the CSI drivers, try out this feature,\nconsider how it can help with problems that your users are having…</li>\n</ul>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p>We always welcome new contributors. So, if you would like to get involved, you can join our <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group</a> (SIG).</p>\n<p>If you would like to share feedback, you can do so on our <a href=\"https://app.slack.com/client/T09NY5SBT/C09QZFCE5\">public Slack channel</a>.</p>\n<p>Special thanks to all the contributors that provided great reviews, shared valuable insight and helped implement this feature (alphabetical order):</p>\n<ul>\n<li>Baofa Fan (calory)</li>\n<li>Ben Swartzlander (bswartz)</li>\n<li>Connor Catlett (ConnorJC3)</li>\n<li>Hemant Kumar (gnufied)</li>\n<li>Jan Šafránek (jsafrane)</li>\n<li>Joe Betz (jpbetz)</li>\n<li>Jordan Liggitt (liggitt)</li>\n<li>Matthew Cary (mattcary)</li>\n<li>Michelle Au (msau42)</li>\n<li>Xing Yang (xing-yang)</li>\n</ul>","PublishedAt":"2023-12-15 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/12/15/kubernetes-1-29-volume-attributes-class/","SourceName":"Kubernetes"}},{"node":{"ID":5459,"Title":"Mitchell reflects as he departs HashiCorp","Description":"After more than 11 years, HashiCorp Co-Founder Mitchell Hashimoto pens a heartfelt goodbye letter to the company he helped create. ","PublishedAt":"2023-12-14 21:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/mitchell-reflects-as-he-departs-hashicorp","SourceName":"HashiCorp"}},{"node":{"ID":5666,"Title":"Kubernetes 1.29: Cloud Provider Integrations Are Now Separate Components","Description":"<p><strong>Authors:</strong> Michael McCune (Red Hat), Andrew Sy Kim (Google)</p>\n<p>For Kubernetes v1.29, you need to use additional components to integrate your\nKubernetes cluster with a cloud infrastructure provider. By default, Kubernetes\nv1.29 components <strong>abort</strong> if you try to specify integration with any cloud provider using\none of the legacy compiled-in cloud provider integrations. If you want to use a legacy\nintegration, you have to opt back in - and a future release will remove even that option.</p>\n<p>In 2018, the <a href=\"https://kubernetes.io/blog/2019/04/17/the-future-of-cloud-providers-in-kubernetes/\">Kubernetes community agreed to form the Cloud Provider Special\nInterest Group (SIG)</a>, with a mission to externalize all cloud provider\nintegrations and remove all the existing in-tree cloud provider integrations.\nIn January 2019, the Kubernetes community approved the initial draft of\n<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-cloud-provider/2395-removing-in-tree-cloud-providers\">KEP-2395: Removing In-Tree Cloud Provider Code</a>. This KEP defines a\nprocess by which we can remove cloud provider specific code from the core\nKubernetes source tree. From the KEP:</p>\n<blockquote>\n<p>Motiviation [sic] behind this effort is to allow cloud providers to develop and\nmake releases independent from the core Kubernetes release cycle. The\nde-coupling of cloud provider code allows for separation of concern between\n&quot;Kubernetes core&quot; and the cloud providers within the ecosystem. In addition,\nthis ensures all cloud providers in the ecosystem are integrating with\nKubernetes in a consistent and extendable way.</p>\n</blockquote>\n<p>After many years of development and collaboration across many contributors,\nthe default behavior for legacy cloud provider integrations is changing.\nThis means that users will need to confirm their Kubernetes configurations,\nand in some cases run external cloud controller managers. These changes are\ntaking effect in Kubernetes version 1.29; read on to learn if you are affected\nand what changes you will need to make.</p>\n<p>These updated default settings affect a large proportion of Kubernetes users,\nand <strong>will require changes</strong> for users who were previously using the in-tree\nprovider integrations. The legacy integrations offered compatibility with\nAzure, AWS, GCE, OpenStack, and vSphere; however for AWS and OpenStack the\ncompiled-in integrations were removed in Kubernetes versions 1.26 and 1.27,\nrespectively.</p>\n<h2 id=\"what-has-changed\">What has changed?</h2>\n<p>At the most basic level, two <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gates</a> are changing their default\nvalue from false to true. Those feature gates, <code>DisableCloudProviders</code> and\n<code>DisableKubeletCloudCredentialProviders</code>, control the way that the\n<a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/\">kube-apiserver</a>, <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/\">kube-controller-manager</a>, and <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/\">kubelet</a>\ninvoke the cloud provider related code that is included in those components.\nWhen these feature gates are true (the default), the only recognized value for\nthe <code>--cloud-provider</code> command line argument is <code>external</code>.</p>\n<p>Let's see what the <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">official Kubernetes documentation</a> says about these\nfeature gates:</p>\n<blockquote>\n<p><code>DisableCloudProviders</code>: Disables any functionality in <code>kube-apiserver</code>,\n<code>kube-controller-manager</code> and <code>kubelet</code> related to the <code>--cloud-provider</code>\ncomponent flag.</p>\n</blockquote>\n<blockquote>\n<p><code>DisableKubeletCloudCredentialProviders</code>: Disable the in-tree functionality\nin kubelet to authenticate to a cloud provider container registry for image\npull credentials.</p>\n</blockquote>\n<p>The next stage beyond beta will be full removal; for that release onwards, you\nwon't be able to override those feature gates back to false.</p>\n<h2 id=\"what-do-you-need-to-do\">What do you need to do?</h2>\n<p>If you are upgrading from Kubernetes 1.28+ and are not on Azure, GCE, or\nvSphere then there are no changes you will need to make. If\nyou <strong>are</strong> on Azure, GCE, or vSphere, or you are upgrading from a version\nolder than 1.28, then read on.</p>\n<p>Historically, Kubernetes has included code for a set of cloud providers that\nincluded AWS, Azure, GCE, OpenStack, and vSphere. Since the inception of\n<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-cloud-provider/2395-removing-in-tree-cloud-providers\">KEP-2395</a> the community has been moving towards removal of that\ncloud provider code. The OpenStack provider code was removed in version 1.26,\nand the AWS provider code was removed in version 1.27. This means that users\nwho are upgrading from one of the affected cloud providers and versions will\nneed to modify their deployments.</p>\n<h3 id=\"upgrading-on-azure-gce-or-vsphere\">Upgrading on Azure, GCE, or vSphere</h3>\n<p>There are two options for upgrading in this configuration: migrate to external\ncloud controller managers, or continue using the in-tree provider code.\nAlthough migrating to external cloud controller managers is recommended,\nthere are scenarios where continuing with the current behavior is desired.\nPlease choose the best option for your needs.</p>\n<h4 id=\"migrate-to-external-cloud-controller-managers\">Migrate to external cloud controller managers</h4>\n<p>Migrating to use external cloud controller managers is the recommended upgrade\npath, when possible in your situation. To do this you will need to\nenable the <code>--cloud-provider=external</code> command line flag for the\n<code>kube-apiserver</code>, <code>kube-controller-manager</code>, and <code>kubelet</code> components. In\naddition you will need to deploy a cloud controller manager for your provider.</p>\n<p>Installing and running cloud controller managers is a larger topic than this\npost can address; if you would like more information on this process please\nread the documentation for <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/\">Cloud Controller Manager Administration</a>\nand <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/controller-manager-leader-migration/\">Migrate Replicated Control Plane To Use Cloud Controller Manager</a>.\nSee <a href=\"#cloud-provider-integrations\">below</a> for links to specific cloud provider\nimplementations.</p>\n<h4 id=\"continue-using-in-tree-provider-code\">Continue using in-tree provider code</h4>\n<p>If you wish to continue using Kubernetes with the in-tree cloud provider code,\nyou will need to modify the command line parameters for <code>kube-apiserver</code>,\n<code>kube-controller-manager</code>, and <code>kubelet</code> to disable the feature gates for\n<code>DisableCloudProviders</code> and <code>DisableKubeletCloudCredentialProviders</code>. To do\nthis, add the following command line flag to the arguments for the previously\nlisted commands:</p>\n<pre tabindex=\"0\"><code>--feature-gates=DisableCloudProviders=false,DisableKubeletCloudCredentialProviders=false\n</code></pre><p><em>Please note that if you have other feature gate modifications on the command\nline, they will need to include these 2 feature gates.</em></p>\n<p><strong>Note</strong>: These feature gates will be locked to <code>true</code> in an upcoming\nrelease. Setting these feature gates to <code>false</code> should be used as a last\nresort. It is highly recommended to migrate to an external cloud controller\nmanager as the in-tree providers are planned for removal as early as Kubernetes\nversion 1.31.</p>\n<h3 id=\"upgrading-on-other-providers\">Upgrading on other providers</h3>\n<p>For providers other than Azure, GCE, or vSphere, good news, the external cloud\ncontroller manager should already be in use. You can confirm this by inspecting\nthe <code>--cloud-provider</code> flag for the kubelets in your cluster, they will have\nthe value <code>external</code> if using external providers. The code for AWS and OpenStack\nproviders was removed from Kubernetes before version 1.27 was released.\nOther providers beyond the AWS, Azure, GCE, OpenStack, and vSphere were never\nincluded in Kubernetes and as such they began their life as external cloud\ncontroller managers.</p>\n<h3 id=\"upgrading-from-older-kubernetes-versions\">Upgrading from older Kubernetes versions</h3>\n<p>If you are upgrading from a Kubernetes release older than 1.26, and you are on\nAWS, Azure, GCE, OpenStack, or vSphere then you will need to enable the\n<code>--cloud-provider=external</code> flag, and follow the advice for installing and\nrunning a cloud controller manager for your provider.</p>\n<p>Please read the documentation for\n<a href=\"https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/\">Cloud Controller Manager Administration</a> and\n<a href=\"https://kubernetes.io/docs/tasks/administer-cluster/controller-manager-leader-migration/\">Migrate Replicated Control Plane To Use Cloud Controller Manager</a>. See\nbelow for links to specific cloud provider implementations.</p>\n<h2 id=\"where-to-find-a-cloud-controller-manager\">Where to find a cloud controller manager?</h2>\n<p>At its core, this announcement is about the cloud provider integrations that\nwere previously included in Kubernetes. As these components move out of the\ncore Kubernetes code and into their own repositories, it is important to note\na few things:</p>\n<p>First, SIG Cloud Provider offers a reference framework for developers who\nwish to create cloud controller managers for any provider. See the\n<a href=\"https://github.com/kubernetes/cloud-provider\">cloud-provider repository</a> for more information about how\nthese controllers work and how to get started creating your own.</p>\n<p>Second, there are many cloud controller managers available for Kubernetes.\nThis post is addressing the provider integrations that have been historically\nincluded with Kubernetes but are now in the process of being removed. If you\nneed a cloud controller manager for your provider and do not see it listed here,\nplease reach out to the cloud provider you are integrating with or the\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-cloud-provider\">Kubernetes SIG Cloud Provider community</a> for help and advice. It is\nworth noting that while most cloud controller managers are open source today,\nthis may not always be the case. Users should always contact their cloud\nprovider to learn if there are preferred solutions to utilize on their\ninfrastructure.</p>\n<h3 id=\"cloud-provider-integrations\">Cloud provider integrations provided by the Kubernetes project</h3>\n<ul>\n<li>AWS - <a href=\"https://github.com/kubernetes/cloud-provider-aws\">https://github.com/kubernetes/cloud-provider-aws</a></li>\n<li>Azure - <a href=\"https://github.com/kubernetes-sigs/cloud-provider-azure\">https://github.com/kubernetes-sigs/cloud-provider-azure</a></li>\n<li>GCE - <a href=\"https://github.com/kubernetes/cloud-provider-gcp\">https://github.com/kubernetes/cloud-provider-gcp</a></li>\n<li>OpenStack - <a href=\"https://github.com/kubernetes/cloud-provider-openstack\">https://github.com/kubernetes/cloud-provider-openstack</a></li>\n<li>vSphere - <a href=\"https://github.com/kubernetes/cloud-provider-vsphere\">https://github.com/kubernetes/cloud-provider-vsphere</a></li>\n</ul>\n<p>If you are looking for an automated approach to installing cloud controller\nmanagers in your clusters, the <a href=\"https://github.com/kubernetes/kops\">kOps</a> project provides a convenient\nsolution for managing production-ready clusters.</p>\n<h2 id=\"want-to-learn-more\">Want to learn more?</h2>\n<p>Cloud providers and cloud controller managers serve a core function in\nKubernetes. Cloud providers are often the substrate upon which Kubernetes is\noperated, and the cloud controller managers supply the essential lifeline\nbetween Kubernetes clusters and their physical infrastructure.</p>\n<p>This post covers one aspect of how the Kubernetes community interacts with\nthe world of cloud infrastructure providers. If you are curious about this\ntopic and want to learn more, the Cloud Provider Special Interest Group (SIG)\nis the place to go. SIG Cloud Provider hosts bi-weekly meetings to discuss all\nmanner of topics related to cloud providers and cloud controller managers in\nKubernetes.</p>\n<h3 id=\"sig-cloud-provider\">SIG Cloud Provider</h3>\n<ul>\n<li>Regular SIG Meeting: <a href=\"https://zoom.us/j/508079177?pwd=ZmEvMksxdTFTc0N1eXFLRm91QUlyUT09\">Wednesdays at 9:00 PT (Pacific Time)</a> (biweekly). <a href=\"http://www.thetimezoneconverter.com/?t=9:00&amp;tz=PT%20%28Pacific%20Time%29\">Convert to your timezone</a>.</li>\n<li><a href=\"https://kubernetes.slack.com\">Kubernetes slack</a> channel <code>#sig-cloud-provider</code></li>\n<li><a href=\"https://github.com/kubernetes/community/tree/master/sig-cloud-provider\">SIG Community page</a></li>\n</ul>","PublishedAt":"2023-12-14 17:30:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/12/14/cloud-provider-integration-changes/","SourceName":"Kubernetes"}},{"node":{"ID":5458,"Title":"Terraform Cloud adds on-demand policy evaluation","Description":"On-demand policy evaluation improves visibility and control by letting users evaluate the effects of policy changes in Terraform Cloud before they are enforced.","PublishedAt":"2023-12-14 16:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/terraform-cloud-adds-on-demand-policy-evaluation","SourceName":"HashiCorp"}},{"node":{"ID":5457,"Title":"Using DNS to estimate the worldwide state of IPv6 adoption","Description":" In the last decade, IPv6 adoption on the client side went from under 1% to somewhere in the high 30 to low 40 percent, depending on who’s reporting, but there’s also the other end of the equation: the server side ","PublishedAt":"2023-12-14 15:05:52+00:00","OriginURL":"https://blog.cloudflare.com/ipv6-from-dns-pov","SourceName":"Cloudflare"}},{"node":{"ID":5454,"Title":"GitHub Availability Report: November 2023","Description":"<p>In November, we experienced one incident that resulted in degraded performance across GitHub services. </p>\n<p>The post <a href=\"https://github.blog/2023-12-13-github-availability-report-november-2023/\">GitHub Availability Report: November 2023</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>\n","PublishedAt":"2023-12-13 20:48:54+00:00","OriginURL":"https://github.blog/2023-12-13-github-availability-report-november-2023/","SourceName":"GitHub"}},{"node":{"ID":5377,"Title":"Cloudera Customer Story","Description":"<p>Providing LGIM with a Scalable Technology Platform for Data Innovation</p>\n<p>The post <a href=\"https://blog.cloudera.com/cloudera-customer-story/\">Cloudera Customer Story</a> appeared first on <a href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2023-12-13 20:32:51+00:00","OriginURL":"https://blog.cloudera.com/cloudera-customer-story/","SourceName":"Cloudera"}},{"node":{"ID":5378,"Title":"#Volunteer Spotlight: Remus Lim","Description":"<p>A 3-day trek in Taiga, Mongolia in support of Children’s Cancer Foundation</p>\n<p>The post <a href=\"https://blog.cloudera.com/volunteer-spotlight-remus-lim/\">#Volunteer Spotlight: Remus Lim</a> appeared first on <a href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2023-12-13 19:34:21+00:00","OriginURL":"https://blog.cloudera.com/volunteer-spotlight-remus-lim/","SourceName":"Cloudera"}}]}},"pageContext":{"limit":30,"skip":300,"numPages":193,"currentPage":11}},"staticQueryHashes":["3649515864"]}