{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/174","result":{"data":{"allPost":{"edges":[{"node":{"ID":771,"Title":"Jellyfish: Cost-Effective Data Tiering for Uber’s Largest Storage System","Description":"<h1><span style=\"font-weight: 400;\">Problem</span></h1>\n<p><span style=\"font-weight: 400;\">Uber deploys a few storage technologies to store business data based on their application model. One such technology is called </span><a href=\"https://eng.uber.com/schemaless-part-one-mysql-datastore/\"><span style=\"font-weight: 400;\">Schemaless</span></a><span style=\"font-weight: 400;\">, which enables the modeling of related entries in one single row of multiple columns, as well as </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/jellyfish-cost-effective-data-tiering/\">Jellyfish: Cost-Effective Data Tiering for Uber’s Largest Storage System</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-09-09 16:00:19+00:00","OriginURL":"https://eng.uber.com/jellyfish-cost-effective-data-tiering/","SourceName":"Uber"}},{"node":{"ID":398,"Title":"Red Means Stop. Green Means Go: A Look into Quality Assessment in Instacart’s Knowledge Graph","Description":"","PublishedAt":"2021-09-08 19:35:43+00:00","OriginURL":"https://tech.instacart.com/red-means-stop-green-means-go-a-look-into-quality-assessment-in-instacarts-knowledge-graph-9ceeb3f1be24?source=rss----587883b5d2ee---4","SourceName":"Instacart"}},{"node":{"ID":85,"Title":"3 Guidelines to Reduce Implementation Flaws","Description":"","PublishedAt":"2021-09-03 17:06:05+00:00","OriginURL":"https://medium.com/groupon-eng/3-guidelines-to-reduce-implementation-flaws-958511e2a82f?source=rss----5c13a88f9872---4","SourceName":"Groupon"}},{"node":{"ID":1256,"Title":"Blog: Alpha in Kubernetes v1.22: API Server Tracing","Description":"<p><strong>Authors:</strong> David Ashpole (Google)</p>\n<p>In distributed systems, it can be hard to figure out where problems are. You grep through one component's logs just to discover that the source of your problem is in another component. You search there only to discover that you need to enable debug logs to figure out what really went wrong... And it goes on. The more complex the path your request takes, the harder it is to answer questions about where it went. I've personally spent many hours doing this dance with a variety of Kubernetes components. Distributed tracing is a tool which is designed to help in these situations, and the Kubernetes API Server is, perhaps, the most important Kubernetes component to be able to debug. At Kubernetes' Sig Instrumentation, our mission is to make it easier to understand what's going on in your cluster, and we are happy to announce that distributed tracing in the Kubernetes API Server reached alpha in 1.22.</p>\n<h2 id=\"what-is-tracing\">What is Tracing?</h2>\n<p>Distributed tracing links together a bunch of super-detailed information from multiple different sources, and structures that telemetry into a single tree for that request. Unlike logging, which limits the quantity of data ingested by using log levels, tracing collects all of the details and uses sampling to collect only a small percentage of requests. This means that once you have a trace which demonstrates an issue, you should have all the information you need to root-cause the problem--no grepping for object UID required! My favorite aspect, though, is how useful the visualizations of traces are. Even if you don't understand the inner workings of the API Server, or don't have a clue what an etcd &quot;Transaction&quot; is, I'd wager you (yes, you!) could tell me roughly what the order of events was, and which components were involved in the request. If some step takes a long time, it is easy to tell where the problem is.</p>\n<h2 id=\"why-opentelemetry\">Why OpenTelemetry?</h2>\n<p>It's important that Kubernetes works well for everyone, regardless of who manages your infrastructure, or which vendors you choose to integrate with. That is particularly true for Kubernetes' integrations with telemetry solutions. OpenTelemetry, being a CNCF project, shares these core values, and is creating exactly what we need in Kubernetes: A set of open standards for Tracing client library APIs and a standard trace format. By using OpenTelemetry, we can ensure users have the freedom to choose their backend, and ensure vendors have a level playing field. The timing couldn't be better: the OpenTelemetry golang API and SDK are very close to their 1.0 release, and will soon offer backwards-compatibility for these open standards.</p>\n<h2 id=\"why-instrument-the-api-server\">Why instrument the API Server?</h2>\n<p>The Kubernetes API Server is a great candidate for tracing for a few reasons:</p>\n<ul>\n<li>It follows the standard &quot;RPC&quot; model (serve a request by making requests to downstream components), which makes it easy to instrument.</li>\n<li>Users are latency-sensitive: If a request takes more than 10 seconds to complete, many clients will time-out.</li>\n<li>It has a complex service topology: A single request could require consulting a dozen webhooks, or involve multiple requests to etcd.</li>\n</ul>\n<h2 id=\"trying-out-apiserver-tracing-with-a-webhook\">Trying out APIServer Tracing with a webhook</h2>\n<h3 id=\"enabling-api-server-tracing\">Enabling API Server Tracing</h3>\n<ol>\n<li>\n<p>Enable the APIServerTracing <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature-gate</a>.</p>\n</li>\n<li>\n<p>Set our configuration for tracing by pointing the <code>--tracing-config-file</code> flag on the kube-apiserver at our config file, which contains:</p>\n</li>\n</ol>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>apiserver.config.k8s.io/v1alpha1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>TracingConfiguration<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#080;font-style:italic\"># 1% sampling rate</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">samplingRatePerMillion</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">10000</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><h3 id=\"enabling-etcd-tracing\">Enabling Etcd Tracing</h3>\n<p>Add <code>--experimental-enable-distributed-tracing</code>, <code>--experimental-distributed-tracing-address=0.0.0.0:4317</code>, <code>--experimental-distributed-tracing-service-name=etcd</code> flags to etcd to enable tracing. Note that this traces every request, so it will probably generate a lot of traces if you enable it. Required etcd version is <a href=\"https://etcd.io/docs/v3.5/op-guide/monitoring/#distributed-tracing\">v3.5+</a>.</p>\n<h3 id=\"example-trace-list-nodes\">Example Trace: List Nodes</h3>\n<p>I could've used any trace backend, but decided to use Jaeger, since it is one of the most popular open-source tracing projects. I deployed <a href=\"https://hub.docker.com/r/jaegertracing/all-in-one\">the Jaeger All-in-one container</a> in my cluster, deployed <a href=\"https://github.com/open-telemetry/opentelemetry-collector\">the OpenTelemetry collector</a> on my control-plane node (<a href=\"https://github.com/dashpole/dashpole_demos/tree/master/otel/controlplane\">example</a>), and captured traces like this one:</p>\n<p><img src=\"https://kubernetes.io/images/blog/2021-09-03-api-server-tracing/example-trace-1.png\" alt=\"Jaeger screenshot showing API server and etcd trace\" title=\"Jaeger screenshot showing API server and etcd trace\"></p>\n<p>The teal lines are from the API Server, and includes it serving a request to <code>/api/v1/nodes</code>, and issuing a grpc <code>Range</code> RPC to ETCD. The yellow-ish line is from ETCD handling the <code>Range</code> RPC.</p>\n<h3 id=\"example-trace-create-pod-with-mutating-webhook\">Example Trace: Create Pod with Mutating Webhook</h3>\n<p>I instrumented the <a href=\"https://github.com/kubernetes-sigs/controller-runtime/tree/master/examples/builtins\">example webhook</a> with OpenTelemetry (I had to <a href=\"https://github.com/dashpole/controller-runtime/commit/85fdda7ba03dd2c22ef62c1a3dbdf5aa651f90da\">patch</a> controller-runtime, but it makes a neat demo), and routed traces to Jaeger as well. I collected traces like this one:</p>\n<p><img src=\"https://kubernetes.io/images/blog/2021-09-03-api-server-tracing/example-trace-2.png\" alt=\"Jaeger screenshot showing API server, admission webhook, and etcd trace\" title=\"Jaeger screenshot showing API server, admission webhook, and etcd trace\"></p>\n<p>Compared with the previous trace, there are two new spans: A teal span from the API Server making a request to the admission webhook, and a brown span from the admission webhook serving the request. Even if you didn't instrument your webhook, you would still get the span from the API Server making the request to the webhook.</p>\n<h2 id=\"get-involved\">Get involved!</h2>\n<p>As this is our first attempt at adding distributed tracing to a Kubernetes component, there is probably a lot we can improve! If my struggles resonated with you, or if you just want to try out the latest Kubernetes has to offer, please give the feature a try and open issues with any problem you encountered and ways you think the feature could be improved.</p>\n<p>This is just the very beginning of what we can do with distributed tracing in Kubernetes. If there are other components you think would benefit from distributed tracing, or want to help bring API Server Tracing to GA, join sig-instrumentation at our <a href=\"https://github.com/kubernetes/community/tree/master/sig-instrumentation#instrumentation-special-interest-group\">regular meetings</a> and get involved!</p>","PublishedAt":"2021-09-03 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/09/03/api-server-tracing/","SourceName":"Kubernetes"}},{"node":{"ID":772,"Title":"Streaming Real-Time Analytics with Redis, AWS Fargate, and Dash Framework","Description":"<h1><span style=\"font-weight: 400;\">Introduction</span></h1>\n<p><span style=\"font-weight: 400;\">Uber’s GSS (Global Scaled Solutions) team runs scaled programs for diverse products and businesses, including but not limited to Eats, Rides, and Freight. The team transforms Uber’s ideas into agile, global solutions by designing and implementing scalable solutions. One </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/streaming-real-time-analytics/\">Streaming Real-Time Analytics with Redis, AWS Fargate, and Dash Framework</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-09-02 16:00:50+00:00","OriginURL":"https://eng.uber.com/streaming-real-time-analytics/","SourceName":"Uber"}},{"node":{"ID":773,"Title":"Enabling Seamless Kafka Async Queuing with Consumer Proxy","Description":"<p><span style=\"font-weight: 400;\">Uber has one of the largest deployments of Apache Kafka in the world, processing trillions of messages and multiple petabytes of data per day. As Figure 1 shows, today we position Apache Kafka as a cornerstone of our technology stack. </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/kafka-async-queuing-with-consumer-proxy/\">Enabling Seamless Kafka Async Queuing with Consumer Proxy</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-08-31 16:00:32+00:00","OriginURL":"https://eng.uber.com/kafka-async-queuing-with-consumer-proxy/","SourceName":"Uber"}},{"node":{"ID":476,"Title":"Instamojo on data stack philosophy","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/08/Ask-An-Expert@2x-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>As the Head of Analytics at Instamojo, an e-commerce enabler that provides e-commerce solutions to over 1.5 million micro- to medium-sized businesses in India, Ankur Sharma is in charge of all things data—data engineering, strategy, and core data analytics. In this interview, he spoke to us about what’s in Instamojo’s data stack and the philosophy</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/ask-an-expert-ankur-sharma-instamojo-data-stack/\">Instamojo on data stack philosophy</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-08-31 10:15:38+00:00","OriginURL":"https://mixpanel.com/blog/ask-an-expert-ankur-sharma-instamojo-data-stack/","SourceName":"Mixpanel"}},{"node":{"ID":1257,"Title":"Blog: Kubernetes 1.22: A New Design for Volume Populators","Description":"<p><strong>Authors:</strong>\nBen Swartzlander (NetApp)</p>\n<p>Kubernetes v1.22, released earlier this month, introduced a redesigned approach for volume\npopulators. Originally implemented\nin v1.18, the API suffered from backwards compatibility issues. Kubernetes v1.22 includes a new API\nfield called <code>dataSourceRef</code> that fixes these problems.</p>\n<h2 id=\"data-sources\">Data sources</h2>\n<p>Earlier Kubernetes releases already added a <code>dataSource</code> field into the\n<a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims\">PersistentVolumeClaim</a> API,\nused for cloning volumes and creating volumes from snapshots. You could use the <code>dataSource</code> field when\ncreating a new PVC, referencing either an existing PVC or a VolumeSnapshot in the same namespace.\nThat also modified the normal provisioning process so that instead of yielding an empty volume, the\nnew PVC contained the same data as either the cloned PVC or the cloned VolumeSnapshot.</p>\n<p>Volume populators embrace the same design idea, but extend it to any type of object, as long\nas there exists a <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\">custom resource</a>\nto define the data source, and a populator controller to implement the logic. Initially,\nthe <code>dataSource</code> field was directly extended to allow arbitrary objects, if the <code>AnyVolumeDataSource</code>\nfeature gate was enabled on a cluster. That change unfortunately caused backwards compatibility\nproblems, and so the new <code>dataSourceRef</code> field was born.</p>\n<p>In v1.22 if the <code>AnyVolumeDataSource</code> feature gate is enabled, the <code>dataSourceRef</code> field is\nadded, which behaves similarly to the <code>dataSource</code> field except that it allows arbitrary\nobjects to be specified. The API server ensures that the two fields always have the same\ncontents, and neither of them are mutable. The differences is that at creation time\n<code>dataSource</code> allows only PVCs or VolumeSnapshots, and ignores all other values, while\n<code>dataSourceRef</code> allows most types of objects, and in the few cases it doesn't allow an\nobject (core objects other than PVCs) a validation error occurs.</p>\n<p>When this API change graduates to stable, we would deprecate using <code>dataSource</code> and recommend\nusing <code>dataSourceRef</code> field for all use cases.\nIn the v1.22 release, <code>dataSourceRef</code> is available (as an alpha feature) specifically for cases\nwhere you want to use for custom volume populators.</p>\n<h2 id=\"using-populators\">Using populators</h2>\n<p>Every volume populator must have one or more CRDs that it supports. Administrators may\ninstall the CRD and the populator controller and then PVCs with a <code>dataSourceRef</code> specifies\na CR of the type that the populator supports will be handled by the populator controller\ninstead of the CSI driver directly.</p>\n<p>Underneath the covers, the CSI driver is still invoked to create an empty volume, which\nthe populator controller fills with the appropriate data. The PVC doesn't bind to the PV\nuntil it's fully populated, so it's safe to define a whole application manifest including\npod and PVC specs and the pods won't begin running until everything is ready, just as if\nthe PVC was a clone of another PVC or VolumeSnapshot.</p>\n<h2 id=\"how-it-works\">How it works</h2>\n<p>PVCs with data sources are still noticed by the external-provisioner sidecar for the\nrelated storage class (assuming a CSI provisioner is used), but because the sidecar\ndoesn't understand the data source kind, it doesn't do anything. The populator controller\nis also watching for PVCs with data sources of a kind that it understands and when it\nsees one, it creates a temporary PVC of the same size, volume mode, storage class,\nand even on the same topology (if topology is used) as the original PVC. The populator\ncontroller creates a worker pod that attaches to the volume and writes the necessary\ndata to it, then detaches from the volume and the populator controller rebinds the PV\nfrom the temporary PVC to the orignal PVC.</p>\n<h2 id=\"trying-it-out\">Trying it out</h2>\n<p>The following things are required to use volume populators:</p>\n<ul>\n<li>Enable the <code>AnyVolumeDataSource</code> feature gate</li>\n<li>Install a CRD for the specific data source / populator</li>\n<li>Install the populator controller itself</li>\n</ul>\n<p>Populator controllers may use the <a href=\"https://github.com/kubernetes-csi/lib-volume-populator\">lib-volume-populator</a>\nlibrary to do most of the Kubernetes API level work. Individual populators only need to\nprovide logic for actually writing data into the volume based on a particular CR\ninstance. This library provides a sample populator implementation.</p>\n<p>These optional components improve user experience:</p>\n<ul>\n<li>Install the VolumePopulator CRD</li>\n<li>Create a VolumePopulator custom respource for each specific data source</li>\n<li>Install the <a href=\"https://github.com/kubernetes-csi/volume-data-source-validator\">volume data source validator</a>\ncontroller (alpha)</li>\n</ul>\n<p>The purpose of these components is to generate warning events on PVCs with data sources\nfor which there is no populator.</p>\n<h2 id=\"putting-it-all-together\">Putting it all together</h2>\n<p>To see how this works, you can install the sample &quot;hello&quot; populator and try it\nout.</p>\n<p>First install the volume-data-source-validator controller.</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/volume-data-source-validator/master/client/config/crd/populator.storage.k8s.io_volumepopulators.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/volume-data-source-validator/master/deploy/kubernetes/rbac-data-source-validator.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/volume-data-source-validator/master/deploy/kubernetes/setup-data-source-validator.yaml\n</code></pre><p>Next install the example populator.</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/lib-volume-populator/master/example/hello-populator/crd.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/lib-volume-populator/master/example/hello-populator/deploy.yaml\n</code></pre><p>Create an instance of the <code>Hello</code> CR, with some text.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>hello.k8s.io/v1alpha1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">fileName</span>:<span style=\"color:#bbb\"> </span>example.txt<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">fileContents</span>:<span style=\"color:#bbb\"> </span>Hello, world!<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Create a PVC that refers to that CR as its data source.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-pvc<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOnce<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>10Mi<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">dataSourceRef</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiGroup</span>:<span style=\"color:#bbb\"> </span>hello.k8s.io<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeMode</span>:<span style=\"color:#bbb\"> </span>Filesystem<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Next, run a job that reads the file in the PVC.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>batch/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Job<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-job<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">template</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">containers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-container<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>busybox:latest<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">command</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- cat<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- /mnt/example.txt<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeMounts</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>vol<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">mountPath</span>:<span style=\"color:#bbb\"> </span>/mnt<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">restartPolicy</span>:<span style=\"color:#bbb\"> </span>Never<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>vol<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">persistentVolumeClaim</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">claimName</span>:<span style=\"color:#bbb\"> </span>example-pvc<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Wait for the job to complete (including all of its dependencies).</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl wait --for=condition=Complete job/example-job\n</code></pre><p>And last examine the log from the job.</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl logs job/example-job\nHello, world!\n</code></pre><p>Note that the volume already contained a text file with the string contents from\nthe CR. This is only the simplest example. Actual populators can set up the volume\nto contain arbitrary contents.</p>\n<h2 id=\"how-to-write-your-own-volume-populator\">How to write your own volume populator</h2>\n<p>Developers interested in writing new poplators are encouraged to use the\n<a href=\"https://github.com/kubernetes-csi/lib-volume-populator\">lib-volume-populator</a> library\nand to only supply a small controller wrapper around the library, and a pod image\ncapable of attaching to volumes and writing the appropriate data to the volume.</p>\n<p>Individual populators can be extremely generic such that they work with every type\nof PVC, or they can do vendor specific things to rapidly fill a volume with data\nif the volume was provisioned by a specific CSI driver from the same vendor, for\nexample, by communicating directly with the storage for that volume.</p>\n<h2 id=\"the-future\">The future</h2>\n<p>As this feature is still in alpha, we expect to update the out of tree controllers\nwith more tests and documentation. The community plans to eventually re-implement\nthe populator library as a sidecar, for ease of operations.</p>\n<p>We hope to see some official community-supported populators for some widely-shared\nuse cases. Also, we expect that volume populators will be used by backup vendors\nas a way to &quot;restore&quot; backups to volumes, and possibly a standardized API to do\nthis will evolve.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>The enhancement proposal,\n<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/1495-volume-populators\">Volume Populators</a>, includes lots of detail about the history and technical implementation\nof this feature.</p>\n<p><a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#volume-populators-and-data-sources\">Volume populators and data sources</a>, within the documentation topic about persistent volumes,\nexplains how to use this feature in your cluster.</p>\n<p>Please get involved by joining the Kubernetes storage SIG to help us enhance this\nfeature. There are a lot of good ideas already and we'd be thrilled to have more!</p>","PublishedAt":"2021-08-30 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/08/30/volume-populators-redesigned/","SourceName":"Kubernetes"}},{"node":{"ID":1258,"Title":"Blog: Minimum Ready Seconds for StatefulSets","Description":"<p><strong>Authors:</strong> Ravi Gudimetla (Red Hat), Maciej Szulik (Red Hat)</p>\n<p>This blog describes the notion of Availability for <code>StatefulSet</code> workloads, and a new alpha feature in Kubernetes 1.22 which adds <code>minReadySeconds</code> configuration for <code>StatefulSets</code>.</p>\n<h2 id=\"what-problems-does-this-solve\">What problems does this solve?</h2>\n<p>Prior to Kubernetes 1.22 release, once a <code>StatefulSet</code> <code>Pod</code> is in the <code>Ready</code> state it is considered <code>Available</code> to receive traffic. For some of the <code>StatefulSet</code> workloads, it may not be the case. For example, a workload like Prometheus with multiple instances of Alertmanager, it should be considered <code>Available</code> only when Alertmanager's state transfer is complete, not when the <code>Pod</code> is in <code>Ready</code> state. Since <code>minReadySeconds</code> adds buffer, the state transfer may be complete before the <code>Pod</code> becomes <code>Available</code>. While this is not a fool proof way of identifying if the state transfer is complete or not, it gives a way to the end user to express their intention of waiting for sometime before the <code>Pod</code> is considered <code>Available</code> and it is ready to serve requests.</p>\n<p>Another case, where <code>minReadySeconds</code> helps is when using <code>LoadBalancer</code> <code>Services</code> with cloud providers. Since <code>minReadySeconds</code> adds latency after a <code>Pod</code> is <code>Ready</code>, it provides buffer time to prevent killing pods in rotation before new pods show up. Imagine a load balancer in unhappy path taking 10-15s to propagate. If you have 2 replicas then, you'd kill the second replica only after the first one is up but in reality, first replica cannot be seen because it is not yet ready to serve requests.</p>\n<p>So, in general, the notion of <code>Availability</code> in <code>StatefulSets</code> is pretty useful and this feature helps in solving the above problems. This is a feature that already exists for <code>Deployments</code> and <code>DaemonSets</code> and we now have them for <code>StatefulSets</code> too to give users consistent workload experience.</p>\n<h2 id=\"how-does-it-work\">How does it work?</h2>\n<p>The statefulSet controller watches for both <code>StatefulSets</code> and the <code>Pods</code> associated with them. When the feature gate associated with this feature is enabled, the statefulSet controller identifies how long a particular <code>Pod</code> associated with a <code>StatefulSet</code> has been in the <code>Running</code> state.</p>\n<p>If this value is greater than or equal to the time specified by the end user in <code>.spec.minReadySeconds</code> field, the statefulSet controller updates a field called <code>availableReplicas</code> in the <code>StatefulSet</code>'s status subresource to include this <code>Pod</code>. The <code>status.availableReplicas</code> in <code>StatefulSet</code>'s status is an integer field which tracks the number of pods that are <code>Available</code>.</p>\n<h2 id=\"how-do-i-use-it\">How do I use it?</h2>\n<p>You are required to prepare the following things in order to try out the feature:</p>\n<ul>\n<li>Download and install a kubectl greater than v1.22.0 version</li>\n<li>Switch on the feature gate with the command line flag <code>--feature-gates=StatefulSetMinReadySeconds=true</code> on <code>kube-apiserver</code> and <code>kube-controller-manager</code></li>\n</ul>\n<p>After successfully starting <code>kube-apiserver</code> and <code>kube-controller-manager</code>, you will see <code>AvailableReplicas</code> in the status and <code>minReadySeconds</code> of spec (with a default value of 0).</p>\n<p>Specify a value for <code>minReadySeconds</code> for any StatefulSet and you can check if <code>Pods</code> are available or not by checking <code>AvailableReplicas</code> field using:\n<code>kubectl get statefulset/&lt;name_of_the_statefulset&gt; -o yaml</code></p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<ul>\n<li>Read the KEP: <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-apps/2599-minreadyseconds-for-statefulsets#readme\">minReadySeconds for StatefulSets</a></li>\n<li>Read the documentation: <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#minimum-ready-seconds\">Minimum ready seconds</a> for StatefulSet</li>\n<li>Review the <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/stateful-set-v1/\">API definition</a> for StatefulSet</li>\n</ul>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>Please reach out to us in the <a href=\"https://kubernetes.slack.com/archives/C18NZM5K9\">#sig-apps</a> channel on Slack (visit <a href=\"https://slack.k8s.io/\">https://slack.k8s.io/</a> for an invitation if you need one), or on the SIG Apps mailing list: <a href=\"mailto:kubernetes-sig-apps@googlegroups.com\">kubernetes-sig-apps@googlegroups.com</a></p>","PublishedAt":"2021-08-27 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/08/27/minreadyseconds-statefulsets/","SourceName":"Kubernetes"}},{"node":{"ID":774,"Title":"How Data Shapes the Uber Rider App","Description":"<h1><span style=\"font-weight: 400;\">Introduction</span></h1>\n<p><span style=\"font-weight: 400;\">Data is crucial for our products. Data analytics help us provide a frictionless experience to the people that use our services. It also enables our engineers, product managers, data analysts, and data scientists to make informed decisions. The impact </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/how-data-shapes-the-uber-rider-app/\">How Data Shapes the Uber Rider App</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-08-26 16:00:20+00:00","OriginURL":"https://eng.uber.com/how-data-shapes-the-uber-rider-app/","SourceName":"Uber"}},{"node":{"ID":1259,"Title":"Blog: Enable seccomp for all workloads with a new v1.22 alpha feature","Description":"<p><strong>Author:</strong> Sascha Grunert, Red Hat</p>\n<p>This blog post is about a new Kubernetes feature introduced in v1.22, which adds\nan additional security layer on top of the existing seccomp support. Seccomp is\na security mechanism for Linux processes to filter system calls (syscalls) based\non a set of defined rules. Applying seccomp profiles to containerized workloads\nis one of the key tasks when it comes to enhancing the security of the\napplication deployment. Developers, site reliability engineers and\ninfrastructure administrators have to work hand in hand to create, distribute\nand maintain the profiles over the applications life-cycle.</p>\n<p>You can use the <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-1\"><code>securityContext</code></a> field of Pods and their\ncontainers can be used to adjust security related configurations of the\nworkload. Kubernetes introduced dedicated <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-1\">seccomp related API\nfields</a> in this <code>SecurityContext</code> with the <a href=\"https://kubernetes.io/blog/2020/08/26/kubernetes-release-1.19-accentuate-the-paw-sitive/#graduated-to-stable\">graduation of seccomp to\nGeneral Availability (GA)</a> in v1.19.0. This enhancement allowed an easier\nway to specify if the whole pod or a specific container should run as:</p>\n<ul>\n<li><code>Unconfined</code>: seccomp will not be enabled</li>\n<li><code>RuntimeDefault</code>: the container runtimes default profile will be used</li>\n<li><code>Localhost</code>: a node local profile will be applied, which is being referenced\nby a relative path to the seccomp profile root (<code>&lt;kubelet-root-dir&gt;/seccomp</code>)\nof the kubelet</li>\n</ul>\n<p>With the graduation of seccomp, nothing has changed from an overall security\nperspective, because <code>Unconfined</code> is still the default. This is totally fine if\nyou consider this from the upgrade path and backwards compatibility perspective of\nKubernetes releases. But it also means that it is more likely that a workload\nruns without seccomp at all, which should be fixed in the long term.</p>\n<h2 id=\"seccompdefault-to-the-rescue\"><code>SeccompDefault</code> to the rescue</h2>\n<p>Kubernetes v1.22.0 introduces a new kubelet <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates\">feature gate</a>\n<code>SeccompDefault</code>, which has been added in <code>alpha</code> state as every other new\nfeature. This means that it is disabled by default and can be enabled manually\nfor every single Kubernetes node.</p>\n<p>What does the feature do? Well, it just changes the default seccomp profile from\n<code>Unconfined</code> to <code>RuntimeDefault</code>. If not specified differently in the pod\nmanifest, then the feature will add a higher set of security constraints by\nusing the default profile of the container runtime. These profiles may differ\nbetween runtimes like <a href=\"https://github.com/cri-o/cri-o/blob/fe30d62/vendor/github.com/containers/common/pkg/seccomp/default_linux.go#L45\">CRI-O</a> or <a href=\"https://github.com/containerd/containerd/blob/e1445df/contrib/seccomp/seccomp_default.go#L51\">containerd</a>. They also differ for\nits used hardware architectures. But generally speaking, those default profiles\nallow a common amount of syscalls while blocking the more dangerous ones, which\nare unlikely or unsafe to be used in a containerized application.</p>\n<h3 id=\"enabling-the-feature\">Enabling the feature</h3>\n<p>Two kubelet configuration changes have to be made to enable the feature:</p>\n<ol>\n<li><strong>Enable the feature</strong> gate by setting the <code>SeccompDefault=true</code> via the command\nline (<code>--feature-gates</code>) or the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file\">kubelet configuration</a> file.</li>\n<li><strong>Turn on the feature</strong> by enabling the feature by adding the\n<code>--seccomp-default</code> command line flag or via the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file\">kubelet\nconfiguration</a> file (<code>seccompDefault: true</code>).</li>\n</ol>\n<p>The kubelet will error on startup if only one of the above steps have been done.</p>\n<h3 id=\"trying-it-out\">Trying it out</h3>\n<p>If the feature is enabled on a node, then you can create a new workload like\nthis:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">containers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-container<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>nginx:1.21<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Now it is possible to inspect the used seccomp profile by using\n<a href=\"https://github.com/kubernetes-sigs/cri-tools\"><code>crictl</code></a> while investigating the containers <a href=\"https://github.com/opencontainers/runtime-spec/blob/0c021c1/config-linux.md#seccomp\">runtime\nspecification</a>:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-bash\" data-lang=\"bash\"><span style=\"display:flex;\"><span><span style=\"color:#b8860b\">CONTAINER_ID</span><span style=\"color:#666\">=</span><span style=\"color:#a2f;font-weight:bold\">$(</span>sudo crictl ps -q --name<span style=\"color:#666\">=</span>test-container<span style=\"color:#a2f;font-weight:bold\">)</span>\n</span></span><span style=\"display:flex;\"><span>sudo crictl inspect <span style=\"color:#b8860b\">$CONTAINER_ID</span> | jq .info.runtimeSpec.linux.seccomp\n</span></span></code></pre></div><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span>{<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;defaultAction&#34;: </span><span style=\"color:#b44\">&#34;SCMP_ACT_ERRNO&#34;</span>,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;architectures&#34;: </span>[<span style=\"color:#b44\">&#34;SCMP_ARCH_X86_64&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;SCMP_ARCH_X86&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;SCMP_ARCH_X32&#34;</span>],<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;syscalls&#34;: </span>[<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>{<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;names&#34;: </span>[<span style=\"color:#b44\">&#34;_llseek&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;_newselect&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;accept&#34;</span>,<span style=\"color:#bbb\"> </span>…, &#34;write&#34;, &#34;writev&#34;],<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;action&#34;: </span><span style=\"color:#b44\">&#34;SCMP_ACT_ALLOW&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>},<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>…<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span>}<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>You can see that the lower level container runtime (<a href=\"https://github.com/cri-o/cri-o\">CRI-O</a> and\n<a href=\"https://github.com/opencontainers/runc\">runc</a> in our case), successfully applied the default seccomp profile.\nThis profile denies all syscalls per default, while allowing commonly used ones\nlike <a href=\"https://man7.org/linux/man-pages/man2/accept.2.html\"><code>accept</code></a> or <a href=\"https://man7.org/linux/man-pages/man2/write.2.html\"><code>write</code></a>.</p>\n<p>Please note that the feature will not influence any Kubernetes API for now.\nTherefore, it is not possible to retrieve the used seccomp profile via <code>kubectl</code>\n<code>get</code> or <code>describe</code> if the <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-1\"><code>SeccompProfile</code></a> field is unset within the\n<code>SecurityContext</code>.</p>\n<p>The feature also works when using multiple containers within a pod, for example\nif you create a pod like this:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">containers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-container-nginx<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>nginx:1.21<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">securityContext</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">seccompProfile</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>Unconfined<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-container-redis<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>redis:6.2<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>then you should see that the <code>test-container-nginx</code> runs without a seccomp profile:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-bash\" data-lang=\"bash\"><span style=\"display:flex;\"><span>sudo crictl inspect <span style=\"color:#a2f;font-weight:bold\">$(</span>sudo crictl ps -q --name<span style=\"color:#666\">=</span>test-container-nginx<span style=\"color:#a2f;font-weight:bold\">)</span> |\n</span></span><span style=\"display:flex;\"><span> jq <span style=\"color:#b44\">&#39;.info.runtimeSpec.linux.seccomp == null&#39;</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#a2f\">true</span>\n</span></span></code></pre></div><p>Whereas the container <code>test-container-redis</code> runs with <code>RuntimeDefault</code>:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-bash\" data-lang=\"bash\"><span style=\"display:flex;\"><span>sudo crictl inspect <span style=\"color:#a2f;font-weight:bold\">$(</span>sudo crictl ps -q --name<span style=\"color:#666\">=</span>test-container-redis<span style=\"color:#a2f;font-weight:bold\">)</span> |\n</span></span><span style=\"display:flex;\"><span> jq <span style=\"color:#b44\">&#39;.info.runtimeSpec.linux.seccomp != null&#39;</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#a2f\">true</span>\n</span></span></code></pre></div><p>The same applies to the pod itself, which also runs with the default profile:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-bash\" data-lang=\"bash\"><span style=\"display:flex;\"><span>sudo crictl inspectp <span style=\"color:#666\">(</span>sudo crictl pods -q --name test-pod<span style=\"color:#666\">)</span> |\n</span></span><span style=\"display:flex;\"><span> jq <span style=\"color:#b44\">&#39;.info.runtimeSpec.linux.seccomp != null&#39;</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#a2f\">true</span>\n</span></span></code></pre></div><h3 id=\"upgrade-strategy\">Upgrade strategy</h3>\n<p>It is recommended to enable the feature in multiple steps, whereas different\nrisks and mitigations exist for each one.</p>\n<h4 id=\"feature-gate-enabling\">Feature gate enabling</h4>\n<p>Enabling the feature gate at the kubelet level will not turn on the feature, but\nwill make it possible by using the <code>SeccompDefault</code> kubelet configuration or the\n<code>--seccomp-default</code> CLI flag. This can be done by an administrator for the whole\ncluster or only a set of nodes.</p>\n<h4 id=\"testing-the-application\">Testing the Application</h4>\n<p>If you're trying this within a dedicated test environment, you have to ensure\nthat the application code does not trigger syscalls blocked by the\n<code>RuntimeDefault</code> profile before enabling the feature on a node. This can be done\nby:</p>\n<ul>\n<li>\n<p><em>Recommended</em>: Analyzing the code (manually or by running the application with\n<a href=\"https://man7.org/linux/man-pages/man1/strace.1.html\">strace</a>) for any executed syscalls which may be blocked by the\ndefault profiles. If that's the case, then you can override the default by\nexplicitly setting the pod or container to run as <code>Unconfined</code>. Alternatively,\nyou can create a custom seccomp profile (see optional step below).\nprofile based on the default by adding the additional syscalls to the\n<code>&quot;action&quot;: &quot;SCMP_ACT_ALLOW&quot;</code> section.</p>\n</li>\n<li>\n<p><em>Recommended</em>: Manually set the profile to the target workload and use a\nrolling upgrade to deploy into production. Rollback the deployment if the\napplication does not work as intended.</p>\n</li>\n<li>\n<p><em>Optional</em>: Run the application against an end-to-end test suite to trigger\nall relevant code paths with <code>RuntimeDefault</code> enabled. If a test fails, use\nthe same mitigation as mentioned above.</p>\n</li>\n<li>\n<p><em>Optional</em>: Create a custom seccomp profile based on the default and change\nits default action from <code>SCMP_ACT_ERRNO</code> to <code>SCMP_ACT_LOG</code>. This means that\nthe seccomp filter for unknown syscalls will have no effect on the application\nat all, but the system logs will now indicate which syscalls may be blocked.\nThis requires at least a Kernel version 4.14 as well as a recent <a href=\"https://github.com/opencontainers/runc\">runc</a>\nrelease. Monitor the application hosts audit logs (defaults to\n<code>/var/log/audit/audit.log</code>) or syslog entries (defaults to <code>/var/log/syslog</code>)\nfor syscalls via <code>type=SECCOMP</code> (for audit) or <code>type=1326</code> (for syslog).\nCompare the syscall ID with those <a href=\"https://github.com/torvalds/linux/blob/7bb7f2a/arch/x86/entry/syscalls/syscall_64.tbl\">listed in the Linux Kernel\nsources</a> and add them to the custom profile. Be aware that custom\naudit policies may lead into missing syscalls, depending on the configuration\nof auditd.</p>\n</li>\n<li>\n<p><em>Optional</em>: Use cluster additions like the <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator\">Security Profiles Operator</a>\nfor profiling the application via its <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/c90ef3a/installation-usage.md#record-profiles-from-workloads-with-profilerecordings\">log enrichment</a> capabilities or\nrecording a profile by using its <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/c90ef3a/installation-usage.md#using-the-log-enricher\">recording feature</a>. This makes the\nabove mentioned manual log investigation obsolete.</p>\n</li>\n</ul>\n<h4 id=\"deploying-the-modified-application\">Deploying the modified application</h4>\n<p>Based on the outcome of the application tests, it may be required to change the\napplication deployment by either specifying <code>Unconfined</code> or a custom seccomp\nprofile. This is not the case if the application works as intended with\n<code>RuntimeDefault</code>.</p>\n<h4 id=\"enable-the-kubelet-configuration\">Enable the kubelet configuration</h4>\n<p>If everything went well, then the feature is ready to be enabled by the kubelet\nconfiguration or its corresponding CLI flag. This should be done on a per-node\nbasis to reduce the overall risk of missing a syscall during the investigations\nwhen running the application tests. If it's possible to monitor audit logs\nwithin the cluster, then it's recommended to do this for eventually missed\nseccomp events. If the application works as intended then the feature can be\nenabled for further nodes within the cluster.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Thank you for reading this blog post! I hope you enjoyed to see how the usage of\nseccomp profiles has been evolved in Kubernetes over the past releases as much\nas I do. On your own cluster, change the default seccomp profile to\n<code>RuntimeDefault</code> (using this new feature) and see the security benefits, and, of\ncourse, feel free to reach out any time for feedback or questions.</p>\n<hr>\n<p><em>Editor's note: If you have any questions or feedback about this blog post, feel\nfree to reach out via the <a href=\"https://kubernetes.slack.com/messages/sig-node\">Kubernetes slack in #sig-node</a>.</em></p>","PublishedAt":"2021-08-25 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/08/25/seccomp-default/","SourceName":"Kubernetes"}},{"node":{"ID":775,"Title":"Building Scalable Streaming Pipelines for Near Real-Time Features","Description":"<h1><span style=\"font-weight: 400;\">Background</span></h1>\n<p><span style=\"font-weight: 400;\">Uber is committed to providing reliable services to customers across our global markets. To achieve this, we heavily rely on machine learning (ML) to make informed decisions like forecasting and surge. As a result, real-time streaming pipelines, which are </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/building-scalable-streaming-pipelines/\">Building Scalable Streaming Pipelines for Near Real-Time Features</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-08-24 16:00:51+00:00","OriginURL":"https://eng.uber.com/building-scalable-streaming-pipelines/","SourceName":"Uber"}},{"node":{"ID":786,"Title":"Service Architecture at SoundCloud — Part 2: Value-Added Services","Description":"This article is part of a series of posts aiming to cast some light onto how service architecture has evolved at SoundCloud over the past…","PublishedAt":"2021-08-20 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/service-architecture-2","SourceName":"Soundcloud"}},{"node":{"ID":776,"Title":"Eats Safety Team On-Call Overview","Description":"<h2><span style=\"font-weight: 400;\">Introduction</span></h2>\n<p><span style=\"font-weight: 400;\">Our engineers have the responsibility of ensuring a consistent and positive experience for our riders, drivers, eaters, and delivery/restaurant partners.</span></p>\n<p><span style=\"font-weight: 400;\">Ensuring such an experience requires reliable systems: our apps have to work when anyone needs them. A major component </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/eats-safety-team-on-call-overview/\">Eats Safety Team On-Call Overview</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-08-19 16:00:52+00:00","OriginURL":"https://eng.uber.com/eats-safety-team-on-call-overview/","SourceName":"Uber"}},{"node":{"ID":777,"Title":"Unifying Support Content to Enable More Empathetic and Personalized Customer Support Experiences","Description":"<h2><span style=\"font-weight: 400;\">Introduction </span></h2>\n<p><span style=\"font-weight: 400;\">Content quality is critical to the support experienced by Uber’s customers. Consider an Eater who reached out for help to cancel a very delayed order. The same resolution, such as refunding the charge, can be delivered alongside a robotic-sounding </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/personalized-customer-support-experiences/\">Unifying Support Content to Enable More Empathetic and Personalized Customer Support Experiences</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-08-17 16:00:58+00:00","OriginURL":"https://eng.uber.com/personalized-customer-support-experiences/","SourceName":"Uber"}},{"node":{"ID":1260,"Title":"Blog: Alpha in v1.22: Windows HostProcess Containers","Description":"<p><strong>Authors:</strong> Brandon Smith (Microsoft)</p>\n<p>Kubernetes v1.22 introduced a new alpha feature for clusters that\ninclude Windows nodes: HostProcess containers.</p>\n<p>HostProcess containers aim to extend the Windows container model to enable a wider\nrange of Kubernetes cluster management scenarios. HostProcess containers run\ndirectly on the host and maintain behavior and access similar to that of a regular\nprocess. With HostProcess containers, users can package and distribute management\noperations and functionalities that require host access while retaining versioning\nand deployment methods provided by containers. This allows Windows containers to\nbe used for a variety of device plugin, storage, and networking management scenarios\nin Kubernetes. With this comes the enablement of host network mode—allowing\nHostProcess containers to be created within the host's network namespace instead of\ntheir own. HostProcess containers can also be built on top of existing Windows server\n2019 (or later) base images, managed through the Windows container runtime, and run\nas any user that is available on or in the domain of the host machine.</p>\n<p>Linux privileged containers are currently used for a variety of key scenarios in\nKubernetes, including kube-proxy (via kubeadm), storage, and networking scenarios.\nSupport for these scenarios in Windows previously required workarounds via proxies\nor other implementations. Using HostProcess containers, cluster operators no longer\nneed to log onto and individually configure each Windows node for administrative\ntasks and management of Windows services. Operators can now utilize the container\nmodel to deploy management logic to as many clusters as needed with ease.</p>\n<h2 id=\"how-does-it-work\">How does it work?</h2>\n<p>Windows HostProcess containers are implemented with Windows <em>Job Objects</em>, a break from the\nprevious container model using server silos. Job objects are components of the Windows OS which offer the ability to\nmanage a group of processes as a group (a.k.a. <em>jobs</em>) and assign resource constraints to the\ngroup as a whole. Job objects are specific to the Windows OS and are not associated with the Kubernetes <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/\">Job API</a>. They have no process or file system isolation,\nenabling the privileged payload to view and edit the host file system with the\ncorrect permissions, among other host resources. The init process, and any processes\nit launches or that are explicitly launched by the user, are all assigned to the\njob object of that container. When the init process exits or is signaled to exit,\nall the processes in the job will be signaled to exit, the job handle will be\nclosed and the storage will be unmounted.</p>\n<p>HostProcess and Linux privileged containers enable similar scenarios but differ\ngreatly in their implementation (hence the naming difference). HostProcess containers\nhave their own pod security policies. Those used to configure Linux privileged\ncontainers <strong>do not</strong> apply. Enabling privileged access to a Windows host is a\nfundamentally different process than with Linux so the configuration and\ncapabilities of each differ significantly. Below is a diagram detailing the\noverall architecture of Windows HostProcess containers:</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2021/08/16/windows-hostprocess-containers/hostprocess-architecture.png\"\nalt=\"HostProcess Architecture\"/>\n</figure>\n<h2 id=\"how-do-i-use-it\">How do I use it?</h2>\n<p>HostProcess containers can be run from within a\n<a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod\">HostProcess Pod</a>.\nWith the feature enabled on Kubernetes version 1.22, a containerd container runtime of\n1.5.4 or higher, and the latest version of hcsshim, deploying a pod spec with the\n<a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/#before-you-begin\">correct HostProcess configuration</a>\nwill enable you to run HostProcess containers. To get started with running\nWindows containers see the general guidance for <a href=\"https://kubernetes.io/docs/setup/production-environment/windows/\">Windows in Kubernetes</a></p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<ul>\n<li>\n<p>Work through <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/\">Create a Windows HostProcess Pod</a></p>\n</li>\n<li>\n<p>Read about Kubernetes <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-standards/\">Pod Security Standards</a></p>\n</li>\n<li>\n<p>Read the enhancement proposal <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-windows/1981-windows-privileged-container-support\">Windows Privileged Containers and Host Networking Mode</a> (KEP-1981)</p>\n</li>\n</ul>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>HostProcess containers are in active development. SIG Windows welcomes suggestions from the community.\nGet involved with <a href=\"https://github.com/kubernetes/community/tree/master/sig-windows\">SIG Windows</a>\nto contribute!</p>","PublishedAt":"2021-08-16 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/08/16/windows-hostprocess-containers/","SourceName":"Kubernetes"}},{"node":{"ID":778,"Title":"Efficiently Managing the Supply and Demand on Uber’s Big Data Platform","Description":"<p><span style=\"font-weight: 400;\">With Uber’s business growth and the fast adoption of big data and AI, Big Data scaled to become our most costly infrastructure platform. To reduce operational expenses, we developed a holistic framework with 3 pillars: platform efficiency, supply, and demand </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/supply-demand-big-data-platform/\">Efficiently Managing the Supply and Demand on Uber’s Big Data Platform</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-08-13 16:00:16+00:00","OriginURL":"https://eng.uber.com/supply-demand-big-data-platform/","SourceName":"Uber"}},{"node":{"ID":1261,"Title":"Blog: Kubernetes Memory Manager moves to beta","Description":"<p><strong>Authors:</strong> Artyom Lukianov (Red Hat), Cezary Zukowski (Samsung)</p>\n<p>The blog post explains some of the internals of the <em>Memory manager</em>, a beta feature\nof Kubernetes 1.22. In Kubernetes, the Memory Manager is a\n<a href=\"https://kubernetes.io/docs/concepts/overview/components/#kubelet\">kubelet</a> subcomponent.\nThe memory manage provides guaranteed memory (and hugepages)\nallocation for pods in the <code>Guaranteed</code> <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/#qos-classes\">QoS class</a>.</p>\n<p>This blog post covers:</p>\n<ol>\n<li><a href=\"#Why-do-you-need-it?\">Why do you need it?</a></li>\n<li><a href=\"#How-does-it-work?\">The internal details of how the <strong>MemoryManager</strong> works</a></li>\n<li><a href=\"#Current-limitations\">Current limitations of the <strong>MemoryManager</strong></a></li>\n<li><a href=\"#Future-work-for-the-Memory-Manager\">Future work for the <strong>MemoryManager</strong></a></li>\n</ol>\n<h2 id=\"why-do-you-need-it\">Why do you need it?</h2>\n<p>Some Kubernetes workloads run on nodes with\n<a href=\"https://en.wikipedia.org/wiki/Non-uniform_memory_access\">non-uniform memory access</a> (NUMA).\nSuppose you have NUMA nodes in your cluster. In that case, you'll know about the potential for extra latency when\ncompute resources need to access memory on the different NUMA locality.</p>\n<p>To get the best performance and latency for your workload, container CPUs,\nperipheral devices, and memory should all be aligned to the same NUMA\nlocality.\nBefore Kubernetes v1.22, the kubelet already provided a set of managers to\nalign CPUs and PCI devices, but you did not have a way to align memory.\nThe Linux kernel was able to make best-effort attempts to allocate\nmemory for tasks from the same NUMA node where the container is\nexecuting are placed, but without any guarantee about that placement.</p>\n<h2 id=\"how-does-it-work\">How does it work?</h2>\n<p>The memory manager is doing two main things:</p>\n<ul>\n<li>provides the topology hint to the Topology Manager</li>\n<li>allocates the memory for containers and updates the state</li>\n</ul>\n<p>The overall sequence of the Memory Manager under the Kubelet</p>\n<p><img src=\"https://kubernetes.io/images/blog/2021-08-11-memory-manager-moves-to-beta/MemoryManagerDiagram.svg\" alt=\"MemoryManagerDiagram\" title=\"MemoryManagerDiagram\"></p>\n<p>During the Admission phase:</p>\n<ol>\n<li>When first handling a new pod, the kubelet calls the TopologyManager's <code>Admit()</code> method.</li>\n<li>The Topology Manager is calling <code>GetTopologyHints()</code> for every hint provider including the Memory Manager.</li>\n<li>The Memory Manager calculates all possible NUMA nodes combinations for every container inside the pod and returns hints to the Topology Manager.</li>\n<li>The Topology Manager calls to <code>Allocate()</code> for every hint provider including the Memory Manager.</li>\n<li>The Memory Manager allocates the memory under the state according to the hint that the Topology Manager chose.</li>\n</ol>\n<p>During Pod creation:</p>\n<ol>\n<li>The kubelet calls <code>PreCreateContainer()</code>.</li>\n<li>For each container, the Memory Manager looks the NUMA nodes where it allocated the\nmemory for the container and then returns that information to the kubelet.</li>\n<li>The kubelet creates the container, via CRI, using a container specification\nthat incorporates information from the Memory Manager information.</li>\n</ol>\n<h3 id=\"let-s-talk-about-the-configuration\">Let's talk about the configuration</h3>\n<p>By default, the Memory Manager runs with the <code>None</code> policy, meaning it will just\nrelax and not do anything. To make use of the Memory Manager, you should set\ntwo command line options for the kubelet:</p>\n<ul>\n<li><code>--memory-manager-policy=Static</code></li>\n<li><code>--reserved-memory=&quot;&lt;numaNodeID&gt;:&lt;resourceName&gt;=&lt;quantity&gt;&quot;</code></li>\n</ul>\n<p>The value for <code>--memory-manager-policy</code> is straightforward: <code>Static</code>. Deciding what to specify for <code>--reserved-memory</code> takes more thought. To configure it correctly, you should follow two main rules:</p>\n<ul>\n<li>The amount of reserved memory for the <code>memory</code> resource must be greater than zero.</li>\n<li>The amount of reserved memory for the resource type must be equal\nto <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable\">NodeAllocatable</a>\n(<code>kube-reserved + system-reserved + eviction-hard</code>) for the resource.\nYou can read more about memory reservations in <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/\">Reserve Compute Resources for System Daemons</a>.</li>\n</ul>\n<p><img src=\"https://kubernetes.io/images/blog/2021-08-11-memory-manager-moves-to-beta/ReservedMemory.svg\" alt=\"Reserved memory\"></p>\n<h2 id=\"current-limitations\">Current limitations</h2>\n<p>The 1.22 release and promotion to beta brings along enhancements and fixes, but the Memory Manager still has several limitations.</p>\n<h3 id=\"single-vs-cross-numa-node-allocation\">Single vs Cross NUMA node allocation</h3>\n<p>The NUMA node can not have both single and cross NUMA node allocations. When the container memory is pinned to two or more NUMA nodes, we can not know from which NUMA node the container will consume the memory.</p>\n<p><img src=\"https://kubernetes.io/images/blog/2021-08-11-memory-manager-moves-to-beta/SingleCrossNUMAAllocation.svg\" alt=\"Single vs Cross NUMA allocation\" title=\"SingleCrossNUMAAllocation\"></p>\n<ol>\n<li>The <code>container1</code> started on the NUMA node 0 and requests <em>5Gi</em> of the memory but currently is consuming only <em>3Gi</em> of the memory.</li>\n<li>For container2 the memory request is 10Gi, and no single NUMA node can satisfy it.</li>\n<li>The <code>container2</code> consumes <em>3.5Gi</em> of the memory from the NUMA node 0, but once the <code>container1</code> will require more memory, it will not have it, and the kernel will kill one of the containers with the <em>OOM</em> error.</li>\n</ol>\n<p>To prevent such issues, the Memory Manager will fail the admission of the <code>container2</code> until the machine has two NUMA nodes without a single NUMA node allocation.</p>\n<h3 id=\"works-only-for-guaranteed-pods\">Works only for Guaranteed pods</h3>\n<p>The Memory Manager can not guarantee memory allocation for Burstable pods,\nalso when the Burstable pod has specified equal memory limit and request.</p>\n<p>Let's assume you have two Burstable pods: <code>pod1</code> has containers with\nequal memory request and limits, and <code>pod2</code> has containers only with a\nmemory request set. You want to guarantee memory allocation for the <code>pod1</code>.\nTo the Linux kernel, processes in either pod have the same <em>OOM score</em>,\nonce the kernel finds that it does not have enough memory, it can kill\nprocesses that belong to pod <code>pod1</code>.</p>\n<h3 id=\"memory-fragmentation\">Memory fragmentation</h3>\n<p>The sequence of Pods and containers that start and stop can fragment the memory on NUMA nodes.\nThe alpha implementation of the Memory Manager does not have any mechanism to balance pods and defragment memory back.</p>\n<h2 id=\"future-work-for-the-memory-manager\">Future work for the Memory Manager</h2>\n<p>We do not want to stop with the current state of the Memory Manager and are looking to\nmake improvements, including in the following areas.</p>\n<h3 id=\"make-the-memory-manager-allocation-algorithm-smarter\">Make the Memory Manager allocation algorithm smarter</h3>\n<p>The current algorithm ignores distances between NUMA nodes during the\ncalculation of the allocation. If same-node placement isn't available, we can still\nprovide better performance compared to the current implementation, by changing the\nMemory Manager to prefer the closest NUMA nodes for cross-node allocation.</p>\n<h3 id=\"reduce-the-number-of-admission-errors\">Reduce the number of admission errors</h3>\n<p>The default Kubernetes scheduler is not aware of the node's NUMA topology, and it can be a reason for many admission errors during the pod start.\nWe're hoping to add a KEP (Kubernetes Enhancement Proposal) to cover improvements in this area.\nFollow <a href=\"https://github.com/kubernetes/enhancements/issues/2044\">Topology aware scheduler plugin in kube-scheduler</a> to see how this idea progresses.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>With the promotion of the Memory Manager to beta in 1.22, we encourage everyone to give it a try and look forward to any feedback you may have. While there are still several limitations, we have a set of enhancements planned to address them and look forward to providing you with many new features in upcoming releases.\nIf you have ideas for additional enhancements or a desire for certain features, please let us know. The team is always open to suggestions to enhance and improve the Memory Manager.\nWe hope you have found this blog informative and helpful! Let us know if you have any questions or comments.</p>\n<p>You can contact us via:</p>\n<ul>\n<li>The Kubernetes <a href=\"https://kubernetes.slack.com/messages/sig-node\">#sig-node </a>\nchannel in Slack (visit <a href=\"https://slack.k8s.io/\">https://slack.k8s.io/</a> for an invitation if you need one)</li>\n<li>The SIG Node mailing list, <a href=\"https://groups.google.com/g/kubernetes-sig-node\">kubernetes-sig-node@googlegroups.com</a></li>\n</ul>","PublishedAt":"2021-08-11 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/08/11/kubernetes-1-22-feature-memory-manager-moves-to-beta/","SourceName":"Kubernetes"}},{"node":{"ID":477,"Title":"Tristan Handy on the changing face of the data stack","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/08/Group-1-3-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>Tristan Handy is the founder of dbt Labs. In this interview, Tristan gives us his thoughts on the data stack of today and the hopefully improved capability and accessibility of tomorrow’s. Ask Tristan Handy what he thinks the future of the data stack will look like and what you’ll get in return is a history</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/tristan-handy-changing-data-stack/\">Tristan Handy on the changing face of the data stack</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-08-10 21:38:00+00:00","OriginURL":"https://mixpanel.com/blog/tristan-handy-changing-data-stack/","SourceName":"Mixpanel"}},{"node":{"ID":86,"Title":"Kubernetes Deployment using Helm Charts and Krane","Description":"","PublishedAt":"2021-08-06 15:52:47+00:00","OriginURL":"https://medium.com/groupon-eng/kubernetes-deployment-using-helm-charts-and-krane-e0100b55d00c?source=rss----5c13a88f9872---4","SourceName":"Groupon"}},{"node":{"ID":148,"Title":"How we’re making Dropbox data centers 100% carbon neutral","Description":"","PublishedAt":"2021-08-03 13:00:00+00:00","OriginURL":"https://dropbox.tech/infrastructure/making-dropbox-data-centers-carbon-neutral","SourceName":"Dropbox"}},{"node":{"ID":478,"Title":"Struggling with math = analytics advocate","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/07/GuestBlog-JazBroughton@2x-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>I’ve struggled with math since high school. It wasn’t that I was incapable of doing simple algebra here and there. My hangup was the topic in general. I always had a hard time applying any real focus on the abstract shapes and concepts with no tangible connection to what I actually cared about. I’m sure</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/how-i-went-from-struggling-with-math-to-becoming-a-data-and-analytics-advocate/\">Struggling with math = analytics advocate</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-07-29 19:31:00+00:00","OriginURL":"https://mixpanel.com/blog/how-i-went-from-struggling-with-math-to-becoming-a-data-and-analytics-advocate/","SourceName":"Mixpanel"}},{"node":{"ID":787,"Title":"Service Architecture at SoundCloud — Part 1: Backends for Frontends","Description":"This article is part of a series of posts aiming to cast some light onto how service architecture has evolved at SoundCloud over the past…","PublishedAt":"2021-07-29 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/service-architecture-1","SourceName":"Soundcloud"}},{"node":{"ID":87,"Title":"On-boarding in a Pandemic and Navigating a Virtual Environment","Description":"","PublishedAt":"2021-07-23 16:39:43+00:00","OriginURL":"https://medium.com/groupon-eng/on-boarding-in-a-pandemic-and-navigating-a-virtual-environment-3d294da5fed7?source=rss----5c13a88f9872---4","SourceName":"Groupon"}},{"node":{"ID":435,"Title":"The most important API metric is time to first call","Description":"","PublishedAt":"2021-07-19 20:43:41+00:00","OriginURL":"https://medium.com/better-practices/the-most-important-api-metric-is-time-to-first-call-62ac3959de44?source=rss----410f2fbc015d---4","SourceName":"Postman"}},{"node":{"ID":788,"Title":"How We Share Knowledge as a Web Collective","Description":"There’s no single platform team that consists of only web engineers at SoundCloud, even though we consider ourselves to be part of the “Web…","PublishedAt":"2021-07-14 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/how-we-share-knowledge-as-a-web-collective","SourceName":"Soundcloud"}},{"node":{"ID":149,"Title":"Sharing our Engineering Career Framework with the world","Description":"","PublishedAt":"2021-07-12 20:00:00+00:00","OriginURL":"https://dropbox.tech/culture/sharing-our-engineering-career-framework-with-the-world","SourceName":"Dropbox"}},{"node":{"ID":479,"Title":"Product analytics cuts costs and headaches for startups","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/07/CTO-guest-blog@2x-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>For startups, product analytics isn’t just a &#8220;nice to have&#8221; tool in your stack of tech solutions that are supposed to help you grow. In my experience, it can sharpen your whole approach to product development and engineering.&#160; Put another way: I wanted to call this article &#8220;How to save money, brain cells, your engineering/product</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/ive-helped-build-5-startups-heres-how-i-use-product-analytics-to-cut-costs-and-headaches/\">Product analytics cuts costs and headaches for startups</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-07-09 21:27:00+00:00","OriginURL":"https://mixpanel.com/blog/ive-helped-build-5-startups-heres-how-i-use-product-analytics-to-cut-costs-and-headaches/","SourceName":"Mixpanel"}},{"node":{"ID":613,"Title":"How we build the Image Gallery on trivago","Description":"","PublishedAt":"2021-07-07 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2021-07-07-image-gallery-pipeline/","SourceName":"Trivago"}},{"node":{"ID":789,"Title":"Upcoming API Security Updates — Action Required","Description":"As part of our continuous effort toward making improvements to our API with the hope that we can relaunch API access to all developers, we…","PublishedAt":"2021-07-01 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/security-updates-api","SourceName":"Soundcloud"}}]}},"pageContext":{"limit":30,"skip":5190,"numPages":193,"currentPage":174}},"staticQueryHashes":["3649515864"]}