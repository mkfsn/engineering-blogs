{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/179","result":{"data":{"allPost":{"edges":[{"node":{"ID":812,"Title":"A Happy New Employee","Description":"My first six months at SoundCloud as an iOS engineer on the Recommendations team have just finished. In that time, I‚Äôve already contributed‚Ä¶","PublishedAt":"2020-02-07 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/a-happy-new-employee","SourceName":"Soundcloud"}},{"node":{"ID":365,"Title":"Chrome's Changes Could Break Your App: Prepare for SameSite Cookie Updates","Description":"<p>In this post, we will cover changes coming to Chrome (and other browsers) that affect how third-party cookies are handled‚Äîspecifically <code>SameSite</code> changes, how to test to see if your site is impacted and how to fix it.</p>\n\n<p><img src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1580744350-samesite-twitter.png\" alt=\"Blog post cover image showing a jar with cookies in it\"></p>\n\n<ul>\n<li>‚öìÔ∏è <a href=\"https://blog.heroku.com/chrome-changes-samesite-cookie#what-is-code-samesite-code-and-why-the-big-change\">What is <code>SameSite</code> and why the big change?</a>\n</li>\n<li>‚öìÔ∏è <a href=\"https://blog.heroku.com/chrome-changes-samesite-cookie#prepare-for-chrome-80-updates\">Prepare for Chrome 80 updates</a>\n\n<ul>\n<li>‚öìÔ∏è <a href=\"https://blog.heroku.com/chrome-changes-samesite-cookie#step-1-enabling-code-samesite-code-chrome-flags-and-test-to-see-if-your-site-faces-potential-code-samesite-code-errors\">Step 1: Enabling <code>SameSite</code> Chrome flags and test to see if your site faces <code>SameSite</code> errors</a>\n</li>\n<li>‚öìÔ∏è <a href=\"https://blog.heroku.com/chrome-changes-samesite-cookie#step-2-fixing-cookie-errors-using-appropriate-attributes\">Step 2: Fixing cookie errors using appropriate attributes</a>\n</li>\n</ul>\n</li>\n</ul>\n<h2 class=\"anchored\">\n  <a name=\"what-is-code-samesite-code-and-why-the-big-change\" href=\"#what-is-code-samesite-code-and-why-the-big-change\">What is <code>SameSite</code> and why the big change?</a>\n</h2>\n\n<p>Back in May 2019, Chrome announced its plan to develop a secure-by-default model for handling cookies. This initiative highlights Chrome‚Äôs promise of a more secure and faster browsing experience. Chrome's goal is to increase transparency, choice and control. Users should be aware of how they are tracked, who is tracking them, and ways to control the information shared. With the influx of privacy concerns and potential cross-site attacks, Chrome is taking action to protect its users. These changes will dramatically impact advertisers, publishers, or any company relying on cookies to target their audience. Be sure to prepare in advance so your users won't experience disruptions.</p>\n\n<p>Now, the day is finally at hand. Starting February 4, 2020, Google Chrome will stop sending third-party cookies in cross-site requests unless the cookies are secured and flagged using an IETF standard called <a href=\"https://web.dev/samesite-cookies-explained/\"><strong><code>SameSite</code></strong></a>.</p>\n<h3 class=\"anchored\">\n  <a name=\"what-does-this-mean-what-are-third-party-cookies-what-are-cross-site-request\" href=\"#what-does-this-mean-what-are-third-party-cookies-what-are-cross-site-request\">What does this mean? What are third-party cookies? What are cross-site request?</a>\n</h3>\n\n<p>When you visit a website, a browser cookie is generated and saved inside a folder in your web browser. This browser cookie is then used as a way to identify you and provide a personalized browsing experience. </p>\n\n<p>There are two types of cookies ‚Äî first-party and third-party. Both types can hold the same information; however, they are accessed and created differently.</p>\n\n<p><img src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1580750955-Same-Site%20Cookie%20Comparison.png\" alt=\"SameSite Cookie Comparison\"></p>\n\n<p>As illustrated above, if you visit website  <code>a.com</code> and you attempt to access a service from the same domain name <code>a.com</code>,  cookies generated will be considered first-party cookies. Being that the cookies were created by the same site, you'll be able to enjoy same-site luxuries while visiting <code>a.com</code>'s web service. These luxuries include saved login information, shopping cart items, site preferences, etc.</p>\n\n<p>Whereas, if you visit a website  <code>a.com</code>  but that page includes content (image, iframe, etc.) from a different domain name  <code>b.com</code>, cookies set by <code>b.com</code> will be considered third-party cookies because they come from a different name than in the URL bar:  <code>a.com</code>.</p>\n\n<p>These cookies were created by a different site and <code>b.com</code> accessing them from  <code>a.com</code>  (or any other domain) would constitute a cross-site request. A page on <code>a.com</code> making requests to <code>b.com</code> (for images, iframes, etc.) is what allows services like Facebook, Google Analytics, Doubleclick, etc. to track users and provide online-advertisements. In that example, Facebook, Google, and Doubleclick are the <code>b.com</code>. This allows, for example, Doubleclick to show targeted ads to you on multiple other sites you visit, like a news site, a hotel site, or a blog you read.</p>\n\n<p>As previously stated, Google Chrome will stop sending third-party cookies in cross-site requests unless the cookies are secured and flagged using an IETF standard called <a href=\"https://web.dev/samesite-cookies-explained/\"><strong><code>SameSite</code></strong></a>. In other words, the content from <code>b.com</code> (images, iframe, etc.) on <code>a.com</code>‚Äôs page will no longer be able to access <code>b.com</code>'s cookies unless those cookies are secured and flagged appropriately.</p>\n<h3 class=\"anchored\">\n  <a name=\"why-is-google-making-such-a-huge-change\" href=\"#why-is-google-making-such-a-huge-change\">Why is Google making such a huge change?</a>\n</h3>\n\n<p>Sharing cross-site cookies is not always an issue; however, it has the potential for abuse. Google Chrome's current behavior allows third-party websites to access all cookies by default.  This creates the possibility of <a href=\"https://developer.mozilla.org/en-US/docs/Glossary/CSRF\"><strong>cross-site request forgery</strong></a> (CSRF) attacks, other security vulnerabilities and privacy leaks.</p>\n<h3 class=\"anchored\">\n  <a name=\"what-s-cross-site-request-forgery-csrf\" href=\"#what-s-cross-site-request-forgery-csrf\">What‚Äôs cross-site request forgery (CSRF)?</a>\n</h3>\n\n<p>Cross-site request forgery is a web security vulnerability that allows a hacker to exploit users through session surfing or one-click attacks. For example, hackers can trick an innocent user to click a believable link. If this user is already logged into a website the hacker wants to access, the hacker can surf on the already authenticated session and make request to a site the user didn't intend to make. Being that the user already authenticated, the site cannot distinguish between the forged or legitimate request.</p>\n\n<p>There are a few ways to create these malicious commands: image tags, link tags, hidden forms, and JavaScript XMLHttpRequests. With Chrome's current default behavior, the requested cookie will be sent by default, and the hacker will have access to the user's session, which means they are effectively logged in as the user. To fight against this web vulnerability, web frameworks often require unique tokens/identifiers that are not accessible to attackers and would not be sent along (like cookies) with requests.</p>\n\n<p>As an example, let‚Äôs assume you sign into your bank account.</p>\n\n<pre><code>www.bankpal.com\n</code></pre>\n\n<p>While browsing your transaction history, you get an email letting you know about a recent suspicious transaction. To investigate further, the email requires you to log into your bank account. It provides a convenient link for you as well. </p>\n\n<p>üí°Note: You are still logged in to BankPal in another tab.</p>\n\n<p><img src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1580744964-Cross-Forgery%20Email%20%281%29.png\" alt=\"BankPal Cross-Forgery Email\"></p>\n\n<p>The link‚Äôs HTML is as follows:</p>\n\n<pre><code class=\"language-html\">&lt;a href=\"http://www.bank.com/transfer?acct=888888&amp;amount=100000\"&gt;Log In&lt;/a&gt;\n</code></pre>\n\n<p>The hacker has already studied BankPal so they know how to mimic account transfers quite well. For example, here is how BankPal typically creates money transfers:</p>\n\n<pre><code>GET http://www.bankpal.com/transfer?acct=AccountId&amp;amount=DollarAmount HTTP/1.1\n</code></pre>\n\n<p>This hacker has sent this email to a large number of bank customers and they know at least one person will click this believable link. </p>\n\n<p>You are that one customer.</p>\n\n<p><img src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1580745029-BUTTON%20click.png\" alt=\"Clicking log in button in email\"></p>\n\n<p>From a quick glance, this email looks legitimate. There is no way it could be suspicious and cause harm to a user's account. It even has the BankPal logo! With full trust, you click the link. Since you are already authenticated in the previous tab, clicking that link ends up creating an unauthorized transaction behind the scenes. This attacker has forged your identity, transferred $100,000 from your account, and has completely ruined your life (or at least your bank account) in seconds.</p>\n\n<p>Let's say BankPal only allows a <code>POST</code> request for money transfers. It would be impossible to create a malicious request using an <code>&lt;a href&gt;</code> tag. This attacker could very well create a <code>&lt;form&gt;</code> tag instead with automatic execution of the embedded JavaScript.</p>\n\n<p>This form's HTML code could look like this:</p>\n\n<pre><code class=\"language-html\"> &lt;body onload=\"document.forms[0].submit()\"&gt;\n   &lt;form action=\"http://www.bankpal.com/transfer\" method=\"POST\"&gt;\n     &lt;input type=\"hidden\" name=\"acct\" value=\"AttackerAccountId\"/&gt;\n     &lt;input type=\"hidden\" name=\"amount\" value=\"100000\"/&gt;\n     &lt;input type=\"submit\" value=\"Log In\"/&gt;\n   &lt;/form&gt;\n &lt;/body&gt;\n</code></pre>\n\n<p>In a real-life scenario, the example above would not happen. Banks prevent CSRF attacks using dynamically generated session tokens, session timeouts and other preventive methods. And now, with the <code>SameSite</code> attribute <code>Strict</code> (read more below), banks have yet another preventive measure. Large companies have found methods of protection; however, there are lots of smaller websites without protection. If an attacker can forge a transaction, they can also forge a password reset request, an email change request, and then gain full control of an account or web application.</p>\n<h3 class=\"anchored\">\n  <a name=\"how-is-chrome-protecting-users-against-csrf-attacks\" href=\"#how-is-chrome-protecting-users-against-csrf-attacks\">How is Chrome protecting users against CSRF attacks?</a>\n</h3>\n\n<p>To alleviate this issue, Chrome version 51 (2016-05-25) introduced the concept of the SameSite attribute. With the SameSite attribute, website developers have the power to set rules around how cookies are shared and accessed.  </p>\n\n<p>The <code>SameSite</code> attribute can be set with the following values: <strong><code>Strict</code></strong>, <strong><code>Lax</code></strong>, or <strong><code>None</code></strong>.</p>\n\n<p><img src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1580745160-Same-Site%20Cookie%20Infographic.png\" alt=\"SameSite Cookie Infographic\"></p>\n\n<p><strong>Strict: Restricts cross-site sharing altogether.</strong>\nCookies with this setting can be accessed only when visiting the domain from which it was initially set. In other words, <code>Strict</code> completely blocks a cookie being sent to <code>a.com</code> when a page from <code>b.com</code> makes the request. Even when clicking a top-level link on a third-party domain to your site, the browser will refuse to send the cookie. This option would be best for applications that require high security, such as banks.</p>\n\n<p><strong>Lax: All the sites belonging to the same domain can set and access cookies.</strong>\nUnlike <code>None</code> where cookies are always sent, <code>Lax</code> cookies are only sent on same-site request like <code>Strict</code>. However,  <code>Lax</code> allows top-level (sometimes called <a href=\"https://publicsuffix.org/\">public suffix</a>) navigation access with a safe HTTP method, like HTTP <code>GET</code>. The cookie will not be sent with cross-domain <code>POST</code> requests or when loading the site in a cross-origin frame, but it will be sent when you navigate to the site via a standard top-level <code>&lt;a href=...&gt;</code> link.</p>\n\n<p><strong>None: Allows third-party cookies to track users across sites.</strong>\nCookies with this setting will work the same way as cookies work today. Cookies will be able to be used across sites. \nüí°Note that you need both the <code>None</code> and <code>Secure</code> attributes together. If you just specify <code>None</code> without <code>Secure</code> the cookie will be rejected. <code>Secure</code> ensures that the browser request is sent by a secure (HTTPS) connection.</p>\n<h3 class=\"anchored\">\n  <a name=\"real-world-example-of-the-difference-between-code-strict-code-and-code-lax-code\" href=\"#real-world-example-of-the-difference-between-code-strict-code-and-code-lax-code\">Real-world example of the difference between <code>Strict</code> and <code>Lax</code></a>\n</h3>\n\n<p>The <code>None</code> attribute is pretty understandable; however, there seems to be confusion around <code>Strict</code> and <code>Lax</code>. Let's dive into a real-world example.</p>\n\n<p>Let's say you are the CEO of TalkToMe, Inc., a feature rich commenting system. You allow your users to embed TalkToMe on their websites and they gain social network integration, advanced moderation options and other extensive community functions. If TalkToMe, Inc.'s first-party cookies are set to <code>Lax</code>, your customers are still able to access their embedded comments. If TalkToMe, Inc.'s first-party cookies are set to <code>Strict</code>, your customers will not be able to access data from an external site.</p>\n<h3 class=\"anchored\">\n  <a name=\"chrome-80-code-samesite-code-update\" href=\"#chrome-80-code-samesite-code-update\">Chrome 80 <code>SameSite</code> update</a>\n</h3>\n\n<p>With the Chrome 51 update, Google gave website developers power to set rules around how cookies are shared; however, many developers don't follow the recommended practice. Instead of leaving the user's cookies exposed to potential security vulnerabilities (allowing third-party requests by default), the Chrome 80 update takes the power back and sets all cookies to <code>SameSite=Lax</code> by default. In other words, Chrome has decided to make all cookies limited to first-party context by default, and will require developers to mark a cookie as needing third-party visibility using <code>SameSite=None</code> explicitly.</p>\n\n<blockquote>\n<p>‚ÄúWe‚Äôve been focused on giving users transparency and choice over how they are tracked on the web through easy to use controls.‚Äù</p>\n<p>- Ben Galbraith, Director, Chrome Product Management</p>\n</blockquote>\n<h3 class=\"anchored\">\n  <a name=\"will-this-change-break-anything\" href=\"#will-this-change-break-anything\">Will this change break anything?</a>\n</h3>\n\n<p>This <code>SameSite</code> update requires explicit labeling for third-party cookies. Cookies that aren‚Äôt labeled appropriately may cease to function in Chrome. Even more than that: all cookies previously set may no longer be accessible.</p>\n<h3 class=\"anchored\">\n  <a name=\"how-many-users-will-this-change-affect\" href=\"#how-many-users-will-this-change-affect\">How many users will this change affect?</a>\n</h3>\n\n<p>According to the online traffic monitor <a href=\"https://gs.statcounter.com/browser-market-share\">StatCounter</a>, Chrome is the most popular web browser, and this change will affect <strong>64%</strong> of the world‚Äôs internet users in 2020. Keep reading to find out how you can keep this change from affecting your users!</p>\n<h3 class=\"anchored\">\n  <a name=\"will-my-website-be-affected\" href=\"#will-my-website-be-affected\">Will my website be affected?</a>\n</h3>\n\n<p>If either of the following is true, you will be affected and you must update your cookies:</p>\n\n<ul>\n<li>If your website integrates with external services for advertising, content recommendations, third-party widgets, social media embeds, or any custom integration that relies on cookies</li>\n<li>If your website uses non-secure (HTTP rather than HTTPS) browser access</li>\n</ul>\n<h2 class=\"anchored\">\n  <a name=\"prepare-for-chrome-80-updates\" href=\"#prepare-for-chrome-80-updates\">Prepare for Chrome 80 updates</a>\n</h2>\n<h3 class=\"anchored\">\n  <a name=\"step-1-enabling-code-samesite-code-chrome-flags-and-test-to-see-if-your-site-faces-potential-code-samesite-code-errors\" href=\"#step-1-enabling-code-samesite-code-chrome-flags-and-test-to-see-if-your-site-faces-potential-code-samesite-code-errors\">Step 1: Enabling <code>SameSite</code> Chrome flags and test to see if your site faces potential <code>SameSite</code> errors</a>\n</h3>\n\n<p>As of Chrome 76, you can enable the new <code>#same-site-by-default-cookies</code> flag and test your site before the February 4, 2020 deadline.</p>\n\n<p>Let's enable the flag:</p>\n\n<ol>\n<li>Go to chrome://flags/\n<img src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1580746066-image-16.png\" alt=\"image-16\">\n</li>\n<li>Enable #same-site-by-default-cookies and #cookies-without-same-site-must-be-secure\n<img src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1580746263-Screen%20Shot%202020-01-09%20at%206.28.20%20PM.png\" alt=\"Screen Shot 2020-01-09 at 6\">\n</li>\n<li>Restart the browser for the changes to take effect.\n<img src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1580746297-Screen%20Shot%202020-01-09%20at%206.26.57%20PM.png\" alt=\"Screen Shot 2020-01-09 at 6\">\n</li>\n<li>Visit your website and see if you can spot error messages in the console of your browser's dev tools.\n<img src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1580746311-Screen%20Shot%202019-12-17%20at%204.44.39%20PM.png\" alt=\"Screen Shot 2019-12-17 at 4\">\n</li>\n</ol>\n\n<p>If you see error messages like the one above, this means your site is not ready for the 2020 Chrome 80 release. You should continue reading to learn how to set your cookies.</p>\n<h3 class=\"anchored\">\n  <a name=\"step-2-fixing-cookie-errors-using-appropriate-attributes\" href=\"#step-2-fixing-cookie-errors-using-appropriate-attributes\">Step 2: Fixing cookie errors using appropriate attributes</a>\n</h3>\n<h4 class=\"anchored\">\n  <a name=\"common-use-cases-auditing-your-cookie-usage\" href=\"#common-use-cases-auditing-your-cookie-usage\">Common use cases: Auditing your cookie usage</a>\n</h4>\n\n<p><a href=\"https://www.chromium.org/updates/same-site\">Chrome</a>, <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#SameSite_cookies\">Firefox</a>, <a href=\"https://blogs.windows.com/msedgedev/2018/05/17/samesite-cookies-microsoft-edge-internet-explorer/\">Edge</a>, and other browsers will also change their default cookie behavior to the following:</p>\n\n<ol>\n<li>Cookies without a <code>SameSite</code> attribute will be treated as <code>SameSite=Lax</code> (See variants below), meaning all cookies will be restricted to first-party context only. <strong>If you need third-party access, you will need to update your cookies.</strong>\n</li>\n<li>Cookies needing third-party access must specify <code>SameSite=None; Secure</code> to enable access.</li>\n</ol>\n\n<p>If you don't know whether you provide cookies that are intended for cross-site usage, some common use-cases are</p>\n\n<ul>\n<li>You present ads on your website.</li>\n<li>You present content in an <code>&lt;iframe&gt;</code>.</li>\n<li>You present content within a WebView.</li>\n<li>You present images from another site on your website.</li>\n<li>You embed content shared from other sites, such as videos, maps, code samples, chat widgets and social post.</li>\n<li>You use third-party services on your website like Facebook, Twitter, Instagram, LinkedIn, Gravatar, Google Calendar, User Tracking (CrazyEgg, Google Analytics, etc.), CRM and/or reservations, booking, anti-fraud and payments services.</li>\n</ul>\n\n<p>üí° NOTE:\nCookie warnings triggered from domains you don't control will need to be set appropriately by the domain owner. If you are getting a warning like this from Google, Google will have to set this cookie appropriately. If the warning messages list a domain you control, you will need to add the correct attributes.  </p>\n\n<pre><code>(index):1 A cookie associated with a resource at http://google.com/ was set with \nSameSite=None but without Secure. A future release of Chrome will only deliver \ncookies marked SameSite=None if they are also marked Secure. You can review cookies\n in developer tools under Application&gt;Storage&gt;Cookies and see more details at \n https://www.chromestatus.com/feature/5633521622188032.\n</code></pre>\n<h4 class=\"anchored\">\n  <a name=\"knowing-which-attribute-to-use\" href=\"#knowing-which-attribute-to-use\">Knowing which attribute to use</a>\n</h4>\n\n<p>First, a quick recap of <code>SameSite</code> attributes:</p>\n\n<table>\n<thead>\n<tr>\n<th>Value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Strict</strong></td>\n<td>Cookies with this setting can be accessed only when visiting the domain from which it was initially set. In other words, <code>Strict</code> completely blocks a cookie being sent to <code>a.com</code> when it is being sent from a page on <code>b.com</code> (i.e. <code>b.com</code> is in the URL bar). Even when clicking a top-level link on a third-party domain to your site, the browser will refuse to send the cookie. This option would be best for applications that require high security, such as banks.</td>\n</tr>\n<tr>\n<td><strong>Lax</strong></td>\n<td>Unlike <code>None</code> where cookies are always sent, <code>Lax</code> cookies are only sent on same-site request like <code>Strict</code>. However,  <code>Lax</code> allows top-level navigation access with a safe HTTP method, like HTTP <code>GET</code>. The cookie will not be sent with cross-domain <code>POST</code> requests or when loading the site in a cross-origin frame, but it will be sent when you navigate to the site via a standard top-level <code>&lt;a href=...&gt;</code> link.</td>\n</tr>\n<tr>\n<td><strong>None</strong></td>\n<td>Cookies with this setting will work the same way as cookies work today. Cookies will be able to be used across sites. üí°Note that you need both the <code>None</code> and <code>Secure</code> attributes together. If you just specify <code>None</code> without <code>Secure</code> the cookie will be rejected. <code>Secure</code> ensures that the browser request is sent by a secure (HTTPS) connection.</td>\n</tr>\n</tbody>\n</table>\n\n<p><strong>üç™ When to use <code>SameSite=Strict</code></strong></p>\n\n<p>Use when the domain in the URL bar equals the cookie‚Äôs domain (first-party) AND the link isn‚Äôt coming from a third-party.</p>\n\n<pre><code>Set-Cookie: first_party_var=value; SameSite=Strict\n</code></pre>\n\n<p><strong>üç™ When to use <code>SameSite=Lax</code></strong></p>\n\n<p>Use when the domain in the URL bar equals the cookie‚Äôs domain (first-party). Note: Third party content (images, iframes, etc.) is allowed.</p>\n\n<pre><code>Set-Cookie: first_party_var=value; SameSite=Lax\n</code></pre>\n\n<p><strong>üç™ When to use <code>SameSite=None; Secure</code></strong></p>\n\n<p>Use when you don't need cross-domain limitations.</p>\n\n<pre><code>Set-Cookie: third_party_var=value; SameSite=None; Secure\n</code></pre>\n\n<p><strong>Common scenarios</strong></p>\n\n<table>\n<thead>\n<tr>\n<th>When to...</th>\n<th>Scenario</th>\n<th>Attribute</th>\n<th>If you do nothing</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Use <code>SameSite=Strict</code></strong></td>\n<td>Your website offers banking services or your website needs a very secure environment</td>\n<td>Update your <code>SameSite</code> attribute to <code>SameSite=Strict</code>  to add a layer of protection from web threats.</td>\n<td>Your site may be susceptible to potential web vulnerabilities and data leaks.</td>\n</tr>\n<tr>\n<td><strong>Use <code>SameSite=Lax</code></strong></td>\n<td>You have a social community website and you offer embedded chat widgets</td>\n<td>Update your <code>SameSite</code> attribute to <code>SameSite=Lax</code>\n</td>\n<td>You'll be good to go. Chrome's default behavior will be <code>SameSite=Lax</code>. Even if <code>SameSite</code> is not set, the default is still <code>SameSite=Lax</code>\n</td>\n</tr>\n<tr>\n<td><strong>Use <code>SameSite=None</code></strong></td>\n<td>Your website offers data analytics services <strong>OR</strong> your website offers retargeting, advertising and conversion tracking.</td>\n<td>Update your <code>SameSite</code> attribute to <code>SameSite=None; Secure</code> to ensure Chrome doesn't reject your third-party cookies.</td>\n<td>Your cookies will no longer work on Feb 4, 2020.</td>\n</tr>\n<tr>\n<td><strong>\"Speak to a representative\"</strong></td>\n<td>You've monetized your website with third-party ad programs <strong>OR</strong> you're utilizing third-party services like Google Calendar, Cloudflare, Facebook, Twitter, Instagram, LinkedIn, Gravatar, User Tracking services, CRM, reservations plugin, anti-fraud, third-party fonts, image/video hosting and/or payments services.</td>\n<td>Speak with the ad program company to ensure they have a plan to update their cookies. You can't update cookies on a domain you don't control.</td>\n<td>You may see a decline in the ad revenue you receive and or business engagement.</td>\n</tr>\n</tbody>\n</table>\n<h4 class=\"anchored\">\n  <a name=\"now-set-your-cookies\" href=\"#now-set-your-cookies\">Now, set your cookies</a>\n</h4>\n\n<p>Most server-side applications support <code>SameSite</code> attributes; however, there are a few clients who don't support it (see <a href=\"https://www.chromium.org/updates/same-site/incompatible-clients\"><strong>Known Incompatible Clients</strong></a>).</p>\n\n<ul>\n<li>\n<strong>For Server-Side Applications</strong>: Support for <code>SameSite=None</code> in languages, libraries, and frameworks\n\n<ul>\n<li><a href=\"https://github.com/GoogleChromeLabs/samesite-examples/blob/master/php.md\">PHP</a></li>\n<li><a href=\"https://github.com/GoogleChromeLabs/samesite-examples/blob/master/javascript-nodejs.md\">NodeJS</a></li>\n<li><a href=\"https://github.com/GoogleChromeLabs/samesite-examples/blob/master/python.md\">Python</a></li>\n<li><a href=\"https://github.com/GoogleChromeLabs/samesite-examples/blob/master/python-flask.md\">Python Flask</a></li>\n<li>\n<a href=\"https://api.rubyonrails.org/classes/ActionDispatch/Cookies.html\">Ruby on Rails</a>\n\n<ul>\n<li>Recent pull request: <a href=\"https://github.com/rails/rails/pull/28297\">https://github.com/rails/rails/pull/28297</a>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<strong>Directly</strong>: <code>document.cookie</code>\n\n<ul>\n<li><a href=\"https://github.com/GoogleChromeLabs/samesite-examples/blob/master/javascript.md\">JavaScript</a></li>\n</ul>\n</li>\n</ul>\n<h2 class=\"anchored\">\n  <a name=\"need-more-help\" href=\"#need-more-help\">Need more help?</a>\n</h2>\n\n<p>Rowan Merewood, Developer Advocate for Chrome, listed a few helpful ways to get help with setting cookies. Keep in mind, this will be a new update so if you run into an issue, it may be the first time anyone has encountered the issue. It is best to just raise the issue, be vocal, and publicly address your concerns because someone else is very likely to encounter the same issue!</p>\n\n<ul>\n<li>Raise an issue on the <a href=\"https://github.com/GoogleChromeLabs/samesite-examples\"><code>SameSite</code> examples repo on GitHub</a>.</li>\n<li>Post a question on the <a href=\"https://stackoverflow.com/questions/tagged/samesite\">\"samesite\" tag on StackOverflow</a>.</li>\n<li>For issues with Chromium's behavior, raise a bug via the <a href=\"https://bit.ly/2lJMd5c\">[<code>SameSite</code> cookies] issue template</a>.</li>\n<li>Follow Chrome's progress on the <a href=\"https://www.chromium.org/updates/same-site\"><code>SameSite</code> updates page</a>.</li>\n</ul>","PublishedAt":"2020-02-03 21:30:00+00:00","OriginURL":"https://blog.heroku.com/chrome-changes-samesite-cookie","SourceName":"Heroku"}},{"node":{"ID":641,"Title":"Meet us at A New Dawn, IxDA20 in Milan, Italy","Description":"","PublishedAt":"2020-01-31 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2020-01-31-findusatanewdawnixda20inmilanitaly/","SourceName":"Trivago"}},{"node":{"ID":813,"Title":"Speeding Up Builds with Dagger Reflect","Description":"A large portion of an Android app‚Äôs build time can consist of Dagger annotation processing, and most developers agree that productivity is‚Ä¶","PublishedAt":"2020-01-30 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/dagger-reflect","SourceName":"Soundcloud"}},{"node":{"ID":642,"Title":"trivago Magazine's Journey to Server-Side Rendering","Description":"","PublishedAt":"2020-01-29 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2020-01-29-trivagomagazinesjourneytoserversiderende/","SourceName":"Trivago"}},{"node":{"ID":643,"Title":"Meet us at FOSDEM, Brussels, Belgium","Description":"","PublishedAt":"2020-01-28 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2020-01-28-fosdem/","SourceName":"Trivago"}},{"node":{"ID":381,"Title":"Five things I learned about working on content quality at Instagram","Description":"","PublishedAt":"2020-01-25 01:13:36+00:00","OriginURL":"https://instagram-engineering.com/five-things-i-learned-about-working-on-content-quality-at-instagram-5031b1342bea?source=rss----37dc2a3034f2---4","SourceName":"Instagram"}},{"node":{"ID":814,"Title":"The Power of Types for¬†Errors","Description":"At KotlinConf 2019, I talked about the power of types. In essence, I discussed limiting the number of primitives we use in our code in favor‚Ä¶","PublishedAt":"2020-01-20 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/power-of-types-for-errors","SourceName":"Soundcloud"}},{"node":{"ID":366,"Title":"Terrier: An Open-Source Tool for Identifying and Analyzing Container and Image Components","Description":"<style scoped>\n@media only screen and\n  (min-width: 415px) {\n    #cover-image { width: 70%; }\n}\n\n@media only screen and\n  (max-width: 414px) \n  and (orientation: portrait) { \n    #cover-image { width: 100%; }\n}\n</style>\n\n<p>As part of our Blackhat Europe talk <a href=\"https://www.blackhat.com/eu-19/briefings/schedule/#reverse-engineering-and-exploiting-builds-in-the-cloud-17287\">‚ÄúReverse Engineering and Exploiting Builds in the Cloud‚Äù</a> we publicly released a new tool called Terrier. </p>\n\n<figure style=\"text-align: center;\">\n<img id=\"cover-image\" src=\"https://heroku-blog-files.s3.amazonaws.com/posts/1578942799-terrier-twitter.png\" alt=\"Announcing Terrier: An open-source tool for identifying and analysing container and image components\">\n<figcaption>Announcing Terrier: An open-source tool for identifying and analysing container and image components.</figcaption>\n</figure>\n\n<p>In this blog post, I am going to show you how Terrier can help you identify and verify container and image components for a wide variety of use-cases, be it from a supply-chain perspective or forensics perspective. Terrier can be found on Github <a href=\"https://github.com/heroku/terrier\">https://github.com/heroku/terrier</a>.</p>\n<h2 class=\"anchored\">\n  <a name=\"containers-and-images\" href=\"#containers-and-images\">Containers and images</a>\n</h2>\n\n<p>In this blog post, I am not going to go into too much detail about containers and images (you can learn more <a href=\"https://www.opencontainers.org/about\">here</a>) however it is important to highlight a few characteristics of containers and images that make them interesting in terms of Terrier. Containers are run from images and currently the Open Containers Initiative (OCI) is the most popular format for images. The remainder of this blog post refers to OCI images as images.</p>\n\n<p>Essentially images are tar archives that container multiple tar archives and meta-information that represent the ‚Äúlayers‚Äù of an image. The OCI format of images makes images relatively simple to work with which makes analysis relatively simple. If you only had access to a terminal and the tar command, you could pretty much get what you need from the image‚Äôs tar archive.</p>\n\n<p>When images are utilised at runtime for a container, their contents become the contents of the running container and the layers are essentially extracted to a location on the container‚Äôs runtime host. The container runtime host is the host that is running and maintaining the containers. This location is typically <code>/var/lib/docker/overlay2/&lt;containerID&gt;/</code>. This location contains a few folders of interest, particularly the \"merged\" folder. The \"merged\" folder contains the contents of the image and any changes that have occurred in the container since its creation. For example, if the image contained a location such as <code>/usr/chris/stuff</code> and after creating a container from this image I created a file called <code>helloworld.txt</code> at the location <code>/usr/chris/stuff</code>. This would result in the following valid path on the container runtime host <code>/var/lib/docker/overlay2/&lt;containerID&gt;/merged/usr/chris/stuff/helloworld.txt</code>.</p>\n<h2 class=\"anchored\">\n  <a name=\"what-does-terrier-do\" href=\"#what-does-terrier-do\">What does Terrier do?</a>\n</h2>\n\n<p>Now that we have a brief understanding of images and containers, we can look at what Terrier does. Often it is the case that you would like to determine if an image or container contains a specific file. This requirement may be due to a forensic analysis need or to identify and prevent a certain supply-chain attack vector. Regardless of the requirement, having the ability to determine the presence of a specific file in an image or container is useful.</p>\n<h3 class=\"anchored\">\n  <a name=\"identifying-files-in-oci-images\" href=\"#identifying-files-in-oci-images\">Identifying files in OCI images</a>\n</h3>\n\n<p>Terrier can be used to determine if a specific image contains a specific file. In order to do this, you need the following:</p>\n\n<ol>\n<li>An OCI Image i.e TAR archive</li>\n<li>A SHA256 hash of a specific file/s</li>\n</ol>\n\n<p>The first point can be easily achieved with Docker by using the following command:</p>\n\n<pre><code class=\"language-term\">$ docker save imageid -o myImage.tar\n</code></pre>\n\n<p>The command above uses a Docker image ID which can be obtained using the following command:</p>\n\n<pre><code class=\"language-term\">$ docker images\n</code></pre>\n\n<p>Once you have your image exported as a tar archive, you will then need to establish the SHA256 hash of the particular file you would like to identify in the image. There are multiple ways to achieve this but in this example, we are going to use the hash of the Golang binary <em>go1.13.4 linux/amd64</em> which can be achieved with following command on a Linux host:</p>\n\n<pre><code class=\"language-term\">$ cat /usr/local/go/bin/go | sha256sum\n</code></pre>\n\n<p>The command above should result in the following SHA256 hash: <code>82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91dd3ff92dd</code></p>\n\n<p>Now that we have a hash, we can use this hash to determine if the Golang binary is in the image <code>myImage.tar</code>. To achieve this, we need to populate a configuration file for Terrier. Terrier makes use of YAML configuration files and below is our config file that we save as <code>cfg.yml</code>:</p>\n\n<pre><code class=\"language-yaml\">mode: image\nimage: myImage.tar\n\nhashes:\n    - hash: '82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91dd3ff92dd'\n</code></pre>\n\n<p>The config file above has multiple entries which allow us to specify the <code>mode</code> that Terrier will operate in and in this case, we are working with an image file (tar archive) so the mode is <code>image</code>. The image file we are working with is <code>myImage.tar</code> and the hash we are looking to identify is in the <code>hashes</code> list.</p>\n\n<p>We are now ready to run Terrier and this can be done with the following command:</p>\n\n<pre><code class=\"language-term\">$ ./terrier\n</code></pre>\n\n<p>The command above should result in output similar to the following:</p>\n\n<pre><code class=\"language-term\">$ ./terrier \n[+] Loading config:  cfg.yml\n[+] Analysing Image\n[+] Docker Image Source:  myImage.tar\n[*] Inspecting Layer:  34a9e0f17132202a82565578a3c2dae1486bb198cde76928c8c2c5c461e11ccf\n[*] Inspecting Layer:  6539a80dd09da08132a525494ff97e92f4148d413e7c48b3583883fda8a40560\n[*] Inspecting Layer:  6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759\n[!] Found file '6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759/usr/local/go/bin/go' with hash: 82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91dd3ff92dd\n[*] Inspecting Layer:  a6e646c34d2d2c2f4ab7db95e4c9f128721f63c905f107887839d3256f1288e1\n[*] Inspecting Layer:  aefc8f0c87a14230e30e510915cbbe13ebcabd611e68db02b050b6ceccf9c545\n[*] Inspecting Layer:  d4468fff8d0f28d87d48f51fc0a6afd4b38946bbbe91480919ebfdd55e43ce8c\n[*] Inspecting Layer:  dbf9da5e4e5e1ecf9c71452f6b67b2b0225cec310a20891cc5dedbfd4ead667c\n</code></pre>\n\n<p>We have identified a file <code>/usr/local/go/bin/go</code> located at layer <code>6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759</code> that has the same SHA256 hash as the one we provided. We now have verification that the image ‚ÄúmyImage.tar‚Äù contains a file with the SHA256 hash we provided.</p>\n\n<p>This example can be extended upon and you can instruct Terrier to search for multiple hashes. In this case, we are going to search for a malicious file. Recently a malicious Python library was identified in the wild and went by the name ‚ÄúJeilyfish‚Äù. Terrier could be used to check if a Docker image of yours contained this malicious package. To do this, we can determine the SHA256 of one of the malicious Python files that contains the backdoor:</p>\n\n<pre><code class=\"language-term\">$ cat jeIlyfish-0.7.1/jeIlyfish/_jellyfish.py | sha256sum\ncf734865dd344cd9b0b349cdcecd83f79a751150b5fd4926f976adddb93d902c\n</code></pre>\n\n<p>We then update our Terrier config to include the hash calculated above.</p>\n\n<pre><code class=\"language-yaml\">mode: image\nimage: myImage.tar\n\nhashes:\n    - hash: '82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91dd3ff92dd'\n    - hash: 'cf734865dd344cd9b0b349cdcecd83f79a751150b5fd4926f976adddb93d902c'\n</code></pre>\n\n<p>We then run Terrier against and analyse the results:</p>\n\n<pre><code class=\"language-term\">$ ./terrier \n[+] Loading config:  cfg.yml\n[+] Analysing Image\n[+] Docker Image Source:  myImage.tar\n[*] Inspecting Layer:  34a9e0f17132202a82565578a3c2dae1486bb198cde76928c8c2c5c461e11ccf\n[*] Inspecting Layer:  6539a80dd09da08132a525494ff97e92f4148d413e7c48b3583883fda8a40560\n[*] Inspecting Layer:  6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759\n[!] Found file '6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759/usr/local/go/bin/go' with hash: 82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91dd3ff92dd\n[*] Inspecting Layer:  a6e646c34d2d2c2f4ab7db95e4c9f128721f63c905f107887839d3256f1288e1\n[*] Inspecting Layer:  aefc8f0c87a14230e30e510915cbbe13ebcabd611e68db02b050b6ceccf9c545\n[*] Inspecting Layer:  d4468fff8d0f28d87d48f51fc0a6afd4b38946bbbe91480919ebfdd55e43ce8c\n[*] Inspecting Layer:  dbf9da5e4e5e1ecf9c71452f6b67b2b0225cec310a20891cc5dedbfd4ead667c\n</code></pre>\n\n<p>The results above indicate that our image did not contain the malicious Python package.</p>\n\n<p>There is no limit as to how many hashes you can search for however it should be noted that Terrier performs all its actions in-memory for performance reasons so you might hit certain limits if you do not have enough accessible memory.</p>\n<h3 class=\"anchored\">\n  <a name=\"identifying-and-verifying-specific-files-in-oci-images\" href=\"#identifying-and-verifying-specific-files-in-oci-images\">Identifying and verifying specific files in OCI images</a>\n</h3>\n\n<p>Terrier can also be used to determine if a specific image contains a specific file <em>at a specific location</em>. This can be useful to ensure that an image is using a specific component i.e binary, shared object or dependency.  This can also be seen as ‚Äúpinning‚Äù components by ensuring that you are images are using specific components i.e a specific version of cURL.</p>\n\n<p>In order to do this, you need the following:</p>\n\n<ol>\n<li>An OCI Image i.e TAR archive</li>\n<li>A SHA256 hash of a specific file/s</li>\n<li>The path and name of the specific file/s</li>\n</ol>\n\n<p>The first point can be easily achieved with Docker by using the following command:</p>\n\n<pre><code class=\"language-term\">$ docker save imageid -o myImage.tar\n</code></pre>\n\n<p>The command above utilises a Docker image id which can be obtained using the following command:</p>\n\n<pre><code class=\"language-term\">$ docker images\n</code></pre>\n\n<p>Once you have your image exported as a tar archive, you will need to determine the path of the file you would like to identify and verify in the image. For example, if we would like to ensure that our images are making use of a specific version of cURL, we can run the following commands in a container or some other environment that resembles the image.</p>\n\n<pre><code class=\"language-term\">$ which curl\n/usr/bin/curl\n</code></pre>\n\n<p>We now have the path to cURL and can now generate the SHA256 of this instance of cURL because in this case, we trust this instance of cURL. We could determine the hash by other means for example many binaries are released with a corresponding hash from the developer which can be acquired from the developer‚Äôs website.</p>\n\n<pre><code class=\"language-term\">$ cat /usr/bin/curl | sha256sum \n9a43cb726fef31f272333b236ff1fde4beab363af54d0bc99c304450065d9c96\n</code></pre>\n\n<p>With this information, we can now populate our config file for Terrier:</p>\n\n<pre><code class=\"language-yaml\">mode: image\nimage: myImage.tar\nfiles:\n  - name: '/usr/bin/curl'\n    hashes:\n      - hash: '9a43cb726fef31f272333b236ff1fde4beab363af54d0bc99c304450065d9c96'\n</code></pre>\n\n<p>We‚Äôve saved the above config as <code>cfg.yml</code> and when we run Terrier with this config, we get the following output:</p>\n\n<pre><code class=\"language-term\">$ ./terrier\n[+] Loading config:  cfg.yml\n[+] Analysing Image\n[+] Docker Image Source:  myImage.tar\n[*] Inspecting Layer:  34a9e0f17132202a82565578a3c2dae1486bb198cde76928c8c2c5c461e11ccf\n[*] Inspecting Layer:  34a9e0f17132202a82565578a3c2dae1486bb198cde76928c8c2c5c461e11ccf\n[*] Inspecting Layer:  6539a80dd09da08132a525494ff97e92f4148d413e7c48b3583883fda8a40560\n[*] Inspecting Layer:  6539a80dd09da08132a525494ff97e92f4148d413e7c48b3583883fda8a40560\n[*] Inspecting Layer:  6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759\n[*] Inspecting Layer:  6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759\n[*] Inspecting Layer:  a6e646c34d2d2c2f4ab7db95e4c9f128721f63c905f107887839d3256f1288e1\n[*] Inspecting Layer:  a6e646c34d2d2c2f4ab7db95e4c9f128721f63c905f107887839d3256f1288e1\n[*] Inspecting Layer:  aefc8f0c87a14230e30e510915cbbe13ebcabd611e68db02b050b6ceccf9c545\n[*] Inspecting Layer:  aefc8f0c87a14230e30e510915cbbe13ebcabd611e68db02b050b6ceccf9c545\n[*] Inspecting Layer:  d4468fff8d0f28d87d48f51fc0a6afd4b38946bbbe91480919ebfdd55e43ce8c\n[*] Inspecting Layer:  d4468fff8d0f28d87d48f51fc0a6afd4b38946bbbe91480919ebfdd55e43ce8c\n[*] Inspecting Layer:  dbf9da5e4e5e1ecf9c71452f6b67b2b0225cec310a20891cc5dedbfd4ead667c\n[*] Inspecting Layer:  dbf9da5e4e5e1ecf9c71452f6b67b2b0225cec310a20891cc5dedbfd4ead667c\n[!] All components were identified: (1/1)\n[!] All components were identified and verified: (1/1)\n$ echo $?\n0\n</code></pre>\n\n<p>The output above indicates that the file <code>/usr/bin/curl</code> was successfully identified and verified, meaning that the image contained a file at the location <code>/usr/bin/curl</code> and that the SHA256 of that file matched the hash we provided in the config. Terrier also makes use of return codes and if we analyse the return code from the output above, we can see that the value is <code>0</code> which indicates a success. If Terrier cannot identify or verify all the provided files, a return code of <code>1</code> is returned which indicates a failure. The setting of return codes is particularly useful in testing environments or CI/CD environments.</p>\n\n<p>We can also run Terrier with verbose mode enable to get more information:</p>\n\n<pre><code class=\"language-term\">$ ./terrier \n[+] Loading config:  cfg.yml\n[+] Analysing Image\n[+] Docker Image Source:  myImage.tar\n[*] Inspecting Layer:  34a9e0f17132202a82565578a3c2dae1486bb198cde76928c8c2c5c461e11ccf\n[*] Inspecting Layer:  6539a80dd09da08132a525494ff97e92f4148d413e7c48b3583883fda8a40560\n        [!] Identified  instance of '/usr/bin/curl' at: 6539a80dd09da08132a525494ff97e92f4148d413e7c48b3583883fda8a40560/usr/bin/curl \n        [!] Verified matching instance of '/usr/bin/curl' at: 6539a80dd09da08132a525494ff97e92f4148d413e7c48b3583883fda8a40560/usr/bin/curl with hash: 9a43cb726fef31f272333b236ff1fde4beab363af54d0bc99c304450065d9c96\n[*] Inspecting Layer:  6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759\n[*] Inspecting Layer:  a6e646c34d2d2c2f4ab7db95e4c9f128721f63c905f107887839d3256f1288e1\n[*] Inspecting Layer:  aefc8f0c87a14230e30e510915cbbe13ebcabd611e68db02b050b6ceccf9c545\n[*] Inspecting Layer:  d4468fff8d0f28d87d48f51fc0a6afd4b38946bbbe91480919ebfdd55e43ce8c\n[*] Inspecting Layer:  dbf9da5e4e5e1ecf9c71452f6b67b2b0225cec310a20891cc5dedbfd4ead667c\n[!] All components were identified: (1/1)\n[!] All components were identified and verified: (1/1)\n</code></pre>\n\n<p>The output above provides some more detailed information such as which layer the cURL files was located at. If you wanted more information, you could enable the <strong>veryveryverbose</strong> option in the config file but beware, this is a lot of output and grep will be your friend.</p>\n\n<p>There is no limit for how many hashes you can specify for a file. This can be useful for when you want to allow more than one version of a specific file i.e multiple versions of cURL. An example config of multiple hashes for a file might look like:</p>\n\n<pre><code class=\"language-yaml\">mode: image\nimage: myImage.tar\nfiles:\n  - name: '/usr/bin/curl'\n    hashes:\n      - hash: '9a43cb726fef31f272333b236ff1fde4beab363af54d0bc99c304450065d9c96'\n      - hash: 'aefc8f0c87a14230e30e510915cbbe13ebcabd611e68db02b050b6ceccf9c545'\n      - hash: '6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759'\n      - hash: 'd4468fff8d0f28d87d48f51fc0a6afd4b38946bbbe91480919ebfdd55e43ce8c'\n</code></pre>\n\n<p>The config above allows Terrier to verify if the identified cURL instance is one of the provided hashes. There is also no limit for the amount of files Terrier can attempt to identify and verify.</p>\n\n<p>Terrier‚Äôs Github repo also contains a useful script called <code>convertSHA.sh</code> which can be used to convert a list of SHA256 hashes and filenames into a Terrier config file. This is useful when converting the output from other tools into a Terrier friendly format. For example, we could have the following contents of a file:</p>\n\n<pre><code>8946690bfe12308e253054ea658b1552c02b67445763439d1165c512c4bc240d ./bin/uname\n6de8254cfd49543097ae946c303602ffd5899b2c88ec27cfcd86d786f95a1e92 ./bin/gzexe\n74ff9700d623415bc866c013a1d8e898c2096ec4750adcb7cd0c853b4ce11c04 ./bin/wdctl\n61c779de6f1b9220cdedd7dfee1fa4fb44a4777fff7bd48d12c21efb87009877 ./bin/dmesg\n7bdde142dc5cb004ab82f55adba0c56fc78430a6f6b23afd33be491d4c7c238b ./bin/which\n3ed46bd8b4d137cad2830974a78df8d6b1d28de491d7a23d305ad58742a07120 ./bin/mknod\ne8ca998df296413624b2bcf92a31ee3b9852f7590f759cc4a8814d3e9046f1eb ./bin/mv\na91d40b349e2bccd3c5fe79664e70649ef0354b9f8bd4658f8c164f194b53d0f ./bin/chown\n091abe52520c96a75cf7d4ff38796fc878cd62c3a75a3fd8161aa3df1e26bebd ./bin/uncompress\nc5ebd611260a9057144fd1d7de48dbefc14e16240895cb896034ae05a94b5750 ./bin/echo\nd4ba9ffb5f396a2584fec1ca878930b677196be21aee16ee6093eb9f0a93bf8f ./bin/df\n5fb515ff832650b2a25aeb9c21f881ca2fa486900e736dfa727a5442a6de83e5 ./bin/tar\n6936c9aa8e17781410f286bb1cbc35b5548ea4e7604c1379dc8e159d91a0193d ./bin/zforce\n8d641329ea7f93b1caf031b70e2a0a3288c49a55c18d8ba86cc534eaa166ec2e ./bin/gzip\n0c1a1f53763ab668fb085327cdd298b4a0c1bf2f0b51b912aa7bc15392cd09e7 ./bin/su\n20c358f7ee877a3fd2138ecce98fada08354810b3e9a0e849631851f92d09cc4 ./bin/bzexe\n01764d96697b060b2a449769073b7cf2df61b5cb604937e39dd7a47017e92ee0 ./bin/znew\n0d1a106dc28c3c41b181d3ba2fc52086ede4e706153e22879e60e7663d2f6aad ./bin/login\nfb130bda68f6a56e2c2edc3f7d5b805fd9dcfbcc26fb123a693b516a83cfb141 ./bin/dir\n0e7ca63849eebc9ea476ea1fefab05e60b0ac8066f73c7d58e8ff607c941f212 ./bin/bzmore\n14dc8106ec64c9e2a7c9430e1d0bef170aaad0f5f7f683c1c1810b466cdf5079 ./bin/zless\n9cf4cda0f73875032436f7d5c457271f235e59c968c1c101d19fc7bf137e6e37 ./bin/chmod\nc5f12f157b605b1141e6f97796732247a26150a0a019328d69095e9760b42e38 ./bin/sleep\nb9711301d3ab42575597d8a1c015f49fddba9a7ea9934e11d38b9ff5248503a8 ./bin/zfgrep\n0b2840eaf05bb6802400cc5fa793e8c7e58d6198334171c694a67417c687ffc7 ./bin/stty\nd9393d0eca1de788628ad0961b74ec7a648709b24423371b208ae525f60bbdad ./bin/bunzip2\nd2a56d64199e674454d2132679c0883779d43568cd4c04c14d0ea0e1307334cf ./bin/mkdir\n1c48ade64b96409e6773d2c5c771f3b3c5acec65a15980d8dca6b1efd3f95969 ./bin/cat\n09198e56abd1037352418279eb51898ab71cc733642b50bcf69d8a723602841e ./bin/true\n97f3993ead63a1ce0f6a48cda92d6655ffe210242fe057b8803506b57c99b7bc ./bin/zdiff\n0d06f9724af41b13cdacea133530b9129a48450230feef9632d53d5bbb837c8c ./bin/ls\nda2da96324108bbe297a75e8ebfcb2400959bffcdaa4c88b797c4d0ce0c94c50 ./bin/zegrep\n</code></pre>\n\n<p>The file contents above are trusted SHA256 hashes for specific files. If we would like to use this list for ensuring that a particular image is making use of the files listed above, we can do the following:</p>\n\n<pre><code class=\"language-term\">$ ./convertSHA.sh trustedhashes.txt terrier.yml\n</code></pre>\n\n<p>The script above takes the input file <code>trustedhashes.txt</code> which contains our trusted hashes listed above and converts them into a Terrier friendly config file called <code>terrier.yml</code> which looks like the following:</p>\n\n<pre><code class=\"language-yaml\">mode: image\nimage: myImage.tar\nfiles:\n  - name: '/bin/uname'\n    hashes:\n       - hash: '8946690bfe12308e253054ea658b1552c02b67445763439d1165c512c4bc240d'\n  - name: '/bin/gzexe'\n    hashes:\n       - hash: '6de8254cfd49543097ae946c303602ffd5899b2c88ec27cfcd86d786f95a1e92'\n  - name: '/bin/wdctl'\n    hashes:\n       - hash: '74ff9700d623415bc866c013a1d8e898c2096ec4750adcb7cd0c853b4ce11c04'\n  - name: '/bin/dmesg'\n    hashes:\n       - hash: '61c779de6f1b9220cdedd7dfee1fa4fb44a4777fff7bd48d12c21efb87009877'\n  - name: '/bin/which'\n    hashes:\n       - hash: '7bdde142dc5cb004ab82f55adba0c56fc78430a6f6b23afd33be491d4c7c238b'\n  - name: '/bin/mknod'\n</code></pre>\n\n<p>The config file <code>terrier.yml</code> is ready to be used:</p>\n\n<pre><code class=\"language-term\">$ ./terrier -cfg=terrier.yml\n[+] Loading config:  terrier.yml\n[+] Analysing Image\n[+] Docker Image Source:  myImage.tar\n[*] Inspecting Layer:  34a9e0f17132202a82565578a3c2dae1486bb198cde76928c8c2c5c461e11ccf\n[*] Inspecting Layer:  6539a80dd09da08132a525494ff97e92f4148d413e7c48b3583883fda8a40560\n[*] Inspecting Layer:  6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759\n[*] Inspecting Layer:  a6e646c34d2d2c2f4ab7db95e4c9f128721f63c905f107887839d3256f1288e1\n[*] Inspecting Layer:  aefc8f0c87a14230e30e510915cbbe13ebcabd611e68db02b050b6ceccf9c545\n[*] Inspecting Layer:  d4468fff8d0f28d87d48f51fc0a6afd4b38946bbbe91480919ebfdd55e43ce8c\n[*] Inspecting Layer:  dbf9da5e4e5e1ecf9c71452f6b67b2b0225cec310a20891cc5dedbfd4ead667c\n[!] Not all components were identifed: (4/31)\n[!] Component not identified:  /bin/uncompress\n[!] Component not identified:  /bin/bzexe\n[!] Component not identified:  /bin/bzmore\n[!] Component not identified:  /bin/bunzip2\n$ echo $?\n1\n</code></pre>\n\n<p>As we can see from the output above, Terrier was unable to identify 4/31 of the components provided in the config. The return code is also 1 which indicates a failure. If we were to remove the components that are not in the provided image, the output from the previous command would look like the following:</p>\n\n<pre><code class=\"language-term\">$ ./terrier -cfg=terrier.yml\n[+] Loading config: terrier.yml\n[+] Analysing Image\n[+] Docker Image Source: myImage.tar\n[*] Inspecting Layer: 34a9e0f17132202a82565578a3c2dae1486bb198cde76928c8c2c5c461e11ccf\n[*] Inspecting Layer: 6539a80dd09da08132a525494ff97e92f4148d413e7c48b3583883fda8a40560\n[*] Inspecting Layer: 6d2d61c78a65b6e6c82b751a38727da355d59194167b28b3f8def198cd116759\n[*] Inspecting Layer: a6e646c34d2d2c2f4ab7db95e4c9f128721f63c905f107887839d3256f1288e1\n[*] Inspecting Layer: aefc8f0c87a14230e30e510915cbbe13ebcabd611e68db02b050b6ceccf9c545\n[*] Inspecting Layer: d4468fff8d0f28d87d48f51fc0a6afd4b38946bbbe91480919ebfdd55e43ce8c\n[*] Inspecting Layer: dbf9da5e4e5e1ecf9c71452f6b67b2b0225cec310a20891cc5dedbfd4ead667c\n[!] All components were identified: (27/27)\n[!] Not all components were verified: (26/27)\n[!] Component not verified: /bin/cat\n[!] Component not verified: /bin/chmod\n[!] Component not verified: /bin/chown\n[!] Component not verified: /bin/df\n[!] Component not verified: /bin/dir\n[!] Component not verified: /bin/dmesg\n[!] Component not verified: /bin/echo\n[!] Component not verified: /bin/gzexe\n[!] Component not verified: /bin/gzip\n[!] Component not verified: /bin/login\n[!] Component not verified: /bin/ls\n[!] Component not verified: /bin/mkdir\n[!] Component not verified: /bin/mknod\n[!] Component not verified: /bin/mv\n[!] Component not verified: /bin/sleep\n[!] Component not verified: /bin/stty\n[!] Component not verified: /bin/su\n[!] Component not verified: /bin/tar\n[!] Component not verified: /bin/true\n[!] Component not verified: /bin/uname\n[!] Component not verified: /bin/wdctl\n[!] Component not verified: /bin/zdiff\n[!] Component not verified: /bin/zfgrep\n[!] Component not verified: /bin/zforce\n[!] Component not verified: /bin/zless\n[!] Component not verified: /bin/znew\n$ echo $?\n1\n</code></pre>\n\n<p>The output above indicates that Terrier was able to identify all the components provided but many were not verifiable, the hashes did not match and once again, the return code is <code>1</code> to indicate this failure.</p>\n<h3 class=\"anchored\">\n  <a name=\"identifying-files-in-containers\" href=\"#identifying-files-in-containers\">Identifying files in containers</a>\n</h3>\n\n<p>The previous sections focused on identifying files in images, which can be referred to as a form of ‚Äústatic analysis,‚Äù however it is also possible to perform this analysis to running containers. In order to do this, you need the following:</p>\n\n<ol>\n<li>Location of the container‚Äôs <code>merged</code> folder </li>\n<li>A SHA256 hash of a specific file/s</li>\n</ol>\n\n<p>The <code>merged</code> folder is Docker specific, in this case, we are using it because this is where the contents of the Docker container reside, this might be another location if it were LXC.</p>\n\n<p>The location of the container‚Äôs <code>merged</code> folder can be determined by running the following commands. First obtain the container‚Äôs ID:</p>\n\n<pre><code class=\"language-term\">$ docker ps\nCONTAINER ID        IMAGE                    COMMAND               CREATED             STATUS              PORTS               NAMES\nb9e676fd7b09        golang                   \"bash\"                20 hours ago        Up 20 hours                             cocky_robinson\n</code></pre>\n\n<p>Once you have the container‚Äôs ID, you can run the following command which will help you identify the location of the container‚Äôs <code>merged</code> folder on the underlying host.</p>\n\n<pre><code class=\"language-term\">$ docker exec b9e676fd7b09 mount | grep diff\noverlay on / type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/7ZDEFE6PX4C3I3LGIGGI5MWQD4:\n/var/lib/docker/overlay2/l/EZNIFFIXOVO2GIT5PTBI754HC4:/var/lib/docker/overlay2/l/UWKXP76FVZULHGRKZMVYJHY5IK:\n/var/lib/docker/overlay2/l/DTQQUTRXU4ZLLQTMACWMJYNRTH:/var/lib/docker/overlay2/l/R6DE2RY63EJABTON6HVSFRFICC:\n/var/lib/docker/overlay2/l/U4JNTFLQEKMFHVEQJ5BQDLL7NO:/var/lib/docker/overlay2/l/FEBURQY25XGHJNPSFY5EEPCFKA:\n/var/lib/docker/overlay2/l/ICNMAZ44JY5WZQTFMYY4VV6OOZ,\nupperdir=/var/lib/docker/overlay2/04f84ddd30a7df7cd3f8b1edeb4fb89d476ed84cf3f76d367e4ebf22cd1978a4/diff,\nworkdir=/var/lib/docker/overlay2/04f84ddd30a7df7cd3f8b1edeb4fb89d476ed84cf3f76d367e4ebf22cd1978a4/work)          \n</code></pre>\n\n<p>From the results above, we are interested in two entries, <code>upperdir</code> and <code>workdir</code> because these two entries will provide us with the path to the container‚Äôs <code>merged</code> folder. From the results above, we can determine that the container‚Äôs <code>merged</code> directory is located at <code>/var/lib/docker/overlay2/04f84ddd30a7df7cd3f8b1edeb4fb89d476ed84cf3f76d367e4ebf22cd1978a4/</code> on the underlying host.</p>\n\n<p>Now that we have the location, we need some files to identify and in this case, we are going to reuse the SHA256 hashes from the previous section. Let‚Äôs now go ahead and populate our Terrier configuration with this new information.</p>\n\n<pre><code class=\"language-yaml\">mode: container\npath: merged\n#image: myImage.tar\n\nhashes:\n    - hash: '82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91dd3ff92dd'\n    - hash: 'cf734865dd344cd9b0b349cdcecd83f79a751150b5fd4926f976adddb93d902c'\n</code></pre>\n\n<p>The configuration above shows that we have changed the <code>mode</code> from <code>image</code> to <code>container</code> and we have added the <code>path</code> to our <code>merged</code> folder. We have kept the two hashes from the previous section. </p>\n\n<p>If we run Terrier with this configuration from the location <code>/var/lib/docker/overlay2/04f84ddd30a7df7cd3f8b1edeb4fb89d476ed84cf3f76d367e4ebf22cd1978a4/</code>, we get the following output:</p>\n\n<pre><code class=\"language-term\">$ ./terrier\n[+] Loading config: cfg.yml\n[+] Analysing Container\n[!] Found matching instance of '82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91dd3ff92dd' at: merged/usr/local/go/bin/go with hash:82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91dd3ff92dd\n</code></pre>\n\n<p>From the output above, we know that the container (<code>b9e676fd7b09</code>) does not contain the malicious Python package but it does contain an instance of the Golang binary which is located at <code>merged/usr/local/go/bin/go</code>.</p>\n<h3 class=\"anchored\">\n  <a name=\"identifying-and-verifying-specific-files-in-containers\" href=\"#identifying-and-verifying-specific-files-in-containers\">Identifying and verifying specific files in containers</a>\n</h3>\n\n<p>And as you might have guessed, Terrier can also be used to verify and identify files at specific paths in containers. To do this, we need the following:</p>\n\n<ol>\n<li>Location of the container‚Äôs <code>merged</code> folder </li>\n<li>A SHA256 hash of a specific file/s</li>\n<li>The path and name of the specific file/s</li>\n</ol>\n\n<p>The points above can be determined using the same procedures described in the previous sections. Below is an example Terrier config file that we could use to identify and verify components in a running container:</p>\n\n<pre><code class=\"language-yaml\">mode: container\npath: merged\nverbose: true\nfiles:\n  - name: '/usr/bin/curl'\n    hashes:\n      - hash: '9a43cb726fef31f272333b236ff1fde4beab363af54d0bc99c304450065d9c96'\n  - name: '/usr/local/go/bin/go'\n    hashes:\n      - hash: '82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91dd3ff92dd'\n</code></pre>\n\n<p>If we run Terrier with the above config, we get the following output:</p>\n\n<pre><code class=\"language-term\">$ ./terrier\n[+] Loading config: cfg.yml\n[+] Analysing Container\n[!] Found matching instance of '/usr/bin/curl' at: merged/usr/bin/curl with hash:9a43cb726fef31f272333b236ff1fde4beab363af54d0bc99c304450065d9c96\n[!] Found matching instance of '/usr/local/go/bin/go' at: merged/usr/local/go/bin/go with hash:82bce4b98d7aaeb4f841a36f7141d540bb049f89219f9e377245a91\ndd3ff92dd\n[!] All components were identified: (2/2)\n[!] All components were identified and verified: (2/2)\n$ echo $?\n0\n</code></pre>\n\n<p>From the output above, we can see that Terrier was able to successfully identify and verify all the files in the running container. The return code is also <code>0</code> which indicates a successful execution of Terrier.</p>\n<h3 class=\"anchored\">\n  <a name=\"using-terrier-with-ci-cd\" href=\"#using-terrier-with-ci-cd\">Using Terrier with CI/CD</a>\n</h3>\n\n<p>In addition to Terrier being used as a standalone CLI tool, Terrier can also be integrated easily with existing CI/CD technologies such as GitHub Actions and CircleCI. Below are two example configurations that show how Terrier can be used to identify and verify certain components of Docker files in a pipeline and prevent the pipeline from continuing if all verifications do not pass. This can be seen as an extra mitigation for supply-chain attacks.</p>\n\n<p>Below is a CircleCI example configuration using Terrier to verify the contents of an image.</p>\n\n<pre><code class=\"language-yaml\">version: 2\njobs:\nbuild:\n  machine: true\n  steps:\n    - checkout\n    - run:\n       name: Build Docker Image\n       command: |\n             docker build -t builditall .\n    - run:\n       name: Save Docker Image Locally\n       command: |\n             docker save builditall -o builditall.tar\n    - run:\n       name: Verify Docker Image Binaries\n       command: |\n             ./terrier\n</code></pre>\n\n<p>Below is a Github Actions example configuration using Terrier to verify the contents of an image.</p>\n\n<pre><code class=\"language-yaml\">name: Go\non: [push]\njobs:\nbuild:\n  name: Build\n  runs-on: ubuntu-latest\n  steps:\n\n  - name: Get Code\n    uses: actions/checkout@master\n  - name: Build Docker Image\n    run: |\n      docker build -t builditall .\n  - name: Save Docker Image Locally\n    run: |\n      docker save builditall -o builditall.tar\n  - name: Verify Docker Image Binaries\n    run: |\n      ./terrier\n</code></pre>\n<h2 class=\"anchored\">\n  <a name=\"conclusion\" href=\"#conclusion\">Conclusion</a>\n</h2>\n\n<p>In this blog post, we have looked at how to perform multiple actions on Docker (and OCI) containers and images via Terrier. The actions performed allowed us to identify specific files according to their hashes in images and containers. The actions performed have also allowed us to identify and verify multiple components in images and containers. These actions performed by Terrier are useful when attempting to prevent certain supply-chain attacks.</p>\n\n<p>We have also seen how Terrier can be used in a DevOps pipeline via GitHub Actions and CircleCI.</p>\n\n<p>Learn more about Terrier on GitHub at <a href=\"https://github.com/heroku/terrier\">https://github.com/heroku/terrier</a>.</p>","PublishedAt":"2020-01-14 21:30:00+00:00","OriginURL":"https://blog.heroku.com/terrier-open-source-identifying-analyzing-containers","SourceName":"Heroku"}},{"node":{"ID":644,"Title":"Makefiles in 2019 ‚Äî Why They Still Matter","Description":"Make was created in 1976 by Stuart Feldman at Bell Labs to help build C programs. But how can this 40+ year old piece of software help us develop and maintain our ever-growing amount of cloud-based microservices?","PublishedAt":"2019-12-20 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2019-12-20-makefiles-in-2019/","SourceName":"Trivago"}},{"node":{"ID":367,"Title":"Know Your Database Types","Description":"<p><em>This blog post is adapted from <a href=\"https://www.youtube.com/watch?v=7QgNDhtaQMQ&amp;t=16m07s\">a lightning talk</a> by Ben Fritsch at Ruby on Ice 2019.</em></p>\n\n<p>There can be a number of reasons why your application performs poorly, but perhaps none are as challenging as issues stemming from your database. If your database's response times tend to be high, it can cause a strain on your network and your users‚Äô patience. The usual culprit for a slow database is an inefficient query being executed somewhere in your application logic. Usually, you can implement a fix in a number of common ways, by:</p>\n\n<ul>\n<li>\n<a href=\"https://jaketrent.com/post/find-kill-locks-postgres/\">reducing the amount of open locks</a> (or more detail about database lock debugging in this other blog post by Heroku Engineer Richard Schneeman, <a href=\"https://blog.heroku.com/curious-case-table-locking-update-query\">The Curious Case of the Table-Locking UPDATE Query</a>)</li>\n<li><a href=\"http://www.postgresqltutorial.com/postgresql-indexes/postgresql-create-index/\">defining indexes for faster <code>WHERE</code> lookups</a></li>\n<li><a href=\"https://www.datadoghq.com/blog/100x-faster-postgres-performance-by-changing-1-line/\">rewriting the query to use more efficient statements</a></li>\n</ul>\n\n<p>...But what if your problem isn't resolved by any of these actions?</p>\n\n<p>Let's talk about a problem that can occur from the underlying database schema, and how to solve it.</p>\n\n<div class=\"embedded-video-wrapper\">\n<iframe title=\"Know Your Database Types\" src=\"https://www.youtube-nocookie.com/embed/7QgNDhtaQMQ?start=967\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</div>\n<h2 class=\"anchored\">\n  <a name=\"the-problem\" href=\"#the-problem\">The problem</a>\n</h2>\n\n<p>Consider this PostgreSQL database schema:</p>\n\n<pre><code class=\"language-sql\">CREATE TABLE table (\n  app_uuid uuid NOT NULL,\n  json_field json\n)\n</code></pre>\n\n<p>Postgres lets you mark a column's data type as <code>json</code>. This, as opposed to simply unstructured <code>text</code>, allows for more flexible querying and data validation.</p>\n\n<p>As part of our application‚Äôs behavior, we receive and store payloads that look like this:</p>\n\n<pre><code class=\"language-json\">{\"data\": \"very large string\", \"url\": \"https://heroku.com\"}\n</code></pre>\n\n<p>If I want to fetch the <code>url</code> values for a specific <code>app_uuid</code>, I would write a query like this:</p>\n\n<pre><code class=\"language-sql\">SELECT (table.large_json_field -&gt;&gt; 'url'::text) AS url,\nFROM table\nWHERE (\"app_uuid\" = $app_uuid)\nORDER BY  \"created_at\" DESC LIMIT 200;\n</code></pre>\n\n<p>The average execution time of this query was 10ms, although there were outliers reaching as high as 1200ms. This was becoming unacceptable, and I dug in to see exactly what was going on.</p>\n<h2 class=\"anchored\">\n  <a name=\"the-investigation\" href=\"#the-investigation\">The investigation</a>\n</h2>\n\n<p>If you need to look into slow queries, the <a href=\"https://www.postgresql.org/docs/12/sql-explain.html\"><code>EXPLAIN ANALYZE</code></a> statement is a good place to start. It will provide you with some internal metrics about how your query is planned and executed. I learned that there is also the option to use <code>EXPLAIN (ANALYZE, BUFFERS)</code>, which looks like this:</p>\n\n<pre><code class=\"language-sql\">EXPLAIN (ANALYZE, BUFFERS)\nSELECT (table.large_json_field -&gt;&gt; 'url'::text) AS url,\nFROM table\nWHERE (\"app_uuid\" = $app_uuid)\nORDER BY  \"created_at\" DESC LIMIT 200;\n</code></pre>\n\n<p><code>BUFFERS</code> provides stats on the I/O subsystem of Postgres, identifying whether information is being loaded from cache (memory) or directly from disk. It is much slower for Postgres to read data outside of the cache.</p>\n\n<p>The result of that informative query was the following information:</p>\n\n<pre><code>-&gt;   Index Cond: (app_uuid = $app_uuid::uuid)\n        Buffers: shared hit=7106\n\nPlanning time: 0.187 ms\nExecution time: 1141.296 ms\n</code></pre>\n\n<p>By default, Postgres has <a href=\"https://www.cybertec-postgresql.com/en/postgresql-block-sizes-getting-started/\">a block size of 8kb</a>. According to the Postgres planner, the query to fetch a <code>url</code> key uses over 7,100 blocks, which means that we've loaded (and discarded) about 60MB of JSON data (7,106 * 8kb), just to fetch the URLs we wanted. Even though the query took less than a millisecond to plan, it takes over a second to execute!</p>\n<h2 class=\"anchored\">\n  <a name=\"the-solution\" href=\"#the-solution\">The solution</a>\n</h2>\n\n<p>The fix for this is simple and direct. Rather than relying on a single <code>json</code> column, I converted it into two separate <code>text</code> fields: one for <code>data</code> and one for <code>url</code>. This brought the query time down from 1200ms to 10ms as we were able to scope our query to the exact piece of information we needed.</p>\n\n<p>We realized that in this use case, storing JSON was no longer a requirement for us. When we started building this feature about three or four years ago, a <code>json</code> data type was the best choice we had, given the information we had. Our system hasn't changed, but our understanding of how the system was being used did. We had been storing the same JSON structure for years, but we were essentially storing unstructured data in our database. As a result of our database design, reading information became expensive for queries which only required a small piece of information.</p>\n\n<p>I encourage you to audit your database schema for columns with data types that are no longer necessary. As our application and knowledge of users' behaviors evolves, so too should our database structure. Of course, don't change tables just for the sake of changing something! We were able to continue operating with this problem for years without any tremendous strain on our systems. If it's not a problem, don't fix it.</p>\n\n<p>Want to learn more about Postgres? Check out another article we wrote on dev.to: <a href=\"https://dev.to/heroku/postgres-is-underrated-it-handles-more-than-you-think-4ff3\">Postgres Is Underrated‚ÄîIt Handles More than You Think</a>.</p>","PublishedAt":"2019-12-18 18:07:49+00:00","OriginURL":"https://blog.heroku.com/know-your-database-types","SourceName":"Heroku"}},{"node":{"ID":368,"Title":"The Curious Case of the Table-Locking UPDATE Query","Description":"<blockquote>\n<p>Update: On closer inspection, the lock type was not on the table, but on a tuple. For more information on this locking mechanism see the <a href=\"https://github.com/postgres/postgres/blob/master/src/backend/access/heap/README.tuplock\">internal Postgresql tuple locking documentation</a>. Postgres does not have lock promotion as suggested in the debugging section of this post.</p>\n</blockquote>\n\n<p>I maintain an internal-facing service at Heroku that does metadata processing. It's not real-time, so there's plenty of slack for when things go wrong. Recently I discovered that the system was getting bogged down to the point where no jobs were being executed at all. After hours of debugging, I found the problem was an <code>UPDATE</code> on a single row on a single table was causing the entire table to lock, which caused a lock queue and ground the whole process to a halt. This post is a story about how the problem was debugged and fixed and why such a seemingly simple query caused so much harm.</p>\n<h2 class=\"anchored\">\n  <a name=\"no-jobs-processing\" href=\"#no-jobs-processing\">No jobs processing</a>\n</h2>\n\n<p>I started debugging when the backlog on our system began to grow, and the number of jobs being processed fell to nearly zero. The system has been running in production for years, and while there have been occasional performance issues, nothing stood out as a huge problem. I checked our datastores, and they were well under their limits, I checked our error tracker and didn't see any smoking guns. My best guess was the database where the results were being stored was having problems.</p>\n\n<p>The first thing I did was run <code>heroku pg:diagnose</code>, which shows \"red\" (critical) and \"yellow\" (important but less critical) issues. It showed that I had queries that had been running for DAYS:</p>\n\n<pre><code>68698   5 days 18:01:26.446979  UPDATE \"table\" SET &lt;values&gt; WHERE (\"uuid\" = '&lt;uuid&gt;')\n</code></pre>\n\n<p>Which seemed odd. The query in question was a simple update, and it's not even on the most massive table in the DB. When I checked <code>heroku pg:outliers</code> from the <a href=\"https://github.com/heroku/heroku-pg-extras\">pg extras CLI plugin</a> I was surprised to see this update taking up 80%+ of the time even though it is smaller than the largest table in the database by a factor of 200. So what gives?</p>\n\n<p>Running the update statement manually didn't reproduce the issue, so I was fresh out of ideas. If it had, then I could have run with <code>EXPLAIN ANALYZE</code> to see why it was so slow. Luckily I work with some pretty fantastic database engineers, and I pinged them for possible ideas. They mentioned that there might be a locking issue with the database. The idea was strange to me since it had been running relatively unchanged for an extremely long time and only now started to see problems, but I decided to look into it.</p>\n\n<pre><code class=\"language-sql\">SELECT\n  S.pid,\n  age(clock_timestamp(), query_start),\n  query,\n  L.mode,\n  L.locktype,\n  L.granted\nFROM pg_stat_activity S\ninner join pg_locks L on S.pid = L.pid\norder by L.granted, L.pid DESC;\n-----------------------------------\npid      | 127624\nage      | 2 days 01:45:00.416267\nquery    | UPDATE \"table\" SET &lt;values&gt; WHERE (\"uuid\" = '&lt;uuid&gt;')\nmode     | AccessExclusiveLock\nlocktype | tuple\ngranted  | f\n</code></pre>\n\n<p>I saw a ton of queries that were hung for quite some time, and most of them pointed to my seemingly teeny <code>UPDATE</code> statement.</p>\n<h2 class=\"anchored\">\n  <a name=\"all-about-locks\" href=\"#all-about-locks\">All about locks</a>\n</h2>\n\n<p>Up until this point, I basically knew nothing about how PostgreSQL uses locking other than in an explicit advisory lock, which can be used via a gem like <a href=\"https://github.com/heroku/pg_lock\">pg_lock</a> (That I maintain). Luckily Postgres has excellent docs around locks, but it's a bit much if you're new to the field: <a href=\"https://www.postgresql.org/docs/11/explicit-locking.html#LOCKING-TABLES\">Postgresql Lock documentation</a></p>\n\n<p>Looking up the name of the lock from before <code>Access Exclusive Lock</code> I saw that it locks the whole table:</p>\n\n<blockquote>\n<p>ACCESS EXCLUSIVE\nConflicts with locks of all modes (ACCESS SHARE, ROW SHARE, ROW EXCLUSIVE, SHARE UPDATE EXCLUSIVE, SHARE, SHARE ROW EXCLUSIVE, EXCLUSIVE, and ACCESS EXCLUSIVE). This mode guarantees that the holder is the only transaction accessing the table in any way.\nAcquired by the DROP TABLE, TRUNCATE, REINDEX, CLUSTER, VACUUM FULL, and REFRESH MATERIALIZED VIEW (without CONCURRENTLY) commands. Many forms of ALTER TABLE also acquire a lock at this level (see ALTER TABLE). This is also the default lock mode for LOCK TABLE statements that do not specify a mode explicitly.</p>\n</blockquote>\n\n<p>From the docs, this lock is not typically triggered by an <code>UPDATE</code>, so what gives? Grepping through the docs showed me that an <code>UPDATE</code> should trigger a <code>ROW SHARE</code> lock:</p>\n\n<pre><code>ROW EXCLUSIVE\nConflicts with the SHARE, SHARE ROW EXCLUSIVE, EXCLUSIVE, and ACCESS EXCLUSIVE lock modes.\n\nThe commands UPDATE, DELETE, and INSERT acquire this lock mode on the target table (in addition to ACCESS SHARE locks on any other referenced tables). In general, this lock mode will be acquired by any command that modifies data in a table.\n</code></pre>\n\n<blockquote>\n<p>A database engineer directly told me what kind of lock an <code>UPDATE</code> should use, but you could find it in the docs if you don't have access to some excellent database professionals.</p>\n</blockquote>\n\n<p>Mostly what happens when you try to <code>UPDATE</code> is that Postgres will acquire a lock on the row that you want to change. If you have two update statements running at the same time on the same row, then the second must wait for the first to process. So why on earth, if an <code>UPDATE</code> is supposed only to take out a row lock, was my query taking out a lock against the whole table?</p>\n<h2 class=\"anchored\">\n  <a name=\"unmasking-a-locking-mystery\" href=\"#unmasking-a-locking-mystery\">Unmasking a locking mystery</a>\n</h2>\n\n<p>I would love to tell you that I have a really great debugging tool to tell you about here, but I mostly duck-duck-go-ed (searched) a ton and eventually found <a href=\"https://grokbase.com/t/postgresql/pgsql-general/124s02j3jy/updates-sharelocks-rowexclusivelocks-and-deadlocks\">this forum post</a>. In the post someone is complaining about a similar behavior, they're using an update but are seeing more aggressive lock being used sometimes.</p>\n\n<p>Based on the responses to the forum it sounded like if there is more than a few <code>UPDATE</code> queries that are trying to modify the same row at the same time what happens is that one of the queries will try to acquire the lock, see it is taken then it will instead acquire a larger lock on the table. Postgres queues locks, so if this happens for multiple rows with similar contention, then multiple queries would be taking out locks on the whole table, which somewhat could explain the behavior I was seeing. It seemed plausible, but why was there such a problem?</p>\n\n<p>I combed over my codebase and couldn't find anything. Then as I was laying down to go to bed that evening, I had a moment of inspiration where I remembered that we were updating the database in parallel for the same UUID using threads:</p>\n\n<pre><code class=\"language-ruby\">@things.map do |thing|\n  Concurrent::Promise.execute(executor: :fast) do\n    store_results!(thing)\n  end\nend.each(&amp;:value!)\n</code></pre>\n\n<p>In every loop, we were creating a promise that would concurrently update values (using a thread pool). Due to a design decision from years ago, each loop causes an <code>UPDATE</code> to the same row in the database for each job being run. This programming pattern was never a problem before because, as I mentioned earlier, there's another table with more than 200x the number of records, so we've never had any issues with this scheme until recently.</p>\n\n<p>With this new theory, I removed the concurrency, which meant that each <code>UPDATE</code> call would be sequential instead of in parallel:</p>\n\n<pre><code class=\"language-ruby\">@things.map do |thing|\n  store_results!(thing)\nend\n</code></pre>\n\n<p>While the code is less efficiently in the use of IO on the Ruby program, it means that the chance that the same row will try to be updated at the same time is drastically decreased.</p>\n\n<p>I manually killed the long-running locked queries using <code>SELECT pg_cancel_backend(&lt;pid&gt;);</code> and I deployed this change (in the morning after a code review).</p>\n\n<p>Once the old stuck queries were aborted, and the new code was in place, then the system promptly got back up and running, churning through plenty of backlog.</p>\n<h2 class=\"anchored\">\n  <a name=\"locks-and-stuff\" href=\"#locks-and-stuff\">Locks and stuff</a>\n</h2>\n\n<p>While this somewhat obscure debugging story might not be directly relevant to your database, here are some things you can take away from this article. Your database has locks (think mutexes but with varying scope), and those locks can mess up your day if they're doing something different than you're expecting. You can see the locks that your database is currently using by running the <code>heroku pg:locks</code> command (may need to install the <code>pg:extras</code> plugin). You can also see which queries are taking out which locks using the SQL query I posted earlier.</p>\n\n<p>The next thing I want to cover is documentation. If it weren't for several very experienced Postgres experts and a seemingly random forum post about how multiple <code>UPDATE</code> statements can trigger a more aggressive lock type, then I never would have figured this out. If you're familiar with the Postgres documentation, is this behavior written down anywhere? If so, then could we make it easier to find or understand somehow? If it's not written down, can you help me document it? I don't mind writing documentation, but I'm not totally sure what the expected behavior is. For instance, why does a lock queue for a row that goes above a specific threshold trigger a table lock? And what exactly is that threshold? I'm sure this behavior makes total sense from an implementation point of view, but as an end-user, I would like it to be spelled out and officially documented.</p>\n\n<p>I hope you either learned a thing or two or at least got a kick out of my misery. This issue was a pain to debug, but in hindsight, a quirky bug to blog about. Thanks for reading!</p>\n\n<p>And to learn about another potential database issue, check out this other blog post by Heroku Engineer Ben Fritsch, <a href=\"https://blog.heroku.com/know-your-database-types\">Know Your Database Types</a>.</p>\n\n<p>Special thanks to <a href=\"https://github.com/mble\">Matthew Blewitt</a> and <a href=\"https://github.com/andscoop\">Andy Cooper</a> for helping me debug this!</p>","PublishedAt":"2019-12-18 18:07:00+00:00","OriginURL":"https://blog.heroku.com/curious-case-table-locking-update-query","SourceName":"Heroku"}},{"node":{"ID":369,"Title":"Let It Crash: Best Practices for Handling Node.js Errors on Shutdown","Description":"<p><em>This blog post is adapted from a talk given by Juli√°n Duque at NodeConf EU 2019 titled \"<a href=\"https://youtu.be/Fguac8pIAtU\">Let it crash!</a>.\"</em></p>\n\n<p>Before coming to Heroku, I did some consulting work as a Node.js solutions architect. My job was to visit various companies and make sure that they were successful in designing production-ready Node applications. Unfortunately, I witnessed many different problems when it came to error handling, especially on process shutdown. When an error occurred, there was often not enough visibility on why it happened, a lack of logging details, and bouts of downtime as applications attempted to recover from crashes.</p>\n\n<div class=\"embedded-video-wrapper\">\n<iframe title=\"Let it Crash!\" src=\"https://www.youtube-nocookie.com/embed/Fguac8pIAtU\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</div>\n\n\n\n<p>We started to assemble a collection of best practices and recommendations on error handling, to ensure they were aligned with the overall Node.js community. In this post, I'll walk through some of the background on the Node.js process lifecycle and some strategies to properly handle graceful shutdown and quickly restart your application after a catastrophic error terminates your program. </p>\n<h2 class=\"anchored\">\n  <a name=\"the-node-js-process-lifecycle\" href=\"#the-node-js-process-lifecycle\">The Node.js process lifecycle</a>\n</h2>\n\n<p>Let's first explore briefly how Node.js operates. A Node.js process is very lightweight and has a small memory footprint. Because crashes are an inevitable part of programming, your primary goal when architecting an application is to keep the startup process very lean, so that your application can quickly boot up. If your startup operations include CPU intensive work or synchronous operations, it might affect the ability of your Node.js processes to quickly restart.</p>\n\n<p>A strategy you can use here is to prebuild as much as possible. That might mean preparing data or compiling assets during the building process. It may increase your deployment times, but it's better to spend more time outside of the startup process. Ultimately, this ensures that when a crash does happen, you can exit a process and start a new one without much downtime.</p>\n<h3 class=\"anchored\">\n  <a name=\"node-js-exit-methods\" href=\"#node-js-exit-methods\">Node.js exit methods</a>\n</h3>\n\n<p>Let's take a look at several ways you can terminate a Node.js process and the differences between them.</p>\n\n<p>The most common function to use is <a href=\"https://nodejs.org/api/process.html#process_process_exit_code\"><code>process.exit()</code></a>, which takes a single argument, an integer. If the argument is <code>0</code>, it represents a successful exit state. If it's greater than that, it indicates that an error occurred; <code>1</code> is a common exit code for failures here.</p>\n\n<p>Another option is <a href=\"https://nodejs.org/api/process.html#process_process_abort\"><code>process.abort()</code></a>. When this method is called, the Node.js process terminates immediately. More importantly, if your operating system allows it, Node will also generate a core dump file, which contains a ton of useful information about the process. You can use this core dump to do some postmortem debugging using tools like <a href=\"https://github.com/nodejs/llnode\"><code>llnode</code></a>.</p>\n<h3 class=\"anchored\">\n  <a name=\"node-js-exit-events\" href=\"#node-js-exit-events\">Node.js exit events</a>\n</h3>\n\n<p>As Node.js is built on top of JavaScript, it has an event loop, which allows you to listen for events that occur and act on them. When Node.js exits, it also emits several types of events.</p>\n\n<p>One of these is <code>beforeExit</code>, and as its name implies, it is emitted right before a Node process exits. You can provide an event handler which can make asynchronous calls, and the event loop will continue to perform the work until it's all finished. It's important to note that this event is <em>not</em> emitted on <code>process.exit()</code> calls or <code>uncaughtException</code>s; we'll get into when you might use this event a little later.</p>\n\n<p>Another event is <code>exit</code>, which is emitted only when <code>process.exit()</code> is explicitly called. As it fires after the event loop has been terminated, you can't do any asynchronous work in this handler.</p>\n\n<p>The code sample below illustrates the differences between the two events:</p>\n\n<pre><code class=\"language-js\">process.on('beforeExit', code =&gt; {\n  // Can make asynchronous calls\n  setTimeout(() =&gt; {\n    console.log(`Process will exit with code: ${code}`)\n    process.exit(code)\n  }, 100)\n})\n\nprocess.on('exit', code =&gt; {\n  // Only synchronous calls\n  console.log(`Process exited with code: ${code}`)\n})\n</code></pre>\n<h3 class=\"anchored\">\n  <a name=\"os-signal-events\" href=\"#os-signal-events\">OS signal events</a>\n</h3>\n\n<p>Your operating system emits events to your Node.js process, too, depending on the circumstances occurring outside of your program. These are referred to as <a href=\"https://en.wikipedia.org/wiki/Signal_(IPC)\">signals</a>. Two of the more common signals are <code>SIGTERM</code> and <code>SIGINT</code>.</p>\n\n<p><code>SIGTERM</code> is normally sent by a process monitor to tell Node.js to expect a successful termination. If you're running <code>systemd</code> or <code>upstart</code> to manage your Node application, and you stop the service, it sends a <code>SIGTERM</code> event so that you can handle the process shutdown.</p>\n\n<p><code>SIGINT</code> is emitted when a Node.js process is interrupted, usually as the result of a control-C (<code>^-C</code>) keyboard event. You can also capture that event and do some work around it.</p>\n\n<p>Here is an example showing how you may act on these signal events:</p>\n\n<pre><code class=\"language-js\">process.on('SIGTERM', signal =&gt; {\n  console.log(`Process ${process.pid} received a SIGTERM signal`)\n  process.exit(0)\n})\n\nprocess.on('SIGINT', signal =&gt; {\n  console.log(`Process ${process.pid} has been interrupted`)\n  process.exit(0)\n})\n</code></pre>\n\n<p>Since these two events are considered a successful termination, we call <code>process.exit</code> and pass an argument of <code>0</code> because it is something that is expected.</p>\n<h3 class=\"anchored\">\n  <a name=\"javascript-error-events\" href=\"#javascript-error-events\">JavaScript error events</a>\n</h3>\n\n<p>At last, we arrive at higher-level error types: the error events thrown by JavaScript itself.</p>\n\n<p>When a JavaScript error is not properly handled, an <code>uncaughtException</code> is emitted. These suggest the programmer has made an error, and they should be treated with the utmost priority. Usually, it means a bug occurred on a piece of logic that needed more testing, such as calling a method on a <code>null</code> type.</p>\n\n<p>An <code>unhandledRejection</code> error is a newer concept. It is emitted when a <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise\">promise</a> is not satisfied; in other words, a promise was rejected (it failed), and there was no handler attached to respond. These errors can indicate an operational error or a programmer error, and they should also be treated as high priority.</p>\n\n<p>In both of these cases, you should do something counterintuitive and <strong>let your program crash</strong>! Please don't try to be clever and introduce some complex logic trying to prevent a process restart. Doing so will almost always leave your application in a bad state, whether that's having a memory leak or leaving sockets hanging. It's simpler to let it crash, start a new process from scratch, and continue receiving more requests.</p>\n\n<p>Here's some code indicating how you might best handle these events:</p>\n\n<pre><code class=\"language-js\">process.on('uncaughtException', err =&gt; {\n  console.log(`Uncaught Exception: ${err.message}`)\n  process.exit(1)\n})\n</code></pre>\n\n<p>We‚Äôre explicitly ‚Äúcrashing‚Äù the Node.js process here! Don‚Äôt be afraid of this! It is more likely than not unsafe to continue. The <a href=\"https://nodejs.org/api/process.html#process_warning_using_uncaughtexception_correctly\">Node.js documentation</a> says,</p>\n\n<blockquote>\n<p>Unhandled exceptions inherently mean that an application is in an undefined state...The correct use of 'uncaughtException' is to perform synchronous cleanup of allocated resources (e.g. file descriptors, handles, etc) before shutting down the process. It is not safe to resume normal operation after 'uncaughtException'.</p>\n</blockquote>\n\n<pre><code class=\"language-js\">process.on('unhandledRejection', (reason, promise) =&gt; {\n  console.log('Unhandled rejection at ', promise, `reason: ${err.message}`)\n  process.exit(1)\n})\n</code></pre>\n\n<p><code>unhandledRejection</code> is such a common error, that the Node.js maintainers have decided it should really crash the process, and they warn us that in a future version of Node.js <code>unhandledRejection</code>s will crash the process.</p>\n\n<blockquote>\n<p>[DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.</p>\n</blockquote>\n<h2 class=\"anchored\">\n  <a name=\"run-more-than-one-process\" href=\"#run-more-than-one-process\">Run more than one process</a>\n</h2>\n\n<p>Even if your process startup time is extremely quick, running just a single process is a risk to safe and uninterrupted application operation. We recommend running more than one process and to use a load balancer to handle the scheduling. That way, if one of the processes crashes, there is another process that is alive and able to receive new requests. This is going to give you a little bit more leverage and prevent downtime.</p>\n\n<p>Use whatever you have on-hand for the load balancing. You can configure a reverse proxy like nginx or HAProxy to do this. If you're on Heroku, you can <a href=\"https://devcenter.heroku.com/articles/how-heroku-works#http-routing\">scale your application</a> to increase the number of dynos. If you're on Kubernetes, you can use <a href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\">Ingress</a> or other load balancer strategies for your application.</p>\n<h2 class=\"anchored\">\n  <a name=\"monitor-your-processes\" href=\"#monitor-your-processes\">Monitor your processes</a>\n</h2>\n\n<p>You should have process monitoring in-place, something running in your operating system or an application environment that's constantly checking if your Node.js process is alive or not. If the process crashes due to a failure, the process monitor is in charge of restarting the process.</p>\n\n<p>Our recommendation is to always use the native process monitoring that's available on your operating system. For example, if you're running on Unix or Linux, you can use the <a href=\"https://en.wikipedia.org/wiki/Systemd\"><code>systemd</code></a> or <a href=\"https://en.wikipedia.org/wiki/Upstart_(software)\"><code>upstart</code></a> commands. If you're using containers, Docker has a <a href=\"https://docs.docker.com/engine/reference/run/#restart-policies---restart\"><code>--restart</code> flag</a>, and Kubernetes has <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy\"><code>restartPolicy</code></a>, both of which are useful.</p>\n\n<p>If you can't use any existing tools, use a Node.js process monitor like <a href=\"https://pm2.keymetrics.io/\">PM2</a> or <a href=\"https://github.com/foreversd/forever\">forever</a> as a last resort. These tools are okay for development environments, but I can't really recommend them for production use.</p>\n\n<p>If your application is running on Heroku, don‚Äôt worry‚Äîwe take care of the restart for you!</p>\n<h2 class=\"anchored\">\n  <a name=\"graceful-shutdowns\" href=\"#graceful-shutdowns\">Graceful shutdowns</a>\n</h2>\n\n<p>Let's say we have a server running. It's receiving requests and establishing connections with clients. But what happens if the process crashes?  If we're not performing a graceful shutdown, some of those sockets are going to hang around and keep waiting for a response until a timeout has been reached. That unnecessary time spent consumes resources, eventually leading to downtime and a degraded experience for your users.</p>\n\n<p>It's best to explicitly stop receiving connections, so that the server can disconnect connections while it's recovering. Any new connections will go to the other Node.js processes running through the load balancer</p>\n\n<p>To do this, you can call <a href=\"https://nodejs.org/api/http.html#http_server_close_callback\"><code>server.close()</code></a>, which tells the server to stop accepting new connections. Most Node servers implement this class, and it accepts a callback function as an argument.</p>\n\n<p>Now, imagine that your server has many clients connected, and the majority of them have not experienced an error or crashed. How can you close the server while not abruptly disconnecting valid clients? We'll need to use a timeout to build a system to indicate that if all the connections don't close within a certain limit, we will completely shutdown the server. We do this because we want to give existing, healthy clients time to finish up but don't want the server to wait for an excessively long time to shutdown.</p>\n\n<p>Here's some sample code of what that might look like:</p>\n\n<pre><code class=\"language-js\">process.on('&lt;signal or error event&gt;', _ =&gt; {\n  server.close(() =&gt; {\n    process.exit(0)\n  })\n  // If server hasn't finished in 1000ms, shut down process\n  setTimeout(() =&gt; {\n    process.exit(0)\n  }, 1000).unref() // Prevents the timeout from registering on event loop\n})\n</code></pre>\n<h2 class=\"anchored\">\n  <a name=\"logging\" href=\"#logging\">Logging</a>\n</h2>\n\n<p>Chances are you have already implemented a robust logging strategy for your running application, so I won't get into it too much about that here. Just remember to log with the same rigorous quality and amount of information for when the application shuts down!</p>\n\n<p>If a crash occurs, log as much relevant information as possible, including the errors and stack trace. Rely on libraries like <a href=\"https://github.com/pinojs/pino\"><code>pino</code></a> or <a href=\"https://github.com/winstonjs/winston\"><code>winston</code></a> in your application, and store these logs using one of their transports for better visibility. You can also take a look at <a href=\"https://elements.heroku.com/addons#logging\">our various logging add-ons</a> to find a provider which matches your application‚Äôs needs.</p>\n<h2 class=\"anchored\">\n  <a name=\"make-sure-everything-is-still-good\" href=\"#make-sure-everything-is-still-good\">Make sure everything is still good</a>\n</h2>\n\n<p>Last, and certainly not least, we recommend that you add a health check route. This is a simple endpoint that returns a <code>200</code> status code if your application is running:</p>\n\n<pre><code class=\"language-js\">// Add a health check route in express\napp.get('/_health', (req, res) =&gt; {\n  res.status(200).send('ok')\n})\n</code></pre>\n\n<p>You can have a separate service continuously monitor that route. You can configure this in a number of ways, whether by using a reverse proxy, such as nginx or HAProxy, or a load balancer, like ELB or ALB.</p>\n\n<p>Any application that acts as the top layer of your Node.js process can be used to constantly monitor that the health check is returning. These will also give you way more visibility around the health of your Node.js processes, and you can rest easy knowing that your Node processes are running properly. There are some great great monitoring services to help you with this in the <a href=\"https://elements.heroku.com/addons#monitoring\">Add-ons section of our Elements Marketplace</a>.</p>\n<h2 class=\"anchored\">\n  <a name=\"putting-it-all-together\" href=\"#putting-it-all-together\">Putting it all together</a>\n</h2>\n\n<p>Whenever I work on a new Node.js project, I use the same function to ensure that my crashes are logged and my recoveries are guaranteed. It looks something like this:</p>\n\n<pre><code class=\"language-js\">function terminate (server, options = { coredump: false, timeout: 500 }) {\n  // Exit function\n  const exit = code =&gt; {\n    options.coredump ? process.abort() : process.exit(code)\n  }\n\n  return (code, reason) =&gt; (err, promise) =&gt; {\n    if (err &amp;&amp; err instanceof Error) {\n    // Log error information, use a proper logging library here :)\n    console.log(err.message, err.stack)\n    }\n\n    // Attempt a graceful shutdown\n    server.close(exit)\n    setTimeout(exit, options.timeout).unref()\n  }\n}\n\nmodule.exports = terminate\n</code></pre>\n\n<p>Here, I've created a module called <code>terminate</code>. I pass the instance of that server that I'm going to be closing, and some configuration options, such as whether I want to enable core dumps, as well as the timeout. I usually use an environment variable to control when I want to enable a core dump. I enable them only when I am going to do some performance testing on my application or whenever I want to replicate the error.</p>\n\n<p>This exported function can then be set to listen to our error events:</p>\n\n<pre><code class=\"language-js\">const http = require('http')\nconst terminate = require('./terminate')\nconst server = http.createServer(...)\n\nconst exitHandler = terminate(server, {\n  coredump: false,\n  timeout: 500\n})\n\nprocess.on('uncaughtException', exitHandler(1, 'Unexpected Error'))\nprocess.on('unhandledRejection', exitHandler(1, 'Unhandled Promise'))\nprocess.on('SIGTERM', exitHandler(0, 'SIGTERM'))\nprocess.on('SIGINT', exitHandler(0, 'SIGINT'))\n</code></pre>\n<h2 class=\"anchored\">\n  <a name=\"additional-resources\" href=\"#additional-resources\">Additional resources</a>\n</h2>\n\n<p>There are a number of existing npm modules that pretty much solve the aforementioned issues in a similar ways. You can check these out as well:</p>\n\n<ul>\n<li><a href=\"https://github.com/godaddy/terminus\">@godaddy/terminus</a></li>\n<li><a href=\"https://github.com/hunterloftis/stoppable\">stoppable</a></li>\n<li><a href=\"https://github.com/sebhildebrandt/http-graceful-shutdown\">http-graceful-shutdown</a></li>\n</ul>\n\n<p>Hopefully, this information will simplify your life and enable your Node app to run better and safer in production!</p>","PublishedAt":"2019-12-17 18:12:00+00:00","OriginURL":"https://blog.heroku.com/best-practices-nodejs-errors","SourceName":"Heroku"}},{"node":{"ID":645,"Title":"Getting Ready For The Big Data Apocalypse","Description":"","PublishedAt":"2019-12-16 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2019-12-16-gettingreadyforbigdataapocalypse/","SourceName":"Trivago"}},{"node":{"ID":382,"Title":"Instagram Data Saver Mode","Description":"<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://instagram-engineering.com/instagram-data-saver-mode-ffb01fd5a6bd?source=rss----37dc2a3034f2---4\"><img src=\"https://cdn-images-1.medium.com/max/912/1*DFLQYzOGL6yMpXmN28iP7g.png\" width=\"912\"></a></p><p class=\"medium-feed-snippet\">We recently shipped Data Saver Mode, a new feature on Instagram for Android that helps the app consume less mobile data. In this post&#x2026;</p><p class=\"medium-feed-link\"><a href=\"https://instagram-engineering.com/instagram-data-saver-mode-ffb01fd5a6bd?source=rss----37dc2a3034f2---4\">Continue reading on Instagram Engineering ¬ª</a></p></div>","PublishedAt":"2019-12-13 18:09:34+00:00","OriginURL":"https://instagram-engineering.com/instagram-data-saver-mode-ffb01fd5a6bd?source=rss----37dc2a3034f2---4","SourceName":"Instagram"}},{"node":{"ID":270,"Title":"NY MusicTech @ GIPHY","Description":"December 10, 2019 GIPHY HQ ‚Äì New York, NY Join us and the MusicTech meetup for a night of demos and musical performances! MusicTech is a community that&#8217;s supports the people who are defining what music technology will look like in the future. Demos by:&#8211; Christian Rutledge, Muzooka&#8211; Hazmin Valdes, BillFold POS&#8211; Deane Marcus, RIFF [&#8230;]","PublishedAt":"2019-12-03 14:50:26+00:00","OriginURL":"https://engineering.giphy.com/ny-musictech-giphy/","SourceName":"GIPHY"}},{"node":{"ID":383,"Title":"Powered by AI: Instagram‚Äôs Explore recommender system","Description":"<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://instagram-engineering.com/powered-by-ai-instagrams-explore-recommender-system-7ca901d2a882?source=rss----37dc2a3034f2---4\"><img src=\"https://cdn-images-1.medium.com/max/1800/0*L8XlYDF2i6ziTrH4\" width=\"1800\"></a></p><p class=\"medium-feed-snippet\">This post was originally published on Facebook AI blog: https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/.</p><p class=\"medium-feed-link\"><a href=\"https://instagram-engineering.com/powered-by-ai-instagrams-explore-recommender-system-7ca901d2a882?source=rss----37dc2a3034f2---4\">Continue reading on Instagram Engineering ¬ª</a></p></div>","PublishedAt":"2019-11-26 13:48:39+00:00","OriginURL":"https://instagram-engineering.com/powered-by-ai-instagrams-explore-recommender-system-7ca901d2a882?source=rss----37dc2a3034f2---4","SourceName":"Instagram"}},{"node":{"ID":646,"Title":"Open Source? trivago.","Description":"","PublishedAt":"2019-11-20 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2019-11-20-opensourcetrivago/","SourceName":"Trivago"}},{"node":{"ID":647,"Title":"Automation-First Approach Using the Karate API Testing Framework","Description":"","PublishedAt":"2019-11-14 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2019-11-14-apitestautomationusingkarate/","SourceName":"Trivago"}},{"node":{"ID":384,"Title":"10 Questions with Shupin Mao, Well-being tech lead","Description":"","PublishedAt":"2019-11-08 16:24:40+00:00","OriginURL":"https://instagram-engineering.com/10-questions-with-shupin-mao-well-being-tech-lead-3b19f19b168d?source=rss----37dc2a3034f2---4","SourceName":"Instagram"}},{"node":{"ID":815,"Title":"Implementing Dark Mode Using the Observer Pattern","Description":"Last week‚Äôs update to the SoundCloud iOS app includes support for Dark Mode. This took several months of work and collaboration between‚Ä¶","PublishedAt":"2019-11-08 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/dark-mode-observer-pattern","SourceName":"Soundcloud"}},{"node":{"ID":385,"Title":"Making instagram.com faster: Code size and execution optimizations (Part 4)","Description":"","PublishedAt":"2019-11-01 13:03:12+00:00","OriginURL":"https://instagram-engineering.com/making-instagram-com-faster-code-size-and-execution-optimizations-part-4-57668be796a8?source=rss----37dc2a3034f2---4","SourceName":"Instagram"}},{"node":{"ID":271,"Title":"Pupline: GIPHY‚Äôs Media Metadata Pipeline","Description":"Here at GIPHY, we receive thousands of GIF uploads each day. Like any tech company, we love data: we want to attach as much data as we can to these GIFs so that we can improve their search performance and the user experience. We also want to do so in an organized, centralized, and asynchronous [&#8230;]","PublishedAt":"2019-10-29 17:07:14+00:00","OriginURL":"https://engineering.giphy.com/pupline-giphys-media-metadata-pipeline/","SourceName":"GIPHY"}},{"node":{"ID":648,"Title":"triversity - An Interview with two trivago Tech Camp Participants","Description":"","PublishedAt":"2019-10-23 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2019-10-23-triversityinterview/","SourceName":"Trivago"}},{"node":{"ID":386,"Title":"Python at Scale: Strict Modules","Description":"","PublishedAt":"2019-10-17 15:01:07+00:00","OriginURL":"https://instagram-engineering.com/python-at-scale-strict-modules-c0bb9245c834?source=rss----37dc2a3034f2---4","SourceName":"Instagram"}},{"node":{"ID":272,"Title":"GIPHY Gets Tagged by K-Nearest Neighbors","Description":"When a brand new GIF gets uploaded onto GIPHY.com, there‚Äôs usually not a lot of data associated with it to make sure that it‚Äôs discoverable via search. While we do rely on machine learning for tag generation, we also allow uploading users and GIPHY‚Äôs content team to manually add ‚Äútags‚Äù, which are keywords that help [&#8230;]","PublishedAt":"2019-10-16 15:14:01+00:00","OriginURL":"https://engineering.giphy.com/giphy-gets-tagged-by-k-nearest-neighbors/","SourceName":"GIPHY"}},{"node":{"ID":387,"Title":"Making instagram.com faster: Part 3‚Ää‚Äî‚Ääcache first","Description":"<div class=\"medium-feed-item\"><p class=\"medium-feed-image\"><a href=\"https://instagram-engineering.com/making-instagram-com-faster-part-3-cache-first-6f3f130b9669?source=rss----37dc2a3034f2---4\"><img src=\"https://cdn-images-1.medium.com/max/1664/1*NGABlwJjUR2g0T23xTvWoQ.png\" width=\"1664\"></a></p><p class=\"medium-feed-snippet\">In recent years instagram.com has seen a lot of changes&#x200A;&#x2014;&#x200A;we&#x2019;ve launched stories, filters, creation tools, notifications, and direct&#x2026;</p><p class=\"medium-feed-link\"><a href=\"https://instagram-engineering.com/making-instagram-com-faster-part-3-cache-first-6f3f130b9669?source=rss----37dc2a3034f2---4\">Continue reading on Instagram Engineering ¬ª</a></p></div>","PublishedAt":"2019-10-11 00:04:26+00:00","OriginURL":"https://instagram-engineering.com/making-instagram-com-faster-part-3-cache-first-6f3f130b9669?source=rss----37dc2a3034f2---4","SourceName":"Instagram"}},{"node":{"ID":388,"Title":"Implementing Dark Mode in iOS 13","Description":"","PublishedAt":"2019-10-08 16:30:51+00:00","OriginURL":"https://instagram-engineering.com/instagram-darkmode-58802b43c0f2?source=rss----37dc2a3034f2---4","SourceName":"Instagram"}},{"node":{"ID":273,"Title":"DevOps and Drinks : Discussing Spinnaker with GIPHY and Armory","Description":"October 10, 2019 GIPHY HQ ‚Äì New York, NY Come join us on October 10th for another iteration of DevOps and Drinks, this time featuring our GIPHY Engineering&#8217;s very own Site Reliability Engineer, Bryant Rockoff, who will discuss how GIPHY has deployed and is using Spinnaker to help ensure we help to keep the internet [&#8230;]","PublishedAt":"2019-10-04 17:33:31+00:00","OriginURL":"https://engineering.giphy.com/devops-and-drinks-discussing-spinnaker-with-giphy-and-armory/","SourceName":"GIPHY"}},{"node":{"ID":274,"Title":"The Round","Description":"October 3rd, 2019 @ 26 Bridge, Brooklyn NY Come see us at The Round NYC on October 3rd where we&#8217;ll be participating in a panel, sharing what it&#8217;s like to work at GIPHY Engineering and chatting with candidates about opportunities to join the team! The event is completely free. You can find more info and [&#8230;]","PublishedAt":"2019-10-01 17:20:04+00:00","OriginURL":"https://engineering.giphy.com/the-round/","SourceName":"GIPHY"}}]}},"pageContext":{"limit":30,"skip":5340,"numPages":193,"currentPage":179}},"staticQueryHashes":["3649515864"]}