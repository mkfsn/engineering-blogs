{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/104","result":{"data":{"allPost":{"edges":[{"node":{"ID":2673,"Title":"The Journey to Machine-Learned Re-ranking","Description":"<p>The Journey to Machine-Learned Re-ranking Search is the most fundamental way users discover what Mercari marketplace has to offer; our users rely on search to find the items they want. This core functionality is powered by a traditional text matching information retrieval system. But recently, we asked ourselves: Is there a reasonable machine-learning based approach [&hellip;]</p>\n","PublishedAt":"2023-01-01 14:24:46+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20230101-the-journey-to-machine-learned-re-ranking/","SourceName":"Mercari"}},{"node":{"ID":2766,"Title":"Datadog 101: SRE Workshop (EMEA)","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/event/sre-workshop-emea/partner/201007_webinar_fieldevent_desktop.png\" width=\"100%\"/>Datadog’s core suite of products is tailored for SREs. Together, they provide a single pane of glass that gives you both a bird’s-eye view of your entire infrastructure and the ability to zoom in on individual processes. <br><br> In this workshop, you will add the Datadog Agent to a containerized web application and use some essential Datadog tools, including: <ul class='dashed'> <li>Integrations</li> <li>Logs</li> <li>Monitors and alerts</li> <li>Application Performance Monitoring (APM)</li> <li>Network Performance Monitoring (NPM)</li> <li>Dashboards</li> </ul> <br><br> By the end of this workshop, you will be able to use these Datadog tools to analyze the past, observe the present, and optimize the future of your application and infrastructure. <br><br> Duration: 2 hours <br><br> Requirements: A modern web browser with WebSockets enabled. <br><br> The session will close with an audience Q&amp;A.","PublishedAt":"2023-01-01 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/event/sre-workshop-emea/","SourceName":"Datadog"}},{"node":{"ID":2921,"Title":"'Intro to AWS Monitoring with Datadog' Workshop","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/event/intro-to-aws-workshop-emea/partner/201007_webinar_fieldevent_desktop.png\" width=\"100%\"/>Datadog’s AWS integration brings you deep visibility into key AWS services like EC2 and Lambda. In this workshop, we will demonstrate how the integration works and how it&rsquo;s configured through a series of hands-on exercises, including installing the integration and installing sub-integrations for specific services, such as AWS Lambda and Amazon RDS. Then you will observe what the integration provides out-of-the-box by touring the resulting metrics, logs, and dashboards in the Datadog app. <br><br> Duration: 2 hours <br><br> Requirements: A modern web browser with WebSockets enabled. <br><br> The session will close with an audience Q&amp;A.","PublishedAt":"2023-01-01 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/event/intro-to-aws-workshop-emea/","SourceName":"Datadog"}},{"node":{"ID":2671,"Title":"The state of HTTP in 2022","Description":"So what happened at all of those working group meetings, specification documents, and side events in 2022? What are implementers and deployers of the web’s protocol doing? And what’s coming next?","PublishedAt":"2022-12-30 14:00:00+00:00","OriginURL":"https://blog.cloudflare.com/the-state-of-http-in-2022/","SourceName":"Cloudflare"}},{"node":{"ID":2672,"Title":"You should be reading academic computer science papers","Description":"<p>You read documentation and tutorials to become a better programmer, but if you really want to be cutting-edge, academic research is where it's at.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/12/30/you-should-be-reading-academic-computer-science-papers/\">You should be reading academic computer science papers</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-12-30 13:56:06+00:00","OriginURL":"https://stackoverflow.blog/2022/12/30/you-should-be-reading-academic-computer-science-papers/","SourceName":"Stack Overflow"}},{"node":{"ID":2670,"Title":"The Overflow #158: Our top blog posts (part 1)","Description":"<p>Terminal tools, defragmenting a SSD, and prompt engineering.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/12/30/the-overflow-158-our-top-blog-posts-part-1/\">The Overflow #158: Our top blog posts (part 1)</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-12-30 13:06:00+00:00","OriginURL":"https://stackoverflow.blog/2022/12/30/the-overflow-158-our-top-blog-posts-part-1/","SourceName":"Stack Overflow"}},{"node":{"ID":2669,"Title":"Blog: Kubernetes v1.26: Advancements in Kubernetes Traffic Engineering","Description":"<p><strong>Authors:</strong> Andrew Sy Kim (Google)</p>\n<p>Kubernetes v1.26 includes significant advancements in network traffic engineering with the graduation of\ntwo features (Service internal traffic policy support, and EndpointSlice terminating conditions) to GA,\nand a third feature (Proxy terminating endpoints) to beta. The combination of these enhancements aims\nto address short-comings in traffic engineering that people face today, and unlock new capabilities for the future.</p>\n<h2 id=\"traffic-loss-from-load-balancers-during-rolling-updates\">Traffic Loss from Load Balancers During Rolling Updates</h2>\n<p>Prior to Kubernetes v1.26, clusters could experience <a href=\"https://github.com/kubernetes/kubernetes/issues/85643\">loss of traffic</a>\nfrom Service load balancers during rolling updates when setting the <code>externalTrafficPolicy</code> field to <code>Local</code>.\nThere are a lot of moving parts at play here so a quick overview of how Kubernetes manages load balancers might help!</p>\n<p>In Kubernetes, you can create a Service with <code>type: LoadBalancer</code> to expose an application externally with a load balancer.\nThe load balancer implementation varies between clusters and platforms, but the Service provides a generic abstraction\nrepresenting the load balancer that is consistent across all Kubernetes installations.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Service<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>my-service<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">selector</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">app.kubernetes.io/name</span>:<span style=\"color:#bbb\"> </span>my-app<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ports</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">protocol</span>:<span style=\"color:#bbb\"> </span>TCP<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">80</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">targetPort</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">9376</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>LoadBalancer<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Under the hood, Kubernetes allocates a NodePort for the Service, which is then used by kube-proxy to provide a\nnetwork data path from the NodePort to the Pod. A controller will then add all available Nodes in the cluster\nto the load balancer’s backend pool, using the designated NodePort for the Service as the backend target port.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2022/12/30/advancements-in-kubernetes-traffic-engineering/traffic-engineering-service-load-balancer.png\"\nalt=\"Figure 1: Overview of Service load balancers\"/> <figcaption>\n<p>Figure 1: Overview of Service load balancers</p>\n</figcaption>\n</figure>\n<p>Oftentimes it is beneficial to set <code>externalTrafficPolicy: Local</code> for Services, to avoid extra hops between\nNodes that are not running healthy Pods backing that Service. When using <code>externalTrafficPolicy: Local</code>,\nan additional NodePort is allocated for health checking purposes, such that Nodes that do not contain healthy\nPods are excluded from the backend pool for a load balancer.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2022/12/30/advancements-in-kubernetes-traffic-engineering/traffic-engineering-lb-healthy.png\"\nalt=\"Figure 2: Load balancer traffic to a healthy Node, when externalTrafficPolicy is Local\"/> <figcaption>\n<p>Figure 2: Load balancer traffic to a healthy Node, when externalTrafficPolicy is Local</p>\n</figcaption>\n</figure>\n<p>One such scenario where traffic can be lost is when a Node loses all Pods for a Service,\nbut the external load balancer has not probed the health check NodePort yet. The likelihood of this situation\nis largely dependent on the health checking interval configured on the load balancer. The larger the interval,\nthe more likely this will happen, since the load balancer will continue to send traffic to a node\neven after kube-proxy has removed forwarding rules for that Service. This also occurrs when Pods start terminating\nduring rolling updates. Since Kubernetes does not consider terminating Pods as “Ready”, traffic can be loss\nwhen there are only terminating Pods on any given Node during a rolling update.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2022/12/30/advancements-in-kubernetes-traffic-engineering/traffic-engineering-lb-without-proxy-terminating-endpoints.png\"\nalt=\"Figure 3: Load balancer traffic to terminating endpoints, when externalTrafficPolicy is Local\"/> <figcaption>\n<p>Figure 3: Load balancer traffic to terminating endpoints, when externalTrafficPolicy is Local</p>\n</figcaption>\n</figure>\n<p>Starting in Kubernetes v1.26, kube-proxy enables the <code>ProxyTerminatingEndpoints</code> feature by default, which\nadds automatic failover and routing to terminating endpoints in scenarios where the traffic would otherwise\nbe dropped. More specifically, when there is a rolling update and a Node only contains terminating Pods,\nkube-proxy will route traffic to the terminating Pods based on their readiness. In addition, kube-proxy will\nactively fail the health check NodePort if there are only terminating Pods available. By doing so,\nkube-proxy alerts the external load balancer that new connections should not be sent to that Node but will\ngracefully handle requests for existing connections.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2022/12/30/advancements-in-kubernetes-traffic-engineering/traffic-engineering-lb-with-proxy-terminating-endpoints.png\"\nalt=\"Figure 4: Load Balancer traffic to terminating endpoints with ProxyTerminatingEndpoints enabled, when externalTrafficPolicy is Local\"/> <figcaption>\n<p>Figure 4: Load Balancer traffic to terminating endpoints with ProxyTerminatingEndpoints enabled, when externalTrafficPolicy is Local</p>\n</figcaption>\n</figure>\n<h3 id=\"endpointslice-conditions\">EndpointSlice Conditions</h3>\n<p>In order to support this new capability in kube-proxy, the EndpointSlice API introduced new conditions for endpoints:\n<code>serving</code> and <code>terminating</code>.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2022/12/30/advancements-in-kubernetes-traffic-engineering/endpointslice-overview.png\"\nalt=\"Figure 5: Overview of EndpointSlice conditions\"/> <figcaption>\n<p>Figure 5: Overview of EndpointSlice conditions</p>\n</figcaption>\n</figure>\n<p>The <code>serving</code> condition is semantically identical to <code>ready</code>, except that it can be <code>true</code> or <code>false</code>\nwhile a Pod is terminating, unlike <code>ready</code> which will always be <code>false</code> for terminating Pods for compatibility reasons.\nThe <code>terminating</code> condition is true for Pods undergoing termination (non-empty deletionTimestamp), false otherwise.</p>\n<p>The addition of these two conditions enables consumers of this API to understand Pod states that were previously not possible.\nFor example, we can now track &quot;ready&quot; and &quot;not ready&quot; Pods that are also terminating.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2022/12/30/advancements-in-kubernetes-traffic-engineering/endpointslice-with-terminating-pod.png\"\nalt=\"Figure 6: EndpointSlice conditions with a terminating Pod\"/> <figcaption>\n<p>Figure 6: EndpointSlice conditions with a terminating Pod</p>\n</figcaption>\n</figure>\n<p>Consumers of the EndpointSlice API, such as Kube-proxy and Ingress Controllers, can now use these conditions to coordinate connection draining\nevents, by continuing to forward traffic for existing connections but rerouting new connections to other non-terminating endpoints.</p>\n<h2 id=\"optimizing-internal-node-local-traffic\">Optimizing Internal Node-Local Traffic</h2>\n<p>Similar to how Services can set <code>externalTrafficPolicy: Local</code> to avoid extra hops for externally sourced traffic, Kubernetes\nnow supports <code>internalTrafficPolicy: Local</code>, to enable the same optimization for traffic originating within the cluster, specifically\nfor traffic using the Service Cluster IP as the destination address. This feature graduated to Beta in Kubernetes v1.24 and is graduating to GA in v1.26.</p>\n<p>Services default the <code>internalTrafficPolicy</code> field to <code>Cluster</code>, where traffic is randomly distributed to all endpoints.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2022/12/30/advancements-in-kubernetes-traffic-engineering/service-internal-traffic-policy-cluster.png\"\nalt=\"Figure 7: Service routing when internalTrafficPolicy is Cluster\"/> <figcaption>\n<p>Figure 7: Service routing when internalTrafficPolicy is Cluster</p>\n</figcaption>\n</figure>\n<p>When <code>internalTrafficPolicy</code> is set to <code>Local</code>, kube-proxy will forward internal traffic for a Service only if there is an available endpoint\nthat is local to the same Node.</p>\n<figure>\n<img src=\"https://kubernetes.io/blog/2022/12/30/advancements-in-kubernetes-traffic-engineering/service-internal-traffic-policy-local.png\"\nalt=\"Figure 8: Service routing when internalTrafficPolicy is Local\"/> <figcaption>\n<p>Figure 8: Service routing when internalTrafficPolicy is Local</p>\n</figcaption>\n</figure>\n<div class=\"alert alert-warning caution callout\" role=\"alert\">\n<strong>Caution:</strong> When using <code>internalTrafficPoliy: Local</code>, traffic will be dropped by kube-proxy when no local endpoints are available.\n</div>\n<h2 id=\"getting-involved\">Getting Involved</h2>\n<p>If you're interested in future discussions on Kubernetes traffic engineering, you can get involved in SIG Network through the following ways:</p>\n<ul>\n<li>Slack: <a href=\"https://kubernetes.slack.com/messages/sig-network\">#sig-network</a></li>\n<li><a href=\"https://groups.google.com/forum/#!forum/kubernetes-sig-network\">Mailing list</a></li>\n<li><a href=\"https://github.com/kubernetes/community/labels/sig%2Fnetwork\">Open Community Issues/PRs</a></li>\n<li><a href=\"https://github.com/kubernetes/community/tree/master/sig-network#meetings\">Biweekly meetings</a></li>\n</ul>","PublishedAt":"2022-12-30 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/12/30/advancements-in-kubernetes-traffic-engineering/","SourceName":"Kubernetes"}},{"node":{"ID":2666,"Title":"You should be using HTTP Strict Transport Security (HSTS) headers in your Node.js server","Description":"Take an in-depth look at HTTP Strict Transport Security (HSTS) headers to discover how they affect web security and why we should use them on Node.js. Then, learn how to enable HSTS inside a Node.js server.","PublishedAt":"2022-12-29 15:35:59+00:00","OriginURL":"https://snyk.io/blog/http-strict-transport-security-hsts-headers-node-js/","SourceName":"Snyk"}},{"node":{"ID":2665,"Title":"Remote work is killing big offices. Cities must change to survive","Description":"<p>If your office is where you live now, would you live in your old office?</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/12/29/remote-work-is-killing-big-offices-cities-must-change-to-survive/\">Remote work is killing big offices. Cities must change to survive</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-12-29 14:06:20+00:00","OriginURL":"https://stackoverflow.blog/2022/12/29/remote-work-is-killing-big-offices-cities-must-change-to-survive/","SourceName":"Stack Overflow"}},{"node":{"ID":2664,"Title":"Blog: Kubernetes 1.26: Job Tracking, to Support Massively Parallel Batch Workloads, Is Generally Available","Description":"<p><strong>Authors:</strong> Aldo Culquicondor (Google)</p>\n<p>The Kubernetes 1.26 release includes a stable implementation of the <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/\">Job</a>\ncontroller that can reliably track a large amount of Jobs with high levels of\nparallelism. <a href=\"https://github.com/kubernetes/community/tree/master/sig-apps\">SIG Apps</a>\nand <a href=\"https://github.com/kubernetes/community/tree/master/wg-batch\">WG Batch</a>\nhave worked on this foundational improvement since Kubernetes 1.22. After\nmultiple iterations and scale verifications, this is now the default\nimplementation of the Job controller.</p>\n<p>Paired with the Indexed <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/#completion-mode\">completion mode</a>,\nthe Job controller can handle massively parallel batch Jobs, supporting up to\n100k concurrent Pods.</p>\n<p>The new implementation also made possible the development of <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/#pod-failure-policy\">Pod failure policy</a>,\nwhich is in beta in the 1.26 release.</p>\n<h2 id=\"how-do-i-use-this-feature\">How do I use this feature?</h2>\n<p>To use Job tracking with finalizers, upgrade to Kubernetes 1.25 or newer and\ncreate new Jobs. You can also use this feature in v1.23 and v1.24, if you have the\nability to enable the <code>JobTrackingWithFinalizers</code> <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gate</a>.</p>\n<p>If your cluster runs Kubernetes 1.26, Job tracking with finalizers is a stable\nfeature. For v1.25, it's behind that feature gate, and your cluster administrators may have\nexplicitly disabled it - for example, if you have a policy of not using\nbeta features.</p>\n<p>Jobs created before the upgrade will still be tracked using the legacy behavior.\nThis is to avoid retroactively adding finalizers to running Pods, which might\nintroduce race conditions.</p>\n<p>For maximum performance on large Jobs, the Kubernetes project recommends\nusing the <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/#completion-mode\">Indexed completion mode</a>.\nIn this mode, the control plane is able to track Job progress with less API\ncalls.</p>\n<p>If you are a developer of operator(s) for batch, <a href=\"https://en.wikipedia.org/wiki/High-performance_computing\">HPC</a>,\n<a href=\"https://en.wikipedia.org/wiki/Artificial_intelligence\">AI</a>, <a href=\"https://en.wikipedia.org/wiki/Machine_learning\">ML</a>\nor related workloads, we encourage you to use the Job API to delegate accurate\nprogress tracking to Kubernetes. If there is something missing in the Job API\nthat forces you to manage plain Pods, the <a href=\"https://github.com/kubernetes/community/tree/master/wg-batch\">Working Group Batch</a>\nwelcomes your feedback and contributions.</p>\n<h3 id=\"deprecation-notices\">Deprecation notices</h3>\n<p>During the development of the feature, the control plane added the annotation\n<a href=\"https://kubernetes.io/docs/reference/labels-annotations-taints/#batch-kubernetes-io-job-tracking\"><code>batch.kubernetes.io/job-tracking</code></a>\nto the Jobs that were created when the feature was enabled.\nThis allowed a safe transition for older Jobs, but it was never meant to stay.</p>\n<p>In the 1.26 release, we deprecated the annotation <code>batch.kubernetes.io/job-tracking</code>\nand the control plane will stop adding it in Kubernetes 1.27.\nAlong with that change, we will remove the legacy Job tracking implementation.\nAs a result, the Job controller will track all Jobs using finalizers and it will\nignore Pods that don't have the aforementioned finalizer.</p>\n<p>Before you upgrade your cluster to 1.27, we recommend that you verify that there\nare no running Jobs that don't have the annotation, or you wait for those jobs\nto complete.\nOtherwise, you might observe the control plane recreating some Pods.\nWe expect that this shouldn't affect any users, as the feature is enabled by\ndefault since Kubernetes 1.25, giving enough buffer for old jobs to complete.</p>\n<h2 id=\"what-problem-does-the-new-implementation-solve\">What problem does the new implementation solve?</h2>\n<p>Generally, Kubernetes workload controllers, such as ReplicaSet or StatefulSet,\nrely on the existence of Pods or other objects in the API to determine the\nstatus of the workload and whether replacements are needed.\nFor example, if a Pod that belonged to a ReplicaSet terminates or ceases to\nexist, the ReplicaSet controller needs to create a replacement Pod to satisfy\nthe desired number of replicas (<code>.spec.replicas</code>).</p>\n<p>Since its inception, the Job controller also relied on the existence of Pods in\nthe API to track Job status. A Job has <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/#completion-mode\">completion</a>\nand <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/#handling-pod-and-container-failures\">failure handling</a>\npolicies, requiring the end state of a finished Pod to determine whether to\ncreate a replacement Pod or mark the Job as completed or failed. As a result,\nthe Job controller depended on Pods, even terminated ones, to remain in the API\nin order to keep track of the status.</p>\n<p>This dependency made the tracking of Job status unreliable, because Pods can be\ndeleted from the API for a number of reasons, including:</p>\n<ul>\n<li>The garbage collector removing orphan Pods when a Node goes down.</li>\n<li>The garbage collector removing terminated Pods when they reach a threshold.</li>\n<li>The Kubernetes scheduler preempting a Pod to accomodate higher priority Pods.</li>\n<li>The taint manager evicting a Pod that doesn't tolerate a <code>NoExecute</code> taint.</li>\n<li>External controllers, not included as part of Kubernetes, or humans deleting\nPods.</li>\n</ul>\n<h3 id=\"the-new-implementation\">The new implementation</h3>\n<p>When a controller needs to take an action on objects before they are removed, it\nshould add a <a href=\"https://kubernetes.io/docs/concepts/overview/working-with-objects/finalizers/\">finalizer</a>\nto the objects that it manages.\nA finalizer prevents the objects from being deleted from the API until the\nfinalizers are removed. Once the controller is done with the cleanup and\naccounting for the deleted object, it can remove the finalizer from the object and the\ncontrol plane removes the object from the API.</p>\n<p>This is what the new Job controller is doing: adding a finalizer during Pod\ncreation, and removing the finalizer after the Pod has terminated and has been\naccounted for in the Job status. However, it wasn't that simple.</p>\n<p>The main challenge is that there are at least two objects involved: the Pod\nand the Job. While the finalizer lives in the Pod object, the accounting lives\nin the Job object. There is no mechanism to atomically remove the finalizer in\nthe Pod and update the counters in the Job status. Additionally, there could be\nmore than one terminated Pod at a given time.</p>\n<p>To solve this problem, we implemented a three staged approach, each translating\nto an API call.</p>\n<ol>\n<li>For each terminated Pod, add the unique ID (UID) of the Pod into short-lived\nlists stored in the <code>.status</code> of the owning Job\n(<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/job-v1/#JobStatus\">.status.uncountedTerminatedPods</a>).</li>\n<li>Remove the finalizer from the Pods(s).</li>\n<li>Atomically do the following operations:\n<ul>\n<li>remove UIDs from the short-lived lists</li>\n<li>increment the overall <code>succeeded</code> and <code>failed</code> counters in the <code>status</code> of\nthe Job.</li>\n</ul>\n</li>\n</ol>\n<p>Additional complications come from the fact that the Job controller might\nreceive the results of the API changes in steps 1 and 2 out of order. We solved\nthis by adding an in-memory cache for removed finalizers.</p>\n<p>Still, we faced some issues during the beta stage, leaving some pods stuck\nwith finalizers in some conditions (<a href=\"https://github.com/kubernetes/kubernetes/issues/108645\">#108645</a>,\n<a href=\"https://github.com/kubernetes/kubernetes/issues/109485\">#109485</a>, and\n<a href=\"https://github.com/kubernetes/kubernetes/pull/111646\">#111646</a>). As a result,\nwe decided to switch that feature gate to be disabled by default for the 1.23\nand 1.24 releases.</p>\n<p>Once resolved, we re-enabled the feature for the 1.25 release. Since then, we\nhave received reports from our customers running tens of thousands of Pods at a\ntime in their clusters through the Job API. Seeing this success, we decided to\ngraduate the feature to stable in 1.26, as part of our long term commitment to\nmake the Job API the best way to run large batch Jobs in a Kubernetes cluster.</p>\n<p>To learn more about the feature, you can read the <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-apps/2307-job-tracking-without-lingering-pods\">KEP</a>.</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>As with any Kubernetes feature, multiple people contributed to getting this\ndone, from testing and filing bugs to reviewing code.</p>\n<p>On behalf of SIG Apps, I would like to especially thank Jordan Liggitt (Google)\nfor helping me debug and brainstorm solutions for more than one race condition\nand Maciej Szulik (Red Hat) for his thorough reviews.</p>","PublishedAt":"2022-12-29 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/12/29/scalable-job-tracking-ga/","SourceName":"Kubernetes"}},{"node":{"ID":2668,"Title":"Datadog Spotlight: Cansu Berkem","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-spotlight-cansu-berkem/employee_spotlight_cansu.png\" width=\"100%\"/>We’re excited to introduce Cansu Berkem, a Group Product Manager based in New York City, for this month’s Datadog Spotlight. As a Group Product Manager, Cansu leads a team of Product Managers (PMs) and covers multiple product areas, such as Incident Management, Cloudcraft, Mobile Applications, and collaboration integrations. We spoke with Cansu to discuss her journey with Datadog, some of the exciting things she’s worked on this year, and the culture of the Product Management team.","PublishedAt":"2022-12-29 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/pup-culture/datadog-spotlight-cansu-berkem/","SourceName":"Datadog"}},{"node":{"ID":2661,"Title":"How to build a secure API gateway in Node.js","Description":"In this article, we’ll build a secure API gateway from scratch using only Node.js and a couple of open source packages. All you need is basic knowledge of your terminal, Node.js version 14 or later, and JavaScript.","PublishedAt":"2022-12-28 15:00:00+00:00","OriginURL":"https://snyk.io/blog/how-to-build-secure-api-gateway-node-js/","SourceName":"Snyk"}},{"node":{"ID":2660,"Title":"Evernote’s Parade of Features, Part Five: Improve Workflow on the Web","Description":"<p>In the final installment of this features series, learn how to improve your Evernote workflow while using the web version of our platform.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://evernote.com/blog/improve-workflow-on-web/\">Evernote&#8217;s Parade of Features, Part Five: Improve Workflow on the Web</a> appeared first on <a rel=\"nofollow\" href=\"https://evernote.com/blog\"></a>.</p>\n","PublishedAt":"2022-12-28 14:30:00+00:00","OriginURL":"https://evernote.com/blog/improve-workflow-on-web/","SourceName":"Evernote"}},{"node":{"ID":2659,"Title":"The Great Resignation is here. What does that mean for developers?","Description":"<p>Nearly two years into the pandemic, many Americans are reevaluating their relationship with work.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/12/28/the-great-resignation-is-here-what-does-that-mean-for-developers/\">The Great Resignation is here. What does that mean for developers?</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-12-28 14:00:00+00:00","OriginURL":"https://stackoverflow.blog/2022/12/28/the-great-resignation-is-here-what-does-that-mean-for-developers/","SourceName":"Stack Overflow"}},{"node":{"ID":2662,"Title":"Service-Specific and Other Supplemental Terms","Description":"Capitalized terms not otherwise defined in these Terms will have the respective meanings assigned to them in the Master Subscription Agreement at https://www.datadoghq.com/legal/msa/ (the &ldquo;MSA&rdquo;). Datadog may modify these Terms from time to time, subject to Section 30 of the MSA.These Terms are in addition to the MSA, the Free-Trial Terms at https://www.datadoghq.com/legal/free-trial-agreement/, the Pass-Through Terms of Use at https://www.datadoghq.com/legal/pass-through/ and any separately executed agreement for Services between Datadog and Customer (each, as applicable, the &ldquo;Agreement&rdquo;).","PublishedAt":"2022-12-28 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/legal/service-terms/2022-12-28/","SourceName":"Datadog"}},{"node":{"ID":2663,"Title":"Applicant and Candidate Privacy Notice","Description":"At Datadog, we care about your privacy. That’s why every candidate for employment with us receives this notice, which explains what information Datadog (“we,” “us,” “our”) collects about you during our hiring process, why we collect and how we use your information, and what your rights are related to your information. Please note that your use of any Datadog service or website is also governed by our general Privacy Policy.","PublishedAt":"2022-12-28 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/legal/applicant-candidate-privacy/2022-12-28/","SourceName":"Datadog"}},{"node":{"ID":2667,"Title":"Vendor Travel and Expense Policy","Description":"Datadog will only be responsible for reasonable expenses (such as travel, lodging, and meals) in accordance with Datadog’s travel and expense policy, and in connection with a duly executed agreement between Vendor and Datadog.Transportation and lodging shall be booked through a TripActions link that Datadog will provide. Transportation and lodging shall only be booked after an agreement between Vendor and Datadog is executed.All reimbursable expenses must be itemized with copies of all receipts.","PublishedAt":"2022-12-28 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/legal/vendor-travel-policy/2022-12-28/","SourceName":"Datadog"}},{"node":{"ID":2658,"Title":"5 “no experience needed” tips for building secure applications","Description":"Learn about the developer security tooling from Snyk that will help you level up your skills to find and fix security vulnerabilities in the code you write and the dependencies you use so you can build secure applications.","PublishedAt":"2022-12-27 16:21:01+00:00","OriginURL":"https://snyk.io/blog/no-experience-needed-secure-applications/","SourceName":"Snyk"}},{"node":{"ID":2656,"Title":"Picture perfect images with the modern <img> element","Description":"<p>You may not think about images as part of your web dev work, but they can affect your web app's performance more than any other part of your code. </p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/12/27/picture-perfect-images-with-the-modern-element/\">Picture perfect images with the modern &lt;img&gt; element</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-12-27 14:00:00+00:00","OriginURL":"https://stackoverflow.blog/2022/12/27/picture-perfect-images-with-the-modern-element/","SourceName":"Stack Overflow"}},{"node":{"ID":2655,"Title":"Blog: Kubernetes v1.26: CPUManager goes GA","Description":"<p><strong>Author:</strong>\nFrancesco Romani (Red Hat)</p>\n<p>The CPU Manager is a part of the kubelet, the Kubernetes node agent, which enables the user to allocate exclusive CPUs to containers.\nSince Kubernetes v1.10, where it <a href=\"https://kubernetes.io/blog/2018/07/24/feature-highlight-cpu-manager/\">graduated to Beta</a>, the CPU Manager proved itself reliable and\nfulfilled its role of allocating exclusive CPUs to containers, so adoption has steadily grown making it a staple component of performance-critical\nand low-latency setups. Over time, most changes were about bugfixes or internal refactoring, with the following noteworthy user-visible changes:</p>\n<ul>\n<li><a href=\"https://github.com/Kubernetes/Kubernetes/pull/83592\">support explicit reservation of CPUs</a>: it was already possible to request to reserve a given\nnumber of CPUs for system resources, including the kubelet itself, which will not be used for exclusive CPU allocation. Now it is possible to also\nexplicitly select which CPUs to reserve instead of letting the kubelet pick them up automatically.</li>\n<li><a href=\"https://github.com/Kubernetes/Kubernetes/pull/97415\">report the exclusively allocated CPUs</a> to containers, much like is already done for devices,\nusing the kubelet-local <a href=\"https://kubernetes.io/docs/concepts/extend-Kubernetes/compute-storage-net/device-plugins/#monitoring-device-plugin-resources\">PodResources API</a>.</li>\n<li><a href=\"https://github.com/Kubernetes/Kubernetes/pull/101771\">optimize the usage of system resources</a>, eliminating unnecessary sysfs changes.</li>\n</ul>\n<p>The CPU Manager reached the point on which it &quot;just works&quot;, so in Kubernetes v1.26 it has graduated to generally available (GA).</p>\n<h2 id=\"cpu-managed-customization\">Customization options for CPU Manager</h2>\n<p>The CPU Manager supports two operation modes, configured using its <em>policies</em>. With the <code>none</code> policy, the CPU Manager allocates CPUs to containers\nwithout any specific constraint except the (optional) quota set in the Pod spec.\nWith the <code>static</code> policy, then provided that the pod is in the Guaranteed QoS class and every container in that Pod requests an integer amount of vCPU cores,\nthen the CPU Manager allocates CPUs exclusively. Exclusive assignment means that other containers (whether from the same Pod, or from a different Pod) do not\nget scheduled onto that CPU.</p>\n<p>This simple operational model served the user base pretty well, but as the CPU Manager matured more and more, users started to look at more elaborate use\ncases and how to better support them.</p>\n<p>Rather than add more policies, the community realized that pretty much all the novel use cases are some variation of the behavior enabled by the <code>static</code>\nCPU Manager policy. Hence, it was decided to add <a href=\"https://github.com/Kubernetes/enhancements/tree/master/keps/sig-node/2625-cpumanager-policies-thread-placement#proposed-change\">options to tune the behavior of the static policy</a>.\nThe options have a varying degree of maturity, like any other Kubernetes feature, and in order to be accepted, each new option provides a backward\ncompatible behavior when disabled, and to document how to interact with each other, should they interact at all.</p>\n<p>This enabled the Kubernetes project to graduate to GA the CPU Manager core component and core CPU allocation algorithms to GA,\nwhile also enabling a new age of experimentation in this area.\nIn Kubernetes v1.26, the CPU Manager supports <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies.md#static-policy-options\">three different policy options</a>:</p>\n<dl>\n<dt><code>full-pcpus-only</code></dt>\n<dd>restrict the CPU Manager core allocation algorithm to full physical cores only, reducing noisy neighbor issues from hardware technologies that allow sharing cores.</dd>\n<dt><code>distribute-cpus-across-numa</code></dt>\n<dd>drive the CPU Manager to evenly distribute CPUs across NUMA nodes, for cases where more than one NUMA node is required to satisfy the allocation.</dd>\n<dt><code>align-by-socket</code></dt>\n<dd>change how the CPU Manager allocates CPUs to a container: consider CPUs to be aligned at the socket boundary, instead of NUMA node boundary.</dd>\n</dl>\n<h2 id=\"further-development\">Further development</h2>\n<p>After graduating the main CPU Manager feature, each existing policy option will follow their graduation process, independent from CPU Manager and from each other option.\nThere is room for new options to be added, but there's also a growing demand for even more flexibility than what the CPU Manager, and its policy options, currently grant.</p>\n<p>Conversations are in progress in the community about splitting the CPU Manager and the other resource managers currently part of the kubelet executable\ninto pluggable, independent kubelet plugins. If you are interested in this effort, please join the conversation on SIG Node communication channels (Slack, mailing list, weekly meeting).</p>\n<h2 id=\"further-reading\">Further reading</h2>\n<p>Please check out the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/\">Control CPU Management Policies on the Node</a>\ntask page to learn more about the CPU Manager, and how it fits in relation to the other node-level resource managers.</p>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p>This feature is driven by the <a href=\"https://github.com/Kubernetes/community/blob/master/sig-node/README.md\">SIG Node</a> community.\nPlease join us to connect with the community and share your ideas and feedback around the above feature and\nbeyond. We look forward to hearing from you!</p>","PublishedAt":"2022-12-27 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/12/27/cpumanager-ga/","SourceName":"Kubernetes"}},{"node":{"ID":2657,"Title":"Perf8: Performance metrics for Python","Description":"","PublishedAt":"2022-12-27 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/perf8-performance-metrics-for-python","SourceName":"Elastic"}},{"node":{"ID":2653,"Title":"Supply-Chain Security: Evaluation of Threats and Mitigations","Description":"<p>This article is a translation of the Japanese article published on December 15th, 2022. Abstract This blog details our research into attacks and mitigations related to supply chain security, and more practical applications of supply chain security. In our research, we took an approach that leveraged a more concretely defined pipeline model than existing frameworks [&hellip;]</p>\n","PublishedAt":"2022-12-26 17:00:02+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20221215-supplychain-security-reevaluation/","SourceName":"Mercari"}},{"node":{"ID":2654,"Title":"Why the number input is the worst input","Description":"<p>Think that web form has got your number? If you used input type=\"number\", you may be surprised to find that it doesn't. </p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/12/26/why-the-number-input-is-the-worst-input/\">Why the number input is the worst input</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-12-26 14:00:00+00:00","OriginURL":"https://stackoverflow.blog/2022/12/26/why-the-number-input-is-the-worst-input/","SourceName":"Stack Overflow"}},{"node":{"ID":2652,"Title":"Our journey of upgrading the Lookup codebase to React 18","Description":"","PublishedAt":"2022-12-26 07:30:18+00:00","OriginURL":"https://medium.com/engineering-housing/our-journey-of-upgrading-the-lookup-codebase-to-react-18-d2a4e2d7eb29?source=rss----3a69e32e2594---4","SourceName":"Housing.com"}},{"node":{"ID":2649,"Title":"Data Deduplication","Description":"","PublishedAt":"2022-12-26 07:26:30+00:00","OriginURL":"https://medium.com/engineering-housing/account-deduplication-d3126aa3355c?source=rss----3a69e32e2594---4","SourceName":"Housing.com"}},{"node":{"ID":2650,"Title":"Establishing robust communication between Micro-services","Description":"","PublishedAt":"2022-12-26 07:21:30+00:00","OriginURL":"https://medium.com/engineering-housing/establishing-robust-communication-between-micro-services-c47337c7ca78?source=rss----3a69e32e2594---4","SourceName":"Housing.com"}},{"node":{"ID":2651,"Title":"Hybrid test framework for Java applications","Description":"","PublishedAt":"2022-12-26 07:13:51+00:00","OriginURL":"https://medium.com/engineering-housing/hybrid-test-framework-for-java-applications-71f0a7b42548?source=rss----3a69e32e2594---4","SourceName":"Housing.com"}},{"node":{"ID":2648,"Title":"Blog: Kubernetes 1.26: Pod Scheduling Readiness","Description":"<p><strong>Author:</strong> Wei Huang (Apple), Abdullah Gharaibeh (Google)</p>\n<p>Kubernetes 1.26 introduced a new Pod feature: <em>scheduling gates</em>. In Kubernetes, scheduling gates\nare keys that tell the scheduler when a Pod is ready to be considered for scheduling.</p>\n<h2 id=\"what-problem-does-it-solve\">What problem does it solve?</h2>\n<p>When a Pod is created, the scheduler will continuously attempt to find a node that fits it. This\ninfinite loop continues until the scheduler either finds a node for the Pod, or the Pod gets deleted.</p>\n<p>Pods that remain unschedulable for long periods of time (e.g., ones that are blocked on some external event)\nwaste scheduling cycles. A scheduling cycle may take ≅20ms or more depending on the complexity of\nthe Pod's scheduling constraints. Therefore, at scale, those wasted cycles significantly impact the\nscheduler's performance. See the arrows in the &quot;scheduler&quot; box below.</p>\n<figure>\n<div class=\"mermaid\">\ngraph LR;\npod((New Pod))-->queue\nsubgraph Scheduler\nqueue(scheduler queue)\nsched_cycle[/scheduling cycle/]\nschedulable{schedulable?}\nqueue==>|Pop out|sched_cycle\nsched_cycle==>schedulable\nschedulable==>|No|queue\nsubgraph note [Cycles wasted on keep rescheduling 'unready' Pods]\nend\nend\nclassDef plain fill:#ddd,stroke:#fff,stroke-width:1px,color:#000;\nclassDef k8s fill:#326ce5,stroke:#fff,stroke-width:1px,color:#fff;\nclassDef Scheduler fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;\nclassDef note fill:#edf2ae,stroke:#fff,stroke-width:1px;\nclass queue,sched_cycle,schedulable k8s;\nclass pod plain;\nclass note note;\nclass Scheduler Scheduler;\n</div>\n</figure>\n<noscript>\n<div class=\"alert alert-secondary callout\" role=\"alert\">\n<em class=\"javascript-required\">JavaScript must be <a href=\"https://www.enable-javascript.com/\">enabled</a> to view this content</em>\n</div>\n</noscript>\n<p>Scheduling gates helps address this problem. It allows declaring that newly created Pods are not\nready for scheduling. When scheduling gates are present on a Pod, the scheduler ignores the Pod\nand therefore saves unnecessary scheduling attempts. Those Pods will also be ignored by Cluster\nAutoscaler if you have it installed in the cluster.</p>\n<p>Clearing the gates is the responsibility of external controllers with knowledge of when the Pod\nshould be considered for scheduling (e.g., a quota manager).</p>\n<figure>\n<div class=\"mermaid\">\ngraph LR;\npod((New Pod))-->queue\nsubgraph Scheduler\nqueue(scheduler queue)\nsched_cycle[/scheduling cycle/]\nschedulable{schedulable?}\npopout{Pop out?}\nqueue==>|PreEnqueue check|popout\npopout-->|Yes|sched_cycle\npopout==>|No|queue\nsched_cycle-->schedulable\nschedulable-->|No|queue\nsubgraph note [A knob to gate Pod's scheduling]\nend\nend\nclassDef plain fill:#ddd,stroke:#fff,stroke-width:1px,color:#000;\nclassDef k8s fill:#326ce5,stroke:#fff,stroke-width:1px,color:#fff;\nclassDef Scheduler fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;\nclassDef note fill:#edf2ae,stroke:#fff,stroke-width:1px;\nclassDef popout fill:#f96,stroke:#fff,stroke-width:1px;\nclass queue,sched_cycle,schedulable k8s;\nclass pod plain;\nclass note note;\nclass popout popout;\nclass Scheduler Scheduler;\n</div>\n</figure>\n<noscript>\n<div class=\"alert alert-secondary callout\" role=\"alert\">\n<em class=\"javascript-required\">JavaScript must be <a href=\"https://www.enable-javascript.com/\">enabled</a> to view this content</em>\n</div>\n</noscript>\n<h2 id=\"how-does-it-work\">How does it work?</h2>\n<p>Scheduling gates in general works very similar to Finalizers. Pods with a non-empty\n<code>spec.schedulingGates</code> field will show as status <code>SchedulingGated</code> and be blocked from\nscheduling. Note that more than one gate can be added, but they all should be added upon Pod\ncreation (e.g., you can add them as part of the spec or via a mutating webhook).</p>\n<pre tabindex=\"0\"><code>NAME READY STATUS RESTARTS AGE\ntest-pod 0/1 SchedulingGated 0 10s\n</code></pre><p>To clear the gates, you update the Pod by removing all of the items from the Pod's <code>schedulingGates</code>\nfield. The gates do not need to be removed all at once, but only when all the gates are removed the\nscheduler will start to consider the Pod for scheduling.</p>\n<p>Under the hood, scheduling gates are implemented as a PreEnqueue scheduler plugin, a new scheduler\nframework extension point that is invoked at the beginning of each scheduling cycle.</p>\n<h2 id=\"use-cases\">Use Cases</h2>\n<p>An important use case this feature enables is dynamic quota management. Kubernetes supports\n<a href=\"https://kubernetes.io/docs/concepts/policy/resource-quotas/\">ResourceQuota</a>, however the API Server enforces quota at\nthe time you attempt Pod creation. For example, if a new Pod exceeds the CPU quota, it gets rejected.\nThe API Server doesn't queue the Pod; therefore, whoever created the Pod needs to continuously attempt\nto recreate it again. This either means a delay between resources becoming available and the Pod\nactually running, or it means load on the API server and Scheduler due to constant attempts.</p>\n<p>Scheduling gates allows an external quota manager to address the above limitation of ResourceQuota.\nSpecifically, the manager could add a <code>example.com/quota-check</code> scheduling gate to all Pods created in the\ncluster (using a mutating webhook). The manager would then remove the gate when there is quota to\nstart the Pod.</p>\n<h2 id=\"whats-next\">Whats next?</h2>\n<p>To use this feature, the <code>PodSchedulingReadiness</code> feature gate must be enabled in the API Server\nand scheduler. You're more than welcome to test it out and tell us (SIG Scheduling) what you think!</p>\n<h2 id=\"additional-resources\">Additional resources</h2>\n<ul>\n<li><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-scheduling-readiness/\">Pod Scheduling Readiness</a>\nin the Kubernetes documentation</li>\n<li><a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-scheduling/3521-pod-scheduling-readiness/README.md\">Kubernetes Enhancement Proposal</a></li>\n</ul>","PublishedAt":"2022-12-26 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/12/26/pod-scheduling-readiness-alpha/","SourceName":"Kubernetes"}},{"node":{"ID":2647,"Title":"Look back of Mercari Engineering 2022","Description":"<p>Hi this is @yasu_shiwaku from the Engineering Office. This is the last article for Mercari Advent Calendar 2022. As introduced in the Advent Calendar up to today, Mercari Engineering Organization was taking on many projects in 2022. Mercari Shops, the B2C marketplace platform operated by the subsidiary company Souzoh, has reached its 1st anniversary from [&hellip;]</p>\n","PublishedAt":"2022-12-25 11:00:07+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20221225-mercari-engineering-lookback-2022/","SourceName":"Mercari"}},{"node":{"ID":2646,"Title":"A brief story about the rotation program and my role in it","Description":"<p>This post is for Day 24 of Merpay Advent Calendar 2022, brought to you by @ntk1000 from the Merpay Trust &amp; Safety(TnS) Platform. I’m working as an Engineering Manager at Merpay, in charge of the Trust &amp; Safety(TnS) Platform team. I joined Merpay in 2019, Dec., and I’ve been in charge of multiple backend teams [&hellip;]</p>\n","PublishedAt":"2022-12-24 12:00:20+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20221222-a-brief-story-about-the-rotation-program-and-my-role-in-it/","SourceName":"Mercari"}}]}},"pageContext":{"limit":30,"skip":3090,"numPages":193,"currentPage":104}},"staticQueryHashes":["3649515864"]}