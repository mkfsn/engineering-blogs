{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/173","result":{"data":{"allPost":{"edges":[{"node":{"ID":1270,"Title":"How Safari crashes the graphics driver","Description":"","PublishedAt":"2021-10-13 06:54:11+00:00","OriginURL":"https://medium.com/miro-engineering/how-safari-crashes-the-graphics-driver-1b56cd80f564?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":784,"Title":"Tiny Letter from Kafka","Description":"This article discusses the powerful design choice of Apache Kafka, “an open-source distributed event streaming platform,” and gives a sneak…","PublishedAt":"2021-10-13 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/tiny-letter-from-kafka","SourceName":"Soundcloud"}},{"node":{"ID":434,"Title":"How (and Why) Postman Engineering Uses Foundation Teams","Description":"","PublishedAt":"2021-10-11 23:08:05+00:00","OriginURL":"https://medium.com/better-practices/how-and-why-postman-engineering-uses-foundation-teams-4acadab0f003?source=rss----410f2fbc015d---4","SourceName":"Postman"}},{"node":{"ID":1251,"Title":"Blog: Introducing ClusterClass and Managed Topologies in Cluster API","Description":"<p><strong>Author:</strong> Fabrizio Pandini (VMware)</p>\n<p>The <a href=\"https://cluster-api.sigs.k8s.io/\">Cluster API community</a> is happy to announce the implementation of <em>ClusterClass and Managed Topologies</em>, a new feature that will greatly simplify how you can provision, upgrade, and operate multiple Kubernetes clusters in a declarative way.</p>\n<h2 id=\"a-little-bit-of-context\">A little bit of context…</h2>\n<p>Before getting into the details, let's take a step back and look at the history of Cluster API.</p>\n<p>The <a href=\"https://github.com/kubernetes-sigs/cluster-api/\">Cluster API project</a> started three years ago, and the first releases focused on extensibility and implementing a declarative API that allows a seamless experience across infrastructure providers. This was a success with many cloud providers: AWS, Azure, Digital Ocean, GCP, Metal3, vSphere and still counting.</p>\n<p>With extensibility addressed, the focus shifted to features, like automatic control plane and etcd management, health-based machine remediation, machine rollout strategies and more.</p>\n<p>Fast forwarding to 2021, with lots of companies using Cluster API to manage fleets of Kubernetes clusters running workloads in production, the community focused its effort on stabilization of both code, APIs, documentation, and on extensive test signals which inform Kubernetes releases.</p>\n<p>With solid foundations in place, and a vibrant and welcoming community that still continues to grow, it was time to plan another iteration on our UX for both new and advanced users.</p>\n<p>Enter ClusterClass and Managed Topologies, tada!</p>\n<h2 id=\"clusterclass\">ClusterClass</h2>\n<p>As the name suggests, ClusterClass and managed topologies are built in two parts.</p>\n<p>The idea behind ClusterClass is simple: define the shape of your cluster once, and reuse it many times, abstracting the complexities and the internals of a Kubernetes cluster away.</p>\n<p><img src=\"https://kubernetes.io/images/blog/2021-10-08-clusterclass-and-managed-topologies/clusterclass.svg\" alt=\"Defining a ClusterClass\"></p>\n<p>ClusterClass, at its heart, is a collection of Cluster and Machine templates. You can use it as a “stamp” that can be leveraged to create many clusters of a similar shape.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#00f;font-weight:bold\">---</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>cluster.x-k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>ClusterClass<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>my-amazing-cluster-class<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">controlPlane</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ref</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>controlplane.cluster.x-k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>KubeadmControlPlaneTemplate<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>high-availability-control-plane<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">machineInfrastructure</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ref</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>infrastructure.cluster.x-k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>DockerMachineTemplate<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>control-plane-machine<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">workers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">machineDeployments</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">class</span>:<span style=\"color:#bbb\"> </span>type1-workers<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">template</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">bootstrap</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ref</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>bootstrap.cluster.x-k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>KubeadmConfigTemplate<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>type1-bootstrap<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">infrastructure</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ref</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>infrastructure.cluster.x-k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>DockerMachineTemplate<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>type1-machine<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">class</span>:<span style=\"color:#bbb\"> </span>type2-workers<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">template</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">bootstrap</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ref</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>bootstrap.cluster.x-k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>KubeadmConfigTemplate<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>type2-bootstrap<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">infrastructure</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ref</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>DockerMachineTemplate<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>infrastructure.cluster.x-k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>type2-machine<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">infrastructure</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ref</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>infrastructure.cluster.x-k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>DockerClusterTemplate<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>cluster-infrastructure<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>The possibilities are endless; you can get a default ClusterClass from the community, “off-the-shelf” classes from your vendor of choice, “certified” classes from the platform admin in your company, or even create custom ones for advanced scenarios.</p>\n<h2 id=\"managed-topologies\">Managed Topologies</h2>\n<p>Managed Topologies let you put the power of ClusterClass into action.</p>\n<p>Given a ClusterClass, you can create many Clusters of a similar shape by providing a single resource, the Cluster.</p>\n<p><img src=\"https://kubernetes.io/images/blog/2021-10-08-clusterclass-and-managed-topologies/create-cluster.svg\" alt=\"Create a Cluster with ClusterClass\"></p>\n<p>Here is an example:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#00f;font-weight:bold\">---</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>cluster.x-k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Cluster<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>my-amazing-cluster<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>bar<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">topology</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># define a managed topology</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">class</span>:<span style=\"color:#bbb\"> </span>my-amazing-cluster-class<span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># use the ClusterClass mentioned earlier</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">version</span>:<span style=\"color:#bbb\"> </span>v1.21.2<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">controlPlane</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">replicas</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">3</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">workers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">machineDeployments</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">class</span>:<span style=\"color:#bbb\"> </span>type1-workers<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>big-pool-of-machines<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">replicas</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">5</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">class</span>:<span style=\"color:#bbb\"> </span>type2-workers<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>small-pool-of-machines<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">replicas</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">1</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>But there is more than simplified cluster creation. Now the Cluster acts as a single control point for your entire topology.</p>\n<p>All the power of Cluster API, extensibility, lifecycle automation, stability, all the features required for managing an enterprise grade Kubernetes cluster on the infrastructure provider of your choice are now at your fingertips: you can create your Cluster, add new machines, upgrade to the next Kubernetes version, and all from a single place.</p>\n<p>It is just as simple as it looks!</p>\n<h2 id=\"what-s-next\">What’s next</h2>\n<p>While the amazing Cluster API community is working hard to deliver the first version of ClusterClass and managed topologies later this year, we are already looking forward to what comes next for the project and its ecosystem.</p>\n<p>There are a lot of great ideas and opportunities ahead!</p>\n<p>We want to make managed topologies even more powerful and flexible, allowing users to dynamically change bits of a ClusterClass according to the specific needs of a Cluster; this will ensure the same simple and intuitive UX for solving complex problems like e.g. selecting machine image for a specific Kubernetes version and for a specific region of your infrastructure provider, or injecting proxy configurations in the entire Cluster, and so on.</p>\n<p>Stay tuned for what comes next, and if you have any questions, comments or suggestions:</p>\n<ul>\n<li>Chat with us on the Kubernetes <a href=\"http://slack.k8s.io/\">Slack</a>:<a href=\"https://kubernetes.slack.com/archives/C8TSNPY4T\">#cluster-api</a></li>\n<li>Join the SIG Cluster Lifecycle <a href=\"https://groups.google.com/g/kubernetes-sig-cluster-lifecycle\">Google Group</a> to receive calendar invites and gain access to documents</li>\n<li>Join our <a href=\"https://zoom.us/j/861487554\">Zoom meeting</a>, every Wednesday at 10:00 Pacific Time</li>\n<li>Check out the <a href=\"https://cluster-api.sigs.k8s.io/user/quick-start.html\">ClusterClass quick-start</a> for the Docker provider (CAPD) in the Cluster API book.</li>\n<li><em>UPDATE</em>: Check out the <a href=\"https://cluster-api.sigs.k8s.io/tasks/experimental-features/cluster-class/index.html\">ClusterClass experimental feature</a> documentation in the Cluster API book.</li>\n</ul>","PublishedAt":"2021-10-08 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/10/08/capi-clusterclass-and-managed-topologies/","SourceName":"Kubernetes"}},{"node":{"ID":612,"Title":"Postmortem: Removing all users from github.com/trivago","Description":"","PublishedAt":"2021-10-05 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2021-10-05-postmortem-removing-all-users-from-github-trivago/","SourceName":"Trivago"}},{"node":{"ID":1252,"Title":"Blog: A Closer Look at NSA/CISA Kubernetes Hardening Guidance","Description":"<p><strong>Authors:</strong> Jim Angel (Google), Pushkar Joglekar (VMware), and Savitha\nRaghunathan (Red Hat)</p>\n<div class=\"alert alert-primary\" role=\"alert\">\n<h4 class=\"alert-heading\">Disclaimer</h4>\nThe open source tools listed in this article are to serve as examples only\nand are in no way a direct recommendation from the Kubernetes community or authors.\n</div>\n<h2 id=\"background\">Background</h2>\n<p>USA's National Security Agency (NSA) and the Cybersecurity and Infrastructure\nSecurity Agency (CISA)\nreleased, &quot;<a href=\"https://media.defense.gov/2021/Aug/03/2002820425/-1/-1/1/CTR_KUBERNETES%20HARDENING%20GUIDANCE.PDF\">Kubernetes Hardening Guidance</a>&quot;\non August 3rd, 2021. The guidance details threats to Kubernetes environments\nand provides secure configuration guidance to minimize risk.</p>\n<p>The following sections of this blog correlate to the sections in the NSA/CISA guidance.\nAny missing sections are skipped because of limited opportunities to add\nanything new to the existing content.</p>\n<p><em>Note</em>: This blog post is not a substitute for reading the guide. Reading the published\nguidance is recommended before proceeding as the following content is\ncomplementary.</p>\n<h2 id=\"introduction-and-threat-model\">Introduction and Threat Model</h2>\n<p>Note that the threats identified as important by the NSA/CISA, or the intended audience of this guidance, may be different from the threats that other enterprise users of Kubernetes consider important. This section\nis still useful for organizations that care about data, resource theft and\nservice unavailability.</p>\n<p>The guidance highlights the following three sources of compromises:</p>\n<ul>\n<li>Supply chain risks</li>\n<li>Malicious threat actors</li>\n<li>Insider threats (administrators, users, or cloud service providers)</li>\n</ul>\n<p>The <a href=\"https://en.wikipedia.org/wiki/Threat_model\">threat model</a> tries to take a step back and review threats that not only\nexist within the boundary of a Kubernetes cluster but also include the underlying\ninfrastructure and surrounding workloads that Kubernetes does not manage.</p>\n<p>For example, when a workload outside the cluster shares the same physical\nnetwork, it has access to the kubelet and to control plane components: etcd, controller manager, scheduler and API\nserver. Therefore, the guidance recommends having network level isolation\nseparating Kubernetes clusters from other workloads that do not need connectivity\nto Kubernetes control plane nodes. Specifically, scheduler, controller-manager,\netcd only need to be accessible to the API server. Any interactions with Kubernetes\nfrom outside the cluster can happen by providing access to API server port.</p>\n<p>List of ports and protocols for each of these components are\ndefined in <a href=\"https://kubernetes.io/docs/reference/ports-and-protocols/\">Ports and Protocols</a>\nwithin the Kubernetes documentation.</p>\n<blockquote>\n<p>Special note: kube-scheduler and kube-controller-manager uses different ports than the ones mentioned in the guidance</p>\n</blockquote>\n<p>The <a href=\"https://cnsmap.netlify.app/threat-modelling\">Threat modelling</a> section\nfrom the CNCF <a href=\"https://github.com/cncf/tag-security/tree/main/security-whitepaper\">Cloud Native Security Whitepaper + Map</a>\nprovides another perspective on approaching threat modelling Kubernetes, from a\ncloud native lens.</p>\n<h2 id=\"kubernetes-pod-security\">Kubernetes Pod security</h2>\n<p>Kubernetes by default does not guarantee strict workload isolation between pods\nrunning in the same node in a cluster. However, the guidance provides several\ntechniques to enhance existing isolation and reduce the attack surface in case of a\ncompromise.</p>\n<h3 id=\"non-root-containers-and-rootless-container-engines\">&quot;Non-root&quot; containers and &quot;rootless&quot; container engines</h3>\n<p>Several best practices related to basic security principle of least privilege\ni.e. provide only the permissions are needed; no more, no less, are worth a\nsecond look.</p>\n<p>The guide recommends setting non-root user at build time instead of relying on\nsetting <code>runAsUser</code> at runtime in your Pod spec. This is a good practice and provides\nsome level of defense in depth. For example, if the container image is built with user <code>10001</code>\nand the Pod spec misses adding the <code>runAsuser</code> field in its <code>Deployment</code> object. In this\ncase there are certain edge cases that are worth exploring for awareness:</p>\n<ol>\n<li>Pods can fail to start, if the user defined at build time is different from\nthe one defined in pod spec and some files are as a result inaccessible.</li>\n<li>Pods can end up sharing User IDs unintentionally. This can be problematic\neven if the User IDs are non-zero in a situation where a container escape to\nhost file system is possible. Once the attacker has access to the host file\nsystem, they get access to all the file resources that are owned by other\nunrelated pods that share the same UID.</li>\n<li>Pods can end up sharing User IDs, with other node level processes not managed\nby Kubernetes e.g. node level daemons for auditing, vulnerability scanning,\ntelemetry. The threat is similar to the one above where host file system\naccess can give attacker full access to these node level daemons without\nneeding to be root on the node.</li>\n</ol>\n<p>However, none of these cases will have as severe an impact as a container\nrunning as root being able to escape as a root user on the host, which can provide\nan attacker with complete control of the worker node, further allowing lateral\nmovement to other worker or control plane nodes.</p>\n<p>Kubernetes 1.22 introduced\nan <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-in-userns/\">alpha feature</a>\nthat specifically reduces the impact of such a control plane component running\nas root user to a non-root user through user namespaces.</p>\n<p>That (<a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/#feature-stages\">alpha stage</a>) support for user namespaces / rootless mode is available with\nthe following container runtimes:</p>\n<ul>\n<li><a href=\"https://docs.docker.com/engine/security/rootless/\">Docker Engine</a></li>\n<li><a href=\"https://developers.redhat.com/blog/2020/09/25/rootless-containers-with-podman-the-basics\">Podman</a></li>\n</ul>\n<p>Some distributions support running in rootless mode, like the following:</p>\n<ul>\n<li><a href=\"https://kind.sigs.k8s.io/docs/user/rootless/\">kind</a></li>\n<li><a href=\"https://rancher.com/docs/k3s/latest/en/advanced/#running-k3s-with-rootless-mode-experimental\">k3s</a></li>\n<li><a href=\"https://github.com/rootless-containers/usernetes\">Usernetes</a></li>\n</ul>\n<h3 id=\"immutable-container-filesystems\">Immutable container filesystems</h3>\n<p>The NSA/CISA Kubernetes Hardening Guidance highlights an often overlooked feature <code>readOnlyRootFileSystem</code>, with a\nworking example in <a href=\"https://media.defense.gov/2021/Aug/03/2002820425/-1/-1/1/CTR_KUBERNETES%20HARDENING%20GUIDANCE.PDF#page=42\">Appendix B</a>. This example limits execution and tampering of\ncontainers at runtime. Any read/write activity can then be limited to few\ndirectories by using <code>tmpfs</code> volume mounts.</p>\n<p>However, some applications that modify the container filesystem at runtime, like exploding a WAR or JAR file at container startup,\ncould face issues when enabling this feature. To avoid this issue, consider making minimal changes to the filesystem at runtime\nwhen possible.</p>\n<h3 id=\"building-secure-container-images\">Building secure container images</h3>\n<p>Kubernetes Hardening Guidance also recommends running a scanner at deploy time as an admission controller,\nto prevent vulnerable or misconfigured pods from running in the cluster.\nTheoretically, this sounds like a good approach but there are several caveats to\nconsider before this can be implemented in practice:</p>\n<ul>\n<li>Depending on network bandwidth, available resources and scanner of choice,\nscanning for vulnerabilities for an image can take an indeterminate amount of\ntime. This could lead to slower or unpredictable pod start up times, which\ncould result in spikes of unavailability when apps are serving peak load.</li>\n<li>If the policy that allows or denies pod startup is made using incorrect or\nincomplete data it could result in several false positive or false negative\noutcomes like the following:\n<ul>\n<li>inside a container image, the <code>openssl</code> package is detected as vulnerable. However,\nthe application is written in Golang and uses the Go <code>crypto</code> package for TLS. Therefore, this vulnerability\nis not in the code execution path and as such has minimal impact if it\nremains unfixed.</li>\n<li>A vulnerability is detected in the <code>openssl</code> package for a Debian base image.\nHowever, the upstream Debian community considers this as a Minor impact\nvulnerability and as a result does not release a patch fix for this\nvulnerability. The owner of this image is now stuck with a vulnerability that\ncannot be fixed and a cluster that does not allow the image to run because\nof predefined policy that does not take into account whether the fix for a\nvulnerability is available or not</li>\n<li>A Golang app is built on top of a <a href=\"https://github.com/GoogleContainerTools/distroless\">distroless</a>\nimage, but it is compiled with a Golang version that uses a vulnerable <a href=\"https://pkg.go.dev/std\">standard library</a>.\nThe scanner has\nno visibility into golang version but only on OS level packages. So it\nallows the pod to run in the cluster in spite of the image containing an\napp binary built on vulnerable golang.</li>\n</ul>\n</li>\n</ul>\n<p>To be clear, relying on vulnerability scanners is absolutely a good idea but\npolicy definitions should be flexible enough to allow:</p>\n<ul>\n<li>Creation of exception lists for images or vulnerabilities through labelling</li>\n<li>Overriding the severity with a risk score based on impact of a vulnerability</li>\n<li>Applying the same policies at build time to catch vulnerable images with\nfixable vulnerabilities before they can be deployed into Kubernetes clusters</li>\n</ul>\n<p>Special considerations like offline vulnerability database fetch, may also be\nneeded, if the clusters run in an air-gapped environment and the scanners\nrequire internet access to update the vulnerability database.</p>\n<h3 id=\"pod-security-policies\">Pod Security Policies</h3>\n<p>Since Kubernetes v1.21, the <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-policy/\">PodSecurityPolicy</a>\nAPI and related features are <a href=\"https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/\">deprecated</a>,\nbut some of the guidance in this section will still apply for the next few years, until cluster operators\nupgrade their clusters to newer Kubernetes versions.</p>\n<p>The Kubernetes project is working on a replacement for PodSecurityPolicy.\nKubernetes v1.22 includes an alpha feature called <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/\">Pod Security Admission</a>\nthat is intended to allow enforcing a minimum level of isolation between pods.</p>\n<p>The built-in isolation levels for Pod Security Admission are derived\nfrom <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-standards/\">Pod Security Standards</a>, which is a superset of all the components mentioned in Table I <a href=\"https://media.defense.gov/2021/Aug/03/2002820425/-1/-1/1/CTR_KUBERNETES%20HARDENING%20GUIDANCE.PDF#page=17\">page 10</a> of\nthe guidance.</p>\n<p>Information about migrating from PodSecurityPolicy to the Pod Security\nAdmission feature is available\nin\n<a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/\">Migrate from PodSecurityPolicy to the Built-In PodSecurity Admission Controller</a>.</p>\n<p>One important behavior mentioned in the guidance that remains the same between\nPod Security Policy and its replacement is that enforcing either of them does\nnot affect pods that are already running. With both PodSecurityPolicy and Pod Security Admission,\nthe enforcement happens during the pod creation\nstage.</p>\n<h3 id=\"hardening-container-engines\">Hardening container engines</h3>\n<p>Some container workloads are less trusted than others but may need to run in the\nsame cluster. In those cases, running them on dedicated nodes that include\nhardened container runtimes that provide stricter pod isolation boundaries can\nact as a useful security control.</p>\n<p>Kubernetes supports\nan API called <a href=\"https://kubernetes.io/docs/concepts/containers/runtime-class/\">RuntimeClass</a> that is\nstable / GA (and, therefore, enabled by default) stage as of Kubernetes v1.20.\nRuntimeClass allows you to ensure that Pods requiring strong isolation are scheduled onto\nnodes that can offer it.</p>\n<p>Some third-party projects that you can use in conjunction with RuntimeClass are:</p>\n<ul>\n<li><a href=\"https://github.com/kata-containers/kata-containers/blob/main/docs/how-to/how-to-use-k8s-with-cri-containerd-and-kata.md#create-runtime-class-for-kata-containers\">kata containers</a></li>\n<li><a href=\"https://gvisor.dev/docs/user_guide/containerd/quick_start/\">gvisor</a></li>\n</ul>\n<p>As discussed here and in the guidance, many features and tooling exist in and around\nKubernetes that can enhance the isolation boundaries between\npods. Based on relevant threats and risk posture, you should pick and choose\nbetween them, instead of trying to apply all the recommendations. Having said that, cluster\nlevel isolation i.e. running workloads in dedicated clusters, remains the strictest workload\nisolation mechanism, in spite of improvements mentioned earlier here and in the guide.</p>\n<h2 id=\"network-separation-and-hardening\">Network Separation and Hardening</h2>\n<p>Kubernetes Networking can be tricky and this section focuses on how to secure\nand harden the relevant configurations. The guide identifies the following as key\ntakeaways:</p>\n<ul>\n<li>Using NetworkPolicies to create isolation between resources,</li>\n<li>Securing the control plane</li>\n<li>Encrypting traffic and sensitive data</li>\n</ul>\n<h3 id=\"network-policies\">Network Policies</h3>\n<p>Network policies can be created with the help of network plugins. In order to\nmake the creation and visualization easier for users, Cilium supports\na <a href=\"https://editor.cilium.io\">web GUI tool</a>. That web GUI lets you create Kubernetes\nNetworkPolicies (a generic API that nevertheless requires a compatible CNI plugin),\nand / or Cilium network policies (CiliumClusterwideNetworkPolicy and CiliumNetworkPolicy,\nwhich only work in clusters that use the Cilium CNI plugin).\nYou can use these APIs to restrict network traffic between pods, and therefore minimize the\nattack vector.</p>\n<p>Another scenario that is worth exploring is the usage of external IPs. Some\nservices, when misconfigured, can create random external IPs. An attacker can take\nadvantage of this misconfiguration and easily intercept traffic. This vulnerability\nhas been reported\nin <a href=\"https://www.cvedetails.com/cve/CVE-2020-8554/\">CVE-2020-8554</a>.\nUsing <a href=\"https://github.com/kubernetes-sigs/externalip-webhook\">externalip-webhook</a>\ncan mitigate this vulnerability by preventing the services from using random\nexternal IPs. <a href=\"https://github.com/kubernetes-sigs/externalip-webhook\">externalip-webhook</a>\nonly allows creation of services that don't require external IPs or whose\nexternal IPs are within the range specified by the administrator.</p>\n<blockquote>\n<p>CVE-2020-8554 - Kubernetes API server in all versions allow an attacker\nwho is able to create a ClusterIP service and set the <code>spec.externalIPs</code> field,\nto intercept traffic to that IP address. Additionally, an attacker who is able to\npatch the <code>status</code> (which is considered a privileged operation and should not\ntypically be granted to users) of a LoadBalancer service can set the\n<code>status.loadBalancer.ingress.ip</code> to similar effect.</p>\n</blockquote>\n<h3 id=\"resource-policies\">Resource Policies</h3>\n<p>In addition to configuring ResourceQuotas and limits, consider restricting how many process\nIDs (PIDs) a given Pod can use, and also to reserve some PIDs for node-level use to avoid\nresource exhaustion. More details to apply these limits can be\nfound in <a href=\"https://kubernetes.io/docs/concepts/policy/pid-limiting/\">Process ID Limits And Reservations</a>.</p>\n<h3 id=\"control-plane-hardening\">Control Plane Hardening</h3>\n<p>In the next section, the guide covers control plane hardening. It is worth\nnoting that\nfrom <a href=\"https://github.com/kubernetes/kubernetes/issues/91506\">Kubernetes 1.20</a>,\ninsecure port from API server, has been removed.</p>\n<h3 id=\"etcd\">Etcd</h3>\n<p>As a general rule, the etcd server should be configured to only trust\ncertificates assigned to the API server. It limits the attack surface and prevents a\nmalicious attacker from gaining access to the cluster. It might be beneficial to\nuse a separate CA for etcd, as it by default trusts all the certificates issued\nby the root CA.</p>\n<h3 id=\"kubeconfig-files\">Kubeconfig Files</h3>\n<p>In addition to specifying the token and certificates directly, <code>.kubeconfig</code>\nsupports dynamic retrieval of temporary tokens using auth provider plugins.\nBeware of the possibility of malicious\nshell <a href=\"https://banzaicloud.com/blog/kubeconfig-security/\">code execution</a> in a\n<code>kubeconfig</code> file. Once attackers gain access to the cluster, they can steal ssh\nkeys/secrets or more.</p>\n<h3 id=\"secrets\">Secrets</h3>\n<p>Kubernetes <a href=\"https://kubernetes.io/docs/concepts/configuration/secret/\">Secrets</a> is the native way of managing secrets as a Kubernetes\nAPI object. However, in some scenarios such as a desire to have a single source of truth for all app secrets, irrespective of whether they run on Kubernetes or not, secrets can be managed loosely coupled with\nKubernetes and consumed by pods through side-cars or init-containers with minimal usage of Kubernetes Secrets API.</p>\n<p><a href=\"https://github.com/external-secrets/kubernetes-external-secrets\">External secrets providers</a>\nand <a href=\"https://github.com/kubernetes-sigs/secrets-store-csi-driver\">csi-secrets-store</a>\nare some of these alternatives to Kubernetes Secrets</p>\n<h2 id=\"log-auditing\">Log Auditing</h2>\n<p>The NSA/CISA guidance stresses monitoring and alerting based on logs. The key points\ninclude logging at the host level, application level, and on the cloud. When\nrunning Kubernetes in production, it's important to understand who's\nresponsible, and who's accountable, for each layer of logging.</p>\n<h3 id=\"kubernetes-api-auditing\">Kubernetes API auditing</h3>\n<p>One area that deserves more focus is what exactly should alert or be logged. The\ndocument outlines a sample policy in <a href=\"https://media.defense.gov/2021/Aug/03/2002820425/-1/-1/1/CTR_KUBERNETES%20HARDENING%20GUIDANCE.PDF#page=55\">Appendix L: Audit Policy</a> that logs all\nRequestResponse's including metadata and request / response bodies. While helpful for a demo, it may not be practical for production.</p>\n<p>Each organization needs to evaluate their\nown threat model and build an audit policy that complements or helps troubleshooting incident response. Think\nabout how someone would attack your organization and what audit trail could identify it. Review more advanced options for tuning audit logs in the official <a href=\"https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/#audit-policy\">audit logging documentation</a>.\nIt's crucial to tune your audit logs to only include events that meet your threat model. A minimal audit policy that logs everything at <code>metadata</code> level can also be a good starting point.</p>\n<p>Audit logging configurations can also be tested with\nkind following these <a href=\"https://kind.sigs.k8s.io/docs/user/auditing\">instructions</a>.</p>\n<h3 id=\"streaming-logs-and-auditing\">Streaming logs and auditing</h3>\n<p>Logging is important for threat and anomaly detection. As the document outlines,\nit's a best practice to scan and alert on logs as close to real time as possible\nand to protect logs from tampering if a compromise occurs. It's important to\nreflect on the various levels of logging and identify the critical areas such as\nAPI endpoints.</p>\n<p>Kubernetes API audit logging can stream to a webhook and there's an example in <a href=\"https://media.defense.gov/2021/Aug/03/2002820425/-1/-1/1/CTR_KUBERNETES%20HARDENING%20GUIDANCE.PDF#page=58\">Appendix N: Webhook configuration</a>. Using a webhook could be a method that\nstores logs off cluster and/or centralizes all audit logs. Once logs are\ncentrally managed, look to enable alerting based on critical events. Also ensure\nyou understand what the baseline is for normal activities.</p>\n<h3 id=\"alert-identification\">Alert identification</h3>\n<p>While the guide stressed the importance of notifications, there is not a blanket\nevent list to alert from. The alerting requirements vary based on your own\nrequirements and threat model. Examples include the following events:</p>\n<ul>\n<li>Changes to the <code>securityContext</code> of a Pod</li>\n<li>Updates to admission controller configs</li>\n<li>Accessing certain files / URLs</li>\n</ul>\n<h3 id=\"additional-logging-resources\">Additional logging resources</h3>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=OPuu8wsu2Zc\">Seccomp Security Profiles and You: A Practical Guide - Duffie Cooley</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=ZJgaGJm9NJE\">TGI Kubernetes 119: Gatekeeper and OPA</a></li>\n<li><a href=\"https://www.lacework.com/blog/hiding-in-plaintext-sight-abusing-the-lack-of-kubernetes-auditing-policies/\">Abusing The Lack of Kubernetes Auditing Policies</a></li>\n<li><a href=\"https://kubernetes.io/blog/2021/08/25/seccomp-default/\">Enable seccomp for all workloads with a new v1.22 alpha feature</a></li>\n<li><a href=\"https://www.twitch.tv/videos/1147889860\">This Week in Cloud Native: Auditing / Pod Security</a></li>\n</ul>\n<h2 id=\"upgrading-and-application-security-practices\">Upgrading and Application Security practices</h2>\n<p>Kubernetes releases three times per year, so upgrade-related toil is a common problem for\npeople running production clusters. In addition to this, operators must\nregularly upgrade the underlying node's operating system and running\napplications. This is a best practice to ensure continued support and to reduce\nthe likelihood of bugs or vulnerabilities.</p>\n<p>Kubernetes supports the three most recent stable releases. While each Kubernetes\nrelease goes through a large number of tests before being published, some\nteams aren't comfortable running the latest stable release until some time has\npassed. No matter what version you're running, ensure that patch upgrades\nhappen frequently or automatically. More information can be found in\nthe <a href=\"https://kubernetes.io/releases/version-skew-policy/\">version skew</a> policy\npages.</p>\n<p>When thinking about how you'll manage node OS upgrades, consider ephemeral\nnodes. Having the ability to destroy and add nodes allows your team to respond\nquicker to node issues. In addition, having deployments that tolerate node\ninstability (and a culture that encourages frequent deployments) allows for\neasier cluster upgrades.</p>\n<p>Additionally, it's worth reiterating from the guidance that periodic\nvulnerability scans and penetration tests can be performed on the various system\ncomponents to proactively look for insecure configurations and vulnerabilities.</p>\n<h3 id=\"finding-release-security-information\">Finding release &amp; security information</h3>\n<p>To find the most recent Kubernetes supported versions, refer to\n<a href=\"https://k8s.io/releases\">https://k8s.io/releases</a>, which includes minor versions. It's good to stay up to date with\nyour minor version patches.</p>\n<p>If you're running a managed Kubernetes offering, look for their release\ndocumentation and find their various security channels.</p>\n<p>Subscribe to\nthe <a href=\"https://groups.google.com/g/kubernetes-announce\">Kubernetes Announce mailing list</a>.\nThe Kubernetes Announce mailing list is searchable for terms such\nas &quot;<a href=\"https://groups.google.com/g/kubernetes-announce/search?q=%5BSecurity%20Advisory%5D\">Security Advisories</a>&quot;.\nYou can set up alerts and email notifications as long as you know what key\nwords to alert on.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>In summary, it is fantastic to see security practitioners sharing this\nlevel of detailed guidance in public. This guidance further highlights\nKubernetes going mainstream and how securing Kubernetes clusters and the\napplication containers running on Kubernetes continues to need attention and focus of\npractitioners. Only a few weeks after the guidance was published, an open source\ntool <a href=\"https://github.com/armosec/kubescape\">kubescape</a> to validate cluster\nagainst this guidance became available.</p>\n<p>This tool can be a great starting point to check the current state of your\nclusters, after which you can use the information in this blog post and in the guidance to assess\nwhere improvements can be made.</p>\n<p>Finally, it is worth reiterating that not all controls in this guidance will\nmake sense for all practitioners. The best way to know which controls matter is\nto rely on the threat model of your own Kubernetes environment.</p>\n<p><em>A special shout out and thanks to Rory McCune (@raesene) for his inputs to this blog post</em></p>","PublishedAt":"2021-10-05 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/10/05/nsa-cisa-kubernetes-hardening-guidance/","SourceName":"Kubernetes"}},{"node":{"ID":39,"Title":"How Asana helps me feel included as a Latina in Engineering Management","Description":"<img width=\"1024\" height=\"663\" src=\"https://blog.asana.com/wp-content/post-images/LHM-Eng-Blog-Header-1024x663.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Latina Eng Manager\" loading=\"lazy\" style=\"display: block; margin: auto; margin-bottom: 5px;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://blog.asana.com/wp-content/post-images/LHM-Eng-Blog-Header-1024x663.png 1024w, https://blog.asana.com/wp-content/post-images/LHM-Eng-Blog-Header-520x337.png 520w, https://blog.asana.com/wp-content/post-images/LHM-Eng-Blog-Header-1536x994.png 1536w, https://blog.asana.com/wp-content/post-images/LHM-Eng-Blog-Header.png 1607w, https://blog.asana.com/wp-content/post-images/LHM-Eng-Blog-Header-520x337@2x.png 1040w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><p>I’m Denise Carolina Videtta, Engineering Manager on the Communications Team in the Workflow Pillar&#160;at Asana. I was raised in Caracas, Venezuela, where I majored in Computer Science at Universidad Simon Bolivar &#8211; Venezuela, and I have a Master’s Degree in Software Engineering from Texas State University in San Marcos. A couple of years ago, someone [&#8230;]</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.asana.com/2021/09/latina-engineering-manager/\">How Asana helps me feel included as a Latina in Engineering&nbsp;Management</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.asana.com\">The Asana Blog</a>.</p>\n","PublishedAt":"2021-09-30 22:24:41+00:00","OriginURL":"https://blog.asana.com/2021/09/latina-engineering-manager/","SourceName":"Asana"}},{"node":{"ID":473,"Title":"User interviews and product analytics","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/09/20210922_BlogHero_UserInterviews@2x-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>As a product leader at Mixpanel, I can go on and on about the value of using product analytics in my work. (And I have.) But that doesn’t mean I don’t understand how important user interviews can be for learning how people use my products. Combining product analytics and user interviews for product development is</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/user-interviews-and-product-analytics-my-methods-for-how-and-when-to-use-each/\">User interviews and product analytics</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-09-30 17:56:00+00:00","OriginURL":"https://mixpanel.com/blog/user-interviews-and-product-analytics-my-methods-for-how-and-when-to-use-each/","SourceName":"Mixpanel"}},{"node":{"ID":61,"Title":"Implementing academic papers: lessons learned from Elasticsearch and Lucene","Description":"<p>While developing Elasticsearch, we occasionally come across an important problem with no simple or established approach to solving it. It's natural to ask “hmm, is there an academic paper that addresses this?” Other times, academic work is a source of inspiration. We'll encounter a paper proposing a new algorithm or data structure and think “this would be so useful!” Here are just a few examples of how Elasticsearch and Apache Lucene incorporate academic work:\n</p><ul>\n\t<li dir=\"ltr\" aria-level=\"1\"><a href=\"https://research.google/pubs/pub40671/\">HyperLogLog++</a> for <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.15/search-aggregations-metrics-cardinality-aggregation.html\">cardinality aggregations</a></li>\n\t<li dir=\"ltr\" aria-level=\"1\"><a href=\"https://www.usenix.org/system/files/conference/nsdi15/nsdi15-paper-suresh.pdf\">C3 algorithm</a> for <a href=\"https://www.elastic.co/blog/improving-response-latency-in-elasticsearch-with-adaptive-replica-selection\">adaptive replica selection</a></li>\n\t<li dir=\"ltr\" aria-level=\"1\"><a href=\"https://arxiv.org/abs/1603.09320\">Hierarchical Navigable Small World Graphs (HNSW)</a> for nearest vector search in Lucene</li>\n\t<li dir=\"ltr\" aria-level=\"1\"><a href=\"https://jmlr.csail.mit.edu/papers/volume17/15-308/15-308.pdf\">MIC statistic</a> to <a href=\"https://github.com/elastic/ml-cpp/pull/488\">improve machine learning classification</a></li>\n\t<li dir=\"ltr\" aria-level=\"1\"><a href=\"http://engineering.nyu.edu/~suel/papers/bmw.pdf\">Block-max WAND</a> for <a href=\"https://www.elastic.co/blog/faster-retrieval-of-top-hits-in-elasticsearch-with-block-max-wand\">faster top-hits retrieval in Lucene</a></li>\n\t<li dir=\"ltr\" aria-level=\"1\">... and <a href=\"https://www.elastic.co/guide/en/elasticsearch///reference/7.15/query-dsl-combined-fields-query.html\">many</a> <a href=\"https://github.com/elastic/elasticsearch/blob/b2a9328890b23e7ccf6c66a3b13d6d65e453a3dd/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java#L302-L323\">more</a><span></span></li>\n</ul><p>Academic papers are an invaluable resource for engineers developing data-intensive systems. But implementing them can be intimidating and error-prone — algorithm descriptions are often complex, with important practical details omitted. And testing is a real challenge: for example, how can we thoroughly test a machine learning algorithm whose output depends closely on the dataset?\n</p><p>This post shares strategies for implementing academic papers in a software application. It draws on examples from Elasticsearch and Lucene in hopes of helping other engineers learn from our experiences. You might read these strategies and think “but this is just software development!” And that would indeed be true: as engineers we already have the right practices and tools, they just need to be adapted to a new challenge.\n</p><h2>Evaluate the paper as you would a software dependency</h2><p>Adding a new software dependency requires careful evaluation: if the other package is incorrect, slow, or insecure, our project could be too. Before pulling in a dependency, developers make sure to evaluate its quality.\n</p><p>The same applies to academic papers you're considering implementing. It may seem that because an algorithm was published in a paper, it must be correct and perform well. But even though it passed a review process, an academic paper can have issues. Maybe the correctness proof relies on assumptions that aren't realistic. Or perhaps the “experiments” section shows much better performance than the baseline, but this only holds on a specific dataset. Even if the paper is of great quality, its approach may not be a good fit for your project.\n</p><p>When thinking about whether to take a “dependency” on an academic paper, it's helpful to ask the same questions we would of a software package:\n</p><ul>\n\t<li dir=\"ltr\" aria-level=\"1\">Is the library widely-used and “battle tested”? → Have other packages implemented this paper, and has it worked well for them?</li>\n\t<li dir=\"ltr\" aria-level=\"1\">Are performance benchmarks available? Do these seem accurate and fair? → Does the paper include realistic experiments? Are they well designed?</li>\n\t<li dir=\"ltr\" aria-level=\"1\">Is a performance improvement big enough to justify the complexity? → Does the paper compare to a strong baseline approach? How much does it outperform this baseline?</li>\n\t<li dir=\"ltr\" aria-level=\"1\">Will the approach integrate well with our system? → Do the algorithm's assumptions and trade-offs fit our use case?</li>\n</ul><p>Somehow when a software package publishes a performance comparison against their competitors, the package always comes out fastest! If a third party designed the benchmarks, they may be more balanced. The same phenomenon applies to academic papers. If an algorithm performs well not only in the original paper, but also appears in other papers as a strong baseline, then it is very likely to be solid.\n</p><h2>Get creative with testing</h2><p>Algorithms from academic papers often have more sophisticated behavior than the types of algorithms we routinely encounter. Perhaps it's an approximation algorithm that trades off accuracy for better speed. Or maybe it's a machine learning method that takes in a large dataset, and produces (sometimes unexpected) outputs. How can we write tests for these algorithms if we can't characterize their behavior in a simple way?\n</p><h3>Focus on invariants</h3><p>When designing unit tests, it's common to think in terms of examples: if we give the algorithm this example input, it should have that output. Unfortunately for most mathematical algorithms, example-based testing doesn't sufficiently cover their behavior.\n</p><p>Let's consider the C3 algorithm, which Elasticsearch uses to figure out what node should handle a search request. It ranks each node using a nuanced formula that incorporates the node's previous service and response times, and its queue size. Testing a couple examples doesn't really verify we understood the formula correctly. It helps to step back and think about testing invariants: if service time increases, does the node's rank decrease? If the queue size is 0, is the rank determined by response time, as the paper claims?\n</p><p>Focusing on invariants can help in a number of common cases:\n</p><ul>\n\t<li dir=\"ltr\" aria-level=\"1\">Is the method supposed to be order-agnostic? If so, passing the input data in a different order should result in the same output.</li>\n\t<li dir=\"ltr\" aria-level=\"1\">Does some step in the algorithm produce class probabilities? If so, these probabilities should sum to 1.</li>\n\t<li dir=\"ltr\" aria-level=\"1\">Is the function symmetric around the origin? If so, flipping the sign of the input should simply flip the sign of the output.</li>\n</ul><p>When we first implemented C3, we had a bug in the formula where we accidentally used the inverse of response time in place of response time. This meant slower nodes could be ranked higher! When fixing the issue, we <a href=\"https://github.com/elastic/elasticsearch/pull/70283\">made sure to add invariant checks</a> to guard against future mistakes.\n</p><h3>Compare to a reference implementation</h3><p>Alongside the paper, the authors hopefully published an implementation of the algorithm. (This is especially likely if the paper contains experiments, as many journals require authors to post code for reproducing the results.) You can test your approach against this reference implementation to make sure you haven't missed important details of the algorithm.\n</p><p>While developing Lucene's HNSW implementation for nearest-neighbor search, we <a href=\"https://issues.apache.org/jira/browse/LUCENE-9937\">tested against a reference library</a> by the paper's authors. We ran both Lucene and the library against the same dataset, comparing the accuracy of their results and the number of computations they performed. When these numbers match closely, we know that Lucene faithfully implements the algorithm.\n</p><p>When incorporating an algorithm into a system, you often need to make modifications or extensions, like scaling it to multiple cores, or adding heuristics to improve performance. It's best to first implement a \"vanilla\" version, test it against the reference, then make incremental changes. That way you can be confident you've captured all the key parts before making customizations.\n</p><h3>Duel against an existing algorithm</h3><p>The last section raises another idea for a test invariant: comparing the algorithm's output to a simpler and better-understood algorithm's output. As an example, consider the block-max WAND algorithm in Lucene, which speeds up document retrieval by skipping over documents that can't appear in the top results. It is difficult to describe exactly how block-max WAND should behave in every case, but we do know that applying it shouldn't change the top results! So our tests can generate several random search queries, then <a href=\"https://github.com/apache/lucene/blob/main/lucene/core/src/test/org/apache/lucene/search/TestWANDScorer.java#L669\">run them both with and without the WAND optimization</a> and check that their results always match.\n</p><p>An important aspect of these tests is that they <a href=\"https://www.elastic.co/blog/elasticsearch-testing-qa-increasing-coverage-randomizing-test-runs\">generate random inputs</a> on which to run the comparison. This can help exercise cases you wouldn't have thought of, and surface unexpected issues. As an example, Lucene's randomized comparison test for BM25F scoring has helped<a href=\"https://issues.apache.org/jira/browse/LUCENE-10039\"> catch bugs in subtle edge cases</a>. The idea of feeding an algorithm random inputs is closely related to the concept of<a href=\"https://en.wikipedia.org/wiki/Fuzzing\"> fuzzing</a>, a common testing technique in computer security.\n</p><p>Elasticsearch and Lucene frequently use this testing approach. If you see a test that mentions a \"duel\" between two algorithms (TestDuelingAnalyzers, testDuelTermsQuery...), then you know this strategy is in action.\n</p><h2>Use the paper's terminology</h2><p>When another developer works with your code, they'll need to consult the paper to follow its details. The<a href=\"https://github.com/elastic/elasticsearch/blob/4f22f437ee50cacb94b37b457be1da0b8ba0e8ce/server/src/main/java/org/elasticsearch/search/aggregations/metrics/HyperLogLogPlusPlus.java#L24-L39\"> comment on Elasticsearch's HyperLogLog++ implementation</a> says it well: “Trying to understand what this class does without having read the paper is considered adventurous.” This method comment also sets a good example. It includes a link to the academic paper, and highlights what modifications were made to the algorithm as it was originally described.\n</p><p>Since developers will base their understanding of the code on the paper, it's helpful to use the exact same terminology. Since mathematical notation is terse, this can result in names that would not usually be considered “good style”, but are very clear in the context of the paper. Formulas from academic papers are one of the few times you'll encounter cryptic variable names in Elasticsearch like<a href=\"https://github.com/elastic/elasticsearch/blob/4f22f437ee50cacb94b37b457be1da0b8ba0e8ce/server/src/main/java/org/elasticsearch/node/ResponseCollectorService.java#L151\"> rS and muBarSInverse</a>.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt83d9ad71c909c603/6154b0ac58e1f54c5cbc48f2/elastic-blog-academicpaper.jpg\" data-sys-asset-uid=\"blt83d9ad71c909c603\" alt=\"elastic-blog-academicpaper.jpg\"><span id=\"docs-internal-guid-0dab3aab-7fff-4f7f-8b92-e1500e9e915e\"><br><em>The author's recommended way of reading a paper: with a large coffee.</em></span></p><h2>You can email the author</h2><p>When working through a tough paper, you may spend hours puzzling over a formula, unsure if you're misunderstanding or if there's just a typo. If this were an open source project, you could ask a question on GitHub or StackOverflow. But where can you turn for an academic paper? The authors seem busy and might be annoyed by your emails.\n</p><p>On the contrary, many academics love hearing that their ideas are being put into practice and are happy to answer questions over email. If you work on a product they're familiar with, they might even list the application on their website!\n</p><p>There's also a growing trend for academics to discuss papers in the open, using many of the same tools from software development. If a paper has an accompanying software package, you might find answers to<a href=\"https://github.com/facebookresearch/faiss/issues/1928\"> common questions on Github</a>. Stack Exchange communities like “Theoretical Computer Science” and “Cross Validated” also contain<a href=\"https://cstheory.stackexchange.com/questions/49296/problem-in-the-paper-stable-minimum-space-partitioning-in-linear-time\"> detailed discussions about popular papers</a>. Some conferences have begun to publish all paper reviews online. These reviews contain<a href=\"https://openreview.net/forum?id=H1eA7AEtvS\"> back-and-forth discussions</a> with the authors that can surface helpful insights about the approach.\n</p><h2>To be continued</h2><p>This post focuses on the basics of choosing an academic paper and implementing it correctly, but doesn't cover all aspects of actually deploying the algorithm. For example, if the algorithm is just one component in a complex system, how do we ensure that changes to the component lead to end-to-end improvements? And what if integrating the algorithm requires substantial modifications or extensions that the original paper doesn't cover? These are important topics we hope to share more about in future posts.\n</p>","PublishedAt":"2021-09-30 01:00:00+00:00","OriginURL":"https://www.elastic.co/blog/implementing-academic-papers-lessons-learned-from-elasticsearch-and-lucene","SourceName":"Elastic"}},{"node":{"ID":768,"Title":"Building Uber’s Fulfillment Platform for Planet-Scale using Google Cloud Spanner","Description":"<p>&#160;</p>\n<h1><span style=\"font-weight: 400;\">Introduction</span></h1>\n<p><span style=\"font-weight: 400;\">The Fulfillment Platform is a foundational Uber domain that enables the rapid scaling of new verticals. The platform handles billions of database transactions each day, ranging from user actions (e.g., a driver starting a trip) and system actions </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/building-ubers-fulfillment-platform/\">Building Uber’s Fulfillment Platform for Planet-Scale using Google Cloud Spanner</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-09-29 19:56:20+00:00","OriginURL":"https://eng.uber.com/building-ubers-fulfillment-platform/","SourceName":"Uber"}},{"node":{"ID":1253,"Title":"Blog: How to Handle Data Duplication in Data-Heavy Kubernetes Environments","Description":"<p><strong>Authors:</strong>\nAugustinas Stirbis (CAST AI)</p>\n<h2 id=\"why-duplicate-data\">Why Duplicate Data?</h2>\n<p>It’s convenient to create a copy of your application with a copy of its state for each team.\nFor example, you might want a separate database copy to test some significant schema changes\nor develop other disruptive operations like bulk insert/delete/update...</p>\n<p><strong>Duplicating data takes a lot of time.</strong> That’s because you need first to download\nall the data from a source block storage provider to compute and then send\nit back to a storage provider again. There’s a lot of network traffic and CPU/RAM used in this process.\nHardware acceleration by offloading certain expensive operations to dedicated hardware is\n<strong>always a huge performance boost</strong>. It reduces the time required to complete an operation by orders\nof magnitude.</p>\n<h2 id=\"volume-snapshots-to-the-rescue\">Volume Snapshots to the rescue</h2>\n<p>Kubernetes introduced <a href=\"https://kubernetes.io/docs/concepts/storage/volume-snapshots/\">VolumeSnapshots</a> as alpha in 1.12,\nbeta in 1.17, and the Generally Available version in 1.20.\nVolumeSnapshots use specialized APIs from storage providers to duplicate volume of data.</p>\n<p>Since data is already in the same storage device (array of devices), duplicating data is usually\na metadata operation for storage providers with local snapshots (majority of on-premise storage providers).\nAll you need to do is point a new disk to an immutable snapshot and only\nsave deltas (or let it do a full-disk copy). As an operation that is inside the storage back-end,\nit’s much quicker and usually doesn’t involve sending traffic over the network.\nPublic Clouds storage providers under the hood work a bit differently. They save snapshots\nto Object Storage and then copy back from Object storage to Block storage when &quot;duplicating&quot; disk.\nTechnically there is a lot of Compute and network resources spent on Cloud providers side,\nbut from Kubernetes user perspective VolumeSnapshots work the same way whether is it local or\nremote snapshot storage provider and no Compute and Network resources are involved in this operation.</p>\n<h2 id=\"sounds-like-we-have-our-solution-right\">Sounds like we have our solution, right?</h2>\n<p>Actually, VolumeSnapshots are namespaced, and Kubernetes protects namespaced data from\nbeing shared between tenants (Namespaces). This Kubernetes limitation is a conscious design\ndecision so that a Pod running in a different namespace can’t mount another application’s\n<a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims\">PersistentVolumeClaim</a> (PVC).</p>\n<p>One way around it would be to create multiple volumes with duplicate data in one namespace.\nHowever, you could easily reference the wrong copy.</p>\n<p>So the idea is to separate teams/initiatives by namespaces to avoid that and generally\nlimit access to the production namespace.</p>\n<h2 id=\"solution-creating-a-golden-snapshot-externally\">Solution? Creating a Golden Snapshot externally</h2>\n<p>Another way around this design limitation is to create Snapshot externally (not through Kubernetes).\nThis is also called pre-provisioning a snapshot manually. Next, I will import it\nas a multi-tenant golden snapshot that can be used for many namespaces. Below illustration will be\nfor AWS EBS (Elastic Block Storage) and GCE PD (Persistent Disk) services.</p>\n<h3 id=\"high-level-plan-for-preparing-the-golden-snapshot\">High-level plan for preparing the Golden Snapshot</h3>\n<ol>\n<li>Identify Disk (EBS/Persistent Disk) that you want to clone with data in the cloud provider</li>\n<li>Make a Disk Snapshot (in cloud provider console)</li>\n<li>Get Disk Snapshot ID</li>\n</ol>\n<h3 id=\"high-level-plan-for-cloning-data-for-each-team\">High-level plan for cloning data for each team</h3>\n<ol>\n<li>Create Namespace “sandbox01”</li>\n<li>Import Disk Snapshot (ID) as VolumeSnapshotContent to Kubernetes</li>\n<li>Create VolumeSnapshot in the Namespace &quot;sandbox01&quot; mapped to VolumeSnapshotContent</li>\n<li>Create the PersistentVolumeClaim from VolumeSnapshot</li>\n<li>Install Deployment or StatefulSet with PVC</li>\n</ol>\n<h2 id=\"step-1-identify-disk\">Step 1: Identify Disk</h2>\n<p>First, you need to identify your golden source. In my case, it’s a PostgreSQL database\non PersistentVolumeClaim “postgres-pv-claim” in the “production” namespace.</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl -n &lt;namespace&gt; get pvc &lt;pvc-name&gt; -o jsonpath=&#39;{.spec.volumeName}&#39;\n</code></pre><p>The output will look similar to:</p>\n<pre tabindex=\"0\"><code>pvc-3096b3ba-38b6-4fd1-a42f-ec99176ed0d90\n</code></pre><h2 id=\"step-2-prepare-your-golden-source\">Step 2: Prepare your golden source</h2>\n<p>You need to do this once or every time you want to refresh your golden data.</p>\n<h3 id=\"make-a-disk-snapshot\">Make a Disk Snapshot</h3>\n<p>Go to AWS EC2 or GCP Compute Engine console and search for an EBS volume\n(on AWS) or Persistent Disk (on GCP), that has a label matching the last output.\nIn this case I saw: <code>pvc-3096b3ba-38b6-4fd1-a42f-ec99176ed0d9</code>.</p>\n<p>Click on Create snapshot and give it a name. You can do it in Console manually,\nin AWS CloudShell / Google Cloud Shell, or in the terminal. To create a snapshot in the\nterminal you must have the AWS CLI tool (<code>aws</code>) or Google's CLI (<code>gcloud</code>)\ninstalled and configured.</p>\n<p>Here’s the command to create snapshot on GCP:</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">gcloud compute disks snapshot &lt;cloud-disk-id&gt; --project=&lt;gcp-project-id&gt; --snapshot-names=&lt;set-new-snapshot-name&gt; --zone=&lt;availability-zone&gt; --storage-location=&lt;region&gt;\n</code></pre>\n<figure>\n<img src=\"https://kubernetes.io/images/blog/2021-09-07-data-duplication-in-data-heavy-k8s-env/create-volume-snapshot-gcp.png\"\nalt=\"Screenshot of a terminal showing volume snapshot creation on GCP\"/> <figcaption>\n<h4>GCP snapshot creation</h4>\n</figcaption>\n</figure>\n<p>GCP identifies the disk by its PVC name, so it’s direct mapping. In AWS, you need to\nfind volume by the CSIVolumeName AWS tag with PVC name value first that will be used for snapshot creation.</p>\n<figure>\n<img src=\"https://kubernetes.io/images/blog/2021-09-07-data-duplication-in-data-heavy-k8s-env/identify-volume-aws.png\"\nalt=\"Screenshot of AWS web console, showing EBS volume identification\"/> <figcaption>\n<h4>Identify disk ID on AWS</h4>\n</figcaption>\n</figure>\n<p>Mark done Volume (volume-id) <code>vol-00c7ecd873c6fb3ec</code> and ether create EBS snapshot in AWS Console, or use <code>aws cli</code>.</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">aws ec2 create-snapshot --volume-id &#39;&lt;volume-id&gt;&#39; --description &#39;&lt;set-new-snapshot-name&gt;&#39; --tag-specifications &#39;ResourceType=snapshot&#39;\n</code></pre><h2 id=\"step-3-get-your-disk-snapshot-id\">Step 3: Get your Disk Snapshot ID</h2>\n<p>In AWS, the command above will output something similar to:</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">&#34;SnapshotId&#34;: &#34;snap-09ed24a70bc19bbe4&#34;\n</code></pre><p>If you’re using the GCP cloud, you can get the snapshot ID from the gcloud command by querying for the snapshot’s given name:</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">gcloud compute snapshots --project=&lt;gcp-project-id&gt; describe &lt;new-snapshot-name&gt; | grep id:\n</code></pre><p>You should get similar output to:</p>\n<pre tabindex=\"0\"><code>id: 6645363163809389170\n</code></pre><h2 id=\"step-4-create-a-development-environment-for-each-team\">Step 4: Create a development environment for each team</h2>\n<p>Now I have my Golden Snapshot, which is immutable data. Each team will get a copy\nof this data, and team members can modify it as they see fit, given that a new EBS/persistent\ndisk will be created for each team.</p>\n<p>Below I will define a manifest for each namespace. To save time, you can replace\nthe namespace name (such as changing “sandbox01” → “sandbox42”) using tools\nsuch as <code>sed</code> or <code>yq</code>, with Kubernetes-aware templating tools like\n<a href=\"https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/\">Kustomize</a>,\nor using variable substitution in a CI/CD pipeline.</p>\n<p>Here's an example manifest:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#00f;font-weight:bold\">---</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>snapshot.storage.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>VolumeSnapshotContent<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>postgresql-orders-db-sandbox01<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>sandbox01<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">deletionPolicy</span>:<span style=\"color:#bbb\"> </span>Retain<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">driver</span>:<span style=\"color:#bbb\"> </span>pd.csi.storage.gke.io<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">source</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">snapshotHandle</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#39;gcp/projects/staging-eu-castai-vt5hy2/global/snapshots/6645363163809389170&#39;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeSnapshotRef</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>VolumeSnapshot<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>postgresql-orders-db-snap<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>sandbox01<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#00f;font-weight:bold\">---</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>snapshot.storage.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>VolumeSnapshot<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>postgresql-orders-db-snap<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>sandbox01<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">source</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeSnapshotContentName</span>:<span style=\"color:#bbb\"> </span>postgresql-orders-db-sandbox01<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>In Kubernetes, VolumeSnapshotContent (VSC) objects are not namespaced.\nHowever, I need a separate VSC for each different namespace to use, so the\n<code>metadata.name</code> of each VSC must also be different. To make that straightfoward,\nI used the target namespace as part of the name.</p>\n<p>Now it’s time to replace the driver field with the CSI (Container Storage Interface) driver\ninstalled in your K8s cluster. Major cloud providers have CSI driver for block storage that\nsupport VolumeSnapshots but quite often CSI drivers are not installed by default, consult\nwith your Kubernetes provider.</p>\n<p>That manifest above defines a VSC that works on GCP.\nOn AWS, driver and SnashotHandle values might look like:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-YAML\" data-lang=\"YAML\"><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">driver</span>:<span style=\"color:#bbb\"> </span>ebs.csi.aws.com<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">source</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">snapshotHandle</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;snap-07ff83d328c981c98&#34;</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>At this point, I need to use the <em>Retain</em> policy, so that the CSI driver doesn’t try to\ndelete my manually created EBS disk snapshot.</p>\n<p>For GCP, you will have to build this string by hand - add a full project ID and snapshot ID.\nFor AWS, it’s just a plain snapshot ID.</p>\n<p>VSC also requires specifying which VolumeSnapshot (VS) will use it, so VSC and VS are\nreferencing each other.</p>\n<p>Now I can create PersistentVolumeClaim from VS above. It’s important to set this first:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#00f;font-weight:bold\">---</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>postgres-pv-claim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>sandbox01<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">dataSource</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>VolumeSnapshot<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>postgresql-orders-db-snap<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiGroup</span>:<span style=\"color:#bbb\"> </span>snapshot.storage.k8s.io<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOnce<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>21Gi<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>If default StorageClass has <a href=\"https://kubernetes.io/docs/concepts/storage/storage-classes/#volume-binding-mode\">WaitForFirstConsumer</a> policy,\nthen the actual Cloud Disk will be created from the Golden Snapshot only when some Pod bounds that PVC.</p>\n<p>Now I assign that PVC to my Pod (in my case, it’s Postgresql) as I would with any other PVC.</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl -n &lt;namespace&gt; get volumesnapshotContent,volumesnapshot,pvc,pod\n</code></pre><p>Both VS and VSC should be <em>READYTOUSE</em> true, PVC bound, and the Pod (from Deployment or StatefulSet) running.</p>\n<p><strong>To keep on using data from my Golden Snapshot, I just need to repeat this for the\nnext namespace and voilà! No need to waste time and compute resources on the duplication process.</strong></p>","PublishedAt":"2021-09-29 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/09/29/how-to-handle-data-duplication-in-data-heavy-kubernetes-environments/","SourceName":"Kubernetes"}},{"node":{"ID":62,"Title":"Elastic on Elastic: Configuring the Security app to use Cross Cluster Search","Description":"<p>The Elastic Infosec Detections and Analytics team is responsible for building, tuning, and maintaining the security detections used to protect all Elastic systems. Within Elastic we call ourselves Customer Zero and <a href=\"https://www.elastic.co/blog/elastic-on-elastic-how-infosec-deploys-infrastructure-and-stays-up-to-date-with-eck\">we strive to always use the newest versions</a> of our products.&nbsp;\n</p>\n<p>In the previous blog posts we gave an overview of our architecture and what data we send to our clusters. In this blog post we will provide instructions on how we use Cross Cluster Search (CCS) with the Security and Machine Learning (ML) applications\n</p>\n<h2>Configuring CCS<br></h2>\n<p>Getting the Security app to work with CCS only requires a few minor changes. The first step is to configure the Security app so that it knows to look for the CCS index patterns instead of local index patterns. To do this open the Kibana ‘Advanced Settings’ within the Stack Management menu, then located within the Security Solution section update the Elasticsearch indices. These should be set to match the CCS index patterns such as *:auditbeat-*, *:filebeat-*, *:logs-*, and any other index patterns you want to add to your Security app.&nbsp;\n</p>\n<p><img src=\"https://lh4.googleusercontent.com/kxD1eOYM7-2VRGKIc0PAkZgUV3cvNg6bSSgcYv-i5HQox3VLEgQXNDSxbS9sgqNfDT_AhbvWuZcEfQA_OJxi68lEsQZIJY7w15EwoM4e2uFdnyAoBnGS3O3-cudSiz1pU4H-CPvy=s0\" width=\"602\" height=\"249\">\n</p>\n<p>Now when you return to the Security app you should see the Overview, Hosts, and Network pages displaying events from all of your remote clusters.\n</p>\n<h2>Configuring Built In Detection Rules to use CCS</h2>\n<p>Creating brand new custom Detection rules does not require any additional steps, the CCS index patterns will be available to select when you create a new detection rule. If you want to use the 500+ built in Detection rules with CCS it requires a little extra work. To do this you will need to import, duplicate, and bulk edit all of the rules to change the index patterns to use Cross Cluster Search.&nbsp;\n</p>\n<p>The first step is to load all of the pre-built Elastic rules into your Security App. Within the detections tab of the security app navigate to the ‘Manage Detections’ page and click the ‘Load Elastic prebuilt rules’ button.\n</p>\n<h2 style=\"line-height:1.38;background-color:#ffffff;margin-top:0pt;margin-bottom:0pt;padding:18pt 0pt 6pt 0pt;\"><img src=\"https://lh5.googleusercontent.com/UolDnHQhugxnjt3-eXvkWouN6ttWFaJsA0G_PYBCAqcL5qXKHu8-sEjvXWtR4LysIiuiAwoGqwdJzWkXzhyaKNhNfLo77bqS9J3TpjmoDkJO5dKYTjKD3io9KZ0jt4Sa5vmowWOl=s0\" width=\"266\" height=\"65\"></h2>\n<p>The Prebuilt rules can not be directly modified but they can be duplicated and then the duplicates can be modified. To do this you will need to select all of the rules and use the ‘Bulk Actions’ menu to duplicate them all. Before starting this process I recommend changing the ‘refresh settings’ to disable automatically refreshing the table. If you don’t then the table may refresh automatically while you are trying to duplicate the rules causing you to deselect some rules.\n</p>\n<p><img src=\"https://lh4.googleusercontent.com/b6A0AsuACM2hHZ1nDmCklF09TdWKmfoQoUPC-35sKP7mDNN2I3Gnl4O-n8R5nQNL2ldEeLSNuyLpyV6GZFpXDW9P3S5vc3n79sxV9Lsu1cuNRsJPViO_mcHy4rz_W2cY9sZP2v31=s0\" width=\"216\" height=\"77\">\n</p>\n<p>To Select all rules on clusters older than 7.14 you will need to change the ‘Rows per page’ to the maximum amount. <br>\n</p>\n<h2 style=\"line-height:1.38;background-color:#ffffff;margin-top:0pt;margin-bottom:0pt;padding:18pt 0pt 6pt 0pt;\" rel=\"line-height:1.38;background-color:#ffffff;margin-top:0pt;margin-bottom:0pt;padding:18pt 0pt 6pt 0pt;\"><img src=\"https://lh3.googleusercontent.com/THYRjUpwmz2qiAWpp780ZtW_SrQ_3rO3bnPlj67rC4uhbGCzDzzUNJ9aewX29WsZUqa5LTihcGefyLbus8L47PuXWHoezF9Ctqg7yZBcQToWSq6SP4CpLc3bGTZa20jvp2LsdLnw=s0\" width=\"192\" height=\"464\"></h2>\n<p>When all of the rules are displayed select all rules and then in the bulk actions menu select ‘Duplicate Selected’. Duplicating all of the rules may take a couple minutes.\n</p>\n<p rel=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\"><img src=\"https://lh5.googleusercontent.com/E1ZILEFSNwUHOWUaRBlvRGBVe1WCCcfhIoU7szJgWDp0DnIy5w1-u00JL9xJPq25H6cP8ISFftr9rh_-AtdC09zrNVK46ThtvGygYrJUVhHMMUXKAaxjOJ_jeilOZnMPiL4rOgGT=s0\" width=\"348\" height=\"406\">\n</p>\n<p>When this is complete you will have two copies of every rule. Using the filter on the right side of the rule table select only the ‘Custom rules’ that you just created<br><br>\n</p>\n<p><img src=\"https://lh4.googleusercontent.com/_P7bkklIKPRBtuwuQzFwvDEZ-zE6bNH5rxCQEsIcDWA-nDyj9sqiRYXie_ThCvsHsk8PBHFe1xvLK7afHpGnqEkfLWh-YCYZhZbQ9C585TL8OsoJzcfp6Cct4-8FY35-50TjllbJ=s0\" width=\"297\" height=\"57\">\n</p>\n<p>With only the Custom Rules displayed ‘select all’ again and select ‘Export Selected’ from the ‘bulk actions’ menu to download all of the rules as an ndjson file.&nbsp;\n</p>\n<p>Within this ndjson file you will need to find and replace all instances of the normal index patterns with the CCS index pattern. For example, to use the remote auditbeat index pattern you will need to find \"auditbeat-*\" and replace it with \"*:auditbeat-*\".&nbsp; Repeat this for the other index patterns until all of the index patterns have been changed to the new CCS pattern.<br><br>\n</p>\n<p><img src=\"https://lh5.googleusercontent.com/SjH1dydxRimjXQP5NGTeRdaQnrCWgZUCcO-g4O5qZCUhKLcKKzbv_LqIgtv55gU2TbjnJg13wta5hM26e7UTI4FoJZOI3XCtiXgfqIcN49tTPFvnpRmrHQPkq3jOrIDZFamCOAw4=s0\" width=\"375\" height=\"76\">\n</p>\n<p>I also recommend replacing the word ‘[Duplicate]’ that was appended to every rule name with the current stack version. This will help you manage your rules over time and track when each rule was installed or last updated.\n</p>\n<p>After all of the changes have been saved to the custom rules ndjson file you can import the modified rules over the existing rules. Click the ‘Import rule’ button to open the rule import interface\n</p>\n<p><img src=\"https://lh6.googleusercontent.com/LlSpXbKOK9bvQRIJcp27-vmCAm2NcJJoQFZwY8JiuQ3KqMQghZt6D2ldD10dfExemIhIsMUDtlkEN-X8cWWh94PmxIN6CnjYiDWSWe7ercmrZT6sTjuTw1OwOdokPiEAlvLjWWVK=s0\" width=\"592\" height=\"166\">\n</p>\n<p>Drag and drop the modified rule file to the pop up window and select the button to ‘Automatically overwrite saved objects with the same rule ID’. If you forget to do this it will create new rules instead of updating the existing rules and you will probably want to clean up all of the unnecessary rules.\n</p>\n<p><img src=\"https://lh4.googleusercontent.com/EIcsjUGxFJPwMCo_GYTsIl9N-yAmUGysZyP0NSW7VBc644oDRArFLtyjsuXmiM4IOPy7EDBLc08IPRaJsy9K7St3fzdZE6Ak_hklXDzTQX7oPleLyWlg2E3P_cjv3iF9A5cEl9Ak=s0\" width=\"602\" height=\"405\">\n</p>\n<p>After the rules have all been re-imported you can activate all of the rules that are applicable to your environment.<br><br>\n</p>\n<h2>Note on Elastic Query Language (EQL)</h2>\n<p><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/master/eql.html\">EQL</a> support for CCS is available as of Elastic release 7.14, but it requires that all of your remote clusters have also been upgraded to 7.14 or newer. Many of the built in Elastic detection rules use EQL so if you are using CCS with clusters older than 7.14 you will need to disable those rules.<br><br>\n</p>\n<h2>Machine Learning with CCS</h2>\n<p>To use the Machine Learning with CCS you will need to update each of the datafeeds to use the CCS index patterns. When creating your own custom Machine Learning jobs this is easy to do, you simply select the CCS index pattern when creating the new job. To use the built in Security Machine Learning jobs requires modifying the datafeeds of each job to use the CCS index patterns. Because you cannot change a datafeed’s index pattern via the UI, doing this requires access to the Kibana Devtools or API access. My method for doing this is to load the built-in Machine Learning jobs, stop all of the jobs, and then use the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-apis.html\">Machine Learning API</a> to <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-get-datafeed.html\">Get the datafeed</a>, make the change to the datafeed’s Index pattern, and then <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-update-datafeed.html\">update the datafeed</a> with the changes. After this is complete all of the ML jobs and datafeeds can be restarted. If you used the built in Security ML jobs you can now enable the built in Detection rules that use Machine Learning.<br>\n</p>\n<h2>Conclusion</h2>\n<p>In this post we showed you how to configure your Security Application and Machine Learning jobs to work with Cross Cluster Search. Keep an eye out for future blog posts from the Elastic Infosec team on how we use Elastic to protect Elastic.\n</p>","PublishedAt":"2021-09-28 15:00:00+00:00","OriginURL":"https://www.elastic.co/blog/elastic-on-elastic-configuring-the-security-app-to-use-cross-cluster-search","SourceName":"Elastic"}},{"node":{"ID":147,"Title":"Why we built a custom Rust library for Capture","Description":"","PublishedAt":"2021-09-28 13:00:00+00:00","OriginURL":"https://dropbox.tech/application/why-we-built-a-custom-rust-library-for-capture","SourceName":"Dropbox"}},{"node":{"ID":63,"Title":"Ingest data directly from Google Pub/Sub into Elastic using Google Dataflow","Description":"<p>Today we’re excited to announce the latest development in our ongoing partnership with Google Cloud. Now developers, site reliability engineers (SREs), and security analysts can ingest data from Google Pub/Sub to the Elastic Stack with just a few clicks in the Google Cloud Console. By leveraging Google Dataflow templates, Elastic makes it easy to stream events and logs from Google Cloud services like Google Cloud Audit, VPC Flow, or firewall into the Elastic Stack. This allows customers to simplify their data pipeline architecture, eliminate operational overhead, and reduce the time required for troubleshooting. </p><p>Many developers, SREs, and security analysts who use Google Cloud to develop applications and set up their infrastructure also use the Elastic Stack to troubleshoot, monitor, and identify security anomalies. Google and Elastic have worked together to provide an easy-to-use, frictionless way to ingest logs and events from applications and infrastructure in Google Cloud services to Elastic. And all of this is possible with just a few clicks in the Google Cloud Console, without ever installing any data shippers.&nbsp; &nbsp; </p><p>In this blog post, we’ll cover how to get started with agentless data ingestion from Google Pub/Sub to the Elastic Stack using Google Dataflow. </p><h2>Skip the overhead</h2><p>Pub/Sub is a popular serverless asynchronous messaging service used to stream data from Google Operations (formerly Stackdriver), applications built using Google Cloud services, or other use cases involving streaming data integration pipelines. Ingesting Google Cloud Audit, VPC Flow, or firewall logs to third-party analytics solutions like the Elastic Stack requires these logs to be shipped to Google Operations first, then Pub/Sub.&nbsp; Once the logs are in Pub/Sub, a Google Cloud user must decide on the ingestion method to ship messages stored in Google Pub/Sub to third-party analytics solutions. </p><p>A popular option for joint Google and Elastic users is to install Filebeat, Elastic Agent, or Fluentd on a Google Compute Engine VM (virtual machine), then use one of these data shippers to send data from Pub/Sub to the Elastic Stack. Provisioning a VM and installing data shippers requires process and management overhead. The ability to skip this step and ingest data directly from Pub/Sub to Elastic is valuable to many users — especially when&nbsp; it can be done with a few clicks in the Google Cloud Console. Now this is possible through a dropdown menu in Google Dataflow. </p><h2>Streamline data ingest</h2><p>Google Dataflow is a serverless asynchronous messaging service based on Apache Beam. Dataflow can be used instead of Filebeat to ship logs directly from the Google Cloud Console. The Google and Elastic teams worked together to develop an out-of-the-box Dataflow template that pushes logs and events from Pub/Sub to Elastic. This template replaces lightweight processing such as data format transformation previously completed by Filebeat in a serverless manner — with no other changes for users who previously used the Elasticsearch ingest pipeline.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </p><p>Here is a summary of data ingestion flow. The integration works for all users, regardless of whether they are using the Elastic Stack on Elastic Cloud, Elastic Cloud in the Google Cloud Marketplace, or a self-managed environment. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt4a0252dfb0591d2f/6143c63764c8007a9bdea6f5/blog-gcp-integration-pubsub-1.png\" data-sys-asset-uid=\"blt4a0252dfb0591d2f\" alt=\"blog-gcp-integration-pubsub-1.png\"/></p><h2>Get started</h2><p>In this section, we’ll go into a step-by-step tutorial on how to get started with the Dataflow template for analyzing <a href=\"https://cloud.google.com/logging/docs/audit\" target=\"_self\">GCP Audit Logs</a> in the Elastic Stack. </p><p>Audit logs contain information that help you answer the question of \"where, how and when\" of operational changes that happen in your Google Cloud account. With our Pub/Sub template, you can stream audit logs from GCP to Elasticsearch and gather insights within seconds.&nbsp; </p><p>We’ll start with installing the Elastic GCP integration straight from the Kibana web UI, which contains prebuilt dashboards, ingest node configurations, and other assets that help you get the most of the audit logs you ingest.&nbsp; </p><p>Before configuring the Dataflow template, you will have to create a <a href=\"https://cloud.google.com/pubsub/docs/quickstart-console\" target=\"_self\">Pub/Sub topic and subscription</a> from your Google Cloud Console where you can send your logs from Google Operations Suite. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt729ea82c62f6cf41/6143c6569d27cf7da4ba0a18/blog-gcp-integration-pubsub-2.png\" data-sys-asset-uid=\"blt729ea82c62f6cf41\" alt=\"blog-gcp-integration-pubsub-2.png\"/></p><p>Next, navigate to the Google Cloud Console to configure our <a href=\"https://cloud.google.com/dataflow/\" target=\"_self\">Dataflow</a> job.&nbsp; </p><p>In the Dataflow product, click “Create job from template” and select \"Pub/Sub to Elasticsearch\" from the Dataflow template dropdown menu. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltbd14459da3fb91c0/6143c6648440e97ef58272c3/blog-gcp-integration-pubsub-3.png\" data-sys-asset-uid=\"bltbd14459da3fb91c0\" alt=\"blog-gcp-integration-pubsub-3.png\"/></p><p>Fill in required parameters, including your Cloud ID and Base64-encoded API Key for Elasticsearch. Since we are streaming audit logs, add “audit” as a log type parameter. Cloud ID can be found from Elastic Cloud UI as shown below. API Key can be created using the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/security-api-create-api-key.html\" target=\"_self\">Create API key API</a>. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltaa76aed1b8faf542/6143c677947b692d209b5352/blog-gcp-integration-pubsub-4.png\" data-sys-asset-uid=\"bltaa76aed1b8faf542\" alt=\"blog-gcp-integration-pubsub-4.png\"/></p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt56be59a0016ed28c/6143c686f725af79f53fc4ea/blog-gcp-integration-pubsub-5.png\" data-sys-asset-uid=\"blt56be59a0016ed28c\" alt=\"blog-gcp-integration-pubsub-5.png\"/></p><p>Click “Run Job” and wait for Dataflow to execute the template, which takes about a few minutes. As you can see, you don’t need to leave the Google Cloud Console or manage agents! </p><p>Now, navigate to Kibana to see your logs parsed and visualized in the [Logs GCP] dashboard. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt879b955d1a95e437/6143c69364c8007a9bdea6fd/blog-gcp-integration-pubsub-6.png\" data-sys-asset-uid=\"blt879b955d1a95e437\" alt=\"blog-gcp-integration-pubsub-6.png\"/></p><h2>Wrapping up</h2><p>Elastic is constantly making it easier and more frictionless for customers to run where they want and use what they want — and this streamlined integration with Google Cloud is the latest example of that. Elastic Cloud extends the value of the Elastic Stack, allowing customers to do more, faster, making it the best way to experience our platform. For more information on the integration, <a href=\"https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming#cloudpubsubtoelasticsearch\" target=\"_self\">visit Google’s documentation</a>. To get started using Elastic on Google Cloud, visit the <a href=\"https://console.cloud.google.com/marketplace/product/elastic-prod/elastic-cloud?utm_source=elastic&utm_medium=elastic_blog&utm_campaign=ingest_data_directly_from_google_pub_sub_into_elastic_using_google_dataflow\" target=\"_self\">Google Cloud Marketplace</a> or <a href=\"https://www.elastic.co/\" target=\"_self\">elastic.co</a>. </p>","PublishedAt":"2021-09-27 17:00:00+00:00","OriginURL":"https://www.elastic.co/blog/ingest-data-directly-from-google-pub-sub-into-elastic-using-google-dataflow","SourceName":"Elastic"}},{"node":{"ID":1254,"Title":"Blog: Spotlight on SIG Node","Description":"<p><strong>Author:</strong> Dewan Ahmed, Red Hat</p>\n<h2 id=\"introduction\">Introduction</h2>\n<p>In Kubernetes, a <em>Node</em> is a representation of a single machine in your cluster. <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG Node</a> owns that very important Node component and supports various subprojects such as Kubelet, Container Runtime Interface (CRI) and more to support how the pods and host resources interact. In this blog, we have summarized our conversation with <a href=\"https://twitter.com/ehashdn\">Elana Hashman (EH)</a> &amp; <a href=\"https://twitter.com/SergeyKanzhelev\">Sergey Kanzhelev (SK)</a>, who walk us through the various aspects of being a part of the SIG and share some insights about how others can get involved.</p>\n<h2 id=\"a-summary-of-our-conversation\">A summary of our conversation</h2>\n<h3 id=\"could-you-tell-us-a-little-about-what-sig-node-does\">Could you tell us a little about what SIG Node does?</h3>\n<p>SK: SIG Node is a vertical SIG responsible for the components that support the controlled interactions between the pods and host resources. We manage the lifecycle of pods that are scheduled to a node. This SIG's focus is to enable a broad set of workload types, including workloads with hardware specific or performance sensitive requirements. All while maintaining isolation boundaries between pods on a node, as well as the pod and the host. This SIG maintains quite a few components and has many external dependencies (like container runtimes or operating system features), which makes the complexity we deal with huge. We tame the complexity and aim to continuously improve node reliability.</p>\n<h3 id=\"sig-node-is-a-vertical-sig-could-you-explain-a-bit-more\">&quot;SIG Node is a vertical SIG&quot; could you explain a bit more?</h3>\n<p>EH: There are two kinds of SIGs: horizontal and vertical. Horizontal SIGs are concerned with a particular function of every component in Kubernetes: for example, SIG Security considers security aspects of every component in Kubernetes, or SIG Instrumentation looks at the logs, metrics, traces and events of every component in Kubernetes. Such SIGs don't tend to own a lot of code.</p>\n<p>Vertical SIGs, on the other hand, own a single component, and are responsible for approving and merging patches to that code base. SIG Node owns the &quot;Node&quot; vertical, pertaining to the kubelet and its lifecycle. This includes the code for the kubelet itself, as well as the node controller, the container runtime interface, and related subprojects like the node problem detector.</p>\n<h3 id=\"how-did-the-ci-subproject-start-is-this-specific-to-sig-node-and-how-does-it-help-the-sig\">How did the CI subproject start? Is this specific to SIG Node and how does it help the SIG?</h3>\n<p>SK: The subproject started as a follow up after one of the releases was blocked by numerous test failures of critical tests. These tests haven’t started falling all at once, rather continuous lack of attention led to slow degradation of tests quality. SIG Node was always prioritizing quality and reliability, and forming of the subproject was a way to highlight this priority.</p>\n<h3 id=\"as-the-3rd-largest-sig-in-terms-of-number-of-issues-and-prs-how-does-your-sig-juggle-so-much-work\">As the 3rd largest SIG in terms of number of issues and PRs, how does your SIG juggle so much work?</h3>\n<p>EH: It helps to be organized. When I increased my contributions to the SIG in January of 2021, I found myself overwhelmed by the volume of pull requests and issues and wasn't sure where to start. We were already tracking test-related issues and pull requests on the CI subproject board, but that was missing a lot of our bugfixes and feature work. So I began putting together a triage board for the rest of our pull requests, which allowed me to sort each one by status and what actions to take, and documented its use for other contributors. We closed or merged over 500 issues and pull requests tracked by our two boards in each of the past two releases. The Kubernetes devstats showed that we have significantly increased our velocity as a result.</p>\n<p>In June, we ran our first bug scrub event to work through the backlog of issues filed against SIG Node, ensuring they were properly categorized. We closed over 130 issues over the course of this 48 hour global event, but as of writing we still have 333 open issues.</p>\n<h3 id=\"why-should-new-and-existing-contributors-consider-joining-sig-node\">Why should new and existing contributors consider joining SIG Node?</h3>\n<p>SK: Being a SIG Node contributor gives you skills and recognition that are rewarding and useful. Understanding under the hood of a kubelet helps architecting better apps, tune and optimize those apps, and gives leg up in issues troubleshooting. If you are a new contributor, SIG Node gives you the foundational knowledge that is key to understanding why other Kubernetes components are designed the way they are. Existing contributors may benefit as many features will require SIG Node changes one way or another. So being a SIG Node contributor helps building features in other SIGs faster.</p>\n<p>SIG Node maintains numerous components, many of which have dependency on external projects or OS features. This makes the onboarding process quite lengthy and demanding. But if you are up for a challenge, there is always a place for you, and a group of people to support.</p>\n<h3 id=\"what-do-you-do-to-help-new-contributors-get-started\">What do you do to help new contributors get started?</h3>\n<p>EH: Getting started in SIG Node can be intimidating, since there is so much work to be done, our SIG meetings are very large, and it can be hard to find a place to start.</p>\n<p>I always encourage new contributors to work on things that they have some investment in already. In SIG Node, that might mean volunteering to help fix a bug that you have personally been affected by, or helping to triage bugs you care about by priority.</p>\n<p>To come up to speed on any open source code base, there are two strategies you can take: start by exploring a particular issue deeply, and follow that to expand the edges of your knowledge as needed, or briefly review as many issues and change requests as you possibly can to get a higher level picture of how the component works. Ultimately, you will need to do both if you want to become a Node reviewer or approver.</p>\n<p><a href=\"https://twitter.com/dims\">Davanum Srinivas</a> and I each ran a cohort of group mentoring to help teach new contributors the skills to become Node reviewers, and if there's interest we can work to find a mentor to run another session. I also encourage new contributors to attend our Node CI Subproject meeting: it's a smaller audience and we don't record the triage sessions, so it can be a less intimidating way to get started with the SIG.</p>\n<h3 id=\"are-there-any-particular-skills-you-d-like-to-recruit-for-what-skills-are-contributors-to-sig-usability-likely-to-learn\">Are there any particular skills you’d like to recruit for? What skills are contributors to SIG Usability likely to learn?</h3>\n<p>SK: SIG Node works on many workstreams in very different areas. All of these areas are on system level. For the typical code contributions you need to have a passion for building and utilizing low level APIs and writing performant and reliable components. Being a contributor you will learn how to debug and troubleshoot, profile, and monitor these components, as well as user workload that is run by these components. Often, with the limited to no access to Nodes, as they are running production workloads.</p>\n<p>The other way of contribution is to help document SIG node features. This type of contribution requires a deep understanding of features, and ability to explain them in simple terms.</p>\n<p>Finally, we are always looking for feedback on how best to run your workload. Come and explain specifics of it, and what features in SIG Node components may help to run it better.</p>\n<h3 id=\"what-are-you-getting-positive-feedback-on-and-what-s-coming-up-next-for-sig-node\">What are you getting positive feedback on, and what’s coming up next for SIG Node?</h3>\n<p>EH: Over the past year SIG Node has adopted some new processes to help manage our feature development and Kubernetes enhancement proposals, and other SIGs have looked to us for inspiration in managing large workloads. I hope that this is an area we can continue to provide leadership in and further iterate on.</p>\n<p>We have a great balance of new features and deprecations in flight right now. Deprecations of unused or difficult to maintain features help us keep technical debt and maintenance load under control, and examples include the dockershim and DynamicKubeletConfiguration deprecations. New features will unlock additional functionality in end users' clusters, and include exciting features like support for cgroups v2, swap memory, graceful node shutdowns, and device management policies.</p>\n<h3 id=\"any-closing-thoughts-resources-you-d-like-to-share\">Any closing thoughts/resources you’d like to share?</h3>\n<p>SK/EH: It takes time and effort to get to any open source community. SIG Node may overwhelm you at first with the number of participants, volume of work, and project scope. But it is totally worth it. Join our welcoming community! <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG Node GitHub Repo</a> contains many useful resources including Slack, mailing list and other contact info.</p>\n<h2 id=\"wrap-up\">Wrap Up</h2>\n<p>SIG Node hosted a <a href=\"https://www.youtube.com/watch?v=z5aY4e2RENA\">KubeCon + CloudNativeCon Europe 2021 talk</a> with an intro and deep dive to their awesome SIG. Join the SIG's meetings to find out about the most recent research results, what the plans are for the forthcoming year, and how to get involved in the upstream Node team as a contributor!</p>","PublishedAt":"2021-09-27 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/09/27/sig-node-spotlight-2021/","SourceName":"Kubernetes"}},{"node":{"ID":40,"Title":"My internship on Asana’s Engineering team","Description":"<img width=\"1024\" height=\"656\" src=\"https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-1024x656.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" loading=\"lazy\" style=\"display: block; margin: auto; margin-bottom: 5px;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-1024x656.png 1024w, https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-520x333.png 520w, https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-1536x984.png 1536w, https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero.png 1607w, https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-520x333@2x.png 1040w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><p>This post was written by Jordan Hunt during his internship before he went back to school! Hi there, I’m Jordan and I’m a rising junior at Harvey Mudd College studying computer science and mathematics. I spent this summer interning at Asana as a Product Engineer on their Pricing &#38; Packaging team. Interning at Asana has [&#8230;]</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.asana.com/2021/09/engineering-internship/\">My internship on Asana&#8217;s Engineering&nbsp;team</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.asana.com\">The Asana Blog</a>.</p>\n","PublishedAt":"2021-09-24 14:37:03+00:00","OriginURL":"https://blog.asana.com/2021/09/engineering-internship/","SourceName":"Asana"}},{"node":{"ID":474,"Title":"Feature flags and product analytics","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/09/ask-an-expert-dave-martin@2x-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>Experimentation is a huge part of getting your product right, whether it&#8217;s trying out a new feature or potential tweaks to existing elements of your app. When it comes to running these kinds of product tests, using feature flags can be a really effective and minimally disruptive way to go. We spoke to David Martin,</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/feature-flags-and-product-analytics-working-together/\">Feature flags and product analytics</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-09-24 00:12:00+00:00","OriginURL":"https://mixpanel.com/blog/feature-flags-and-product-analytics-working-together/","SourceName":"Mixpanel"}},{"node":{"ID":64,"Title":"Elastic APM iOS agent technical preview released","Description":"<p>We are proud to announce the preview release of the Elastic APM iOS agent! This release is intended to elicit feedback from the community, while providing some initial functionality within the Elastic Observability stack and is not intended for production use. Now is your chance to influence the direction of this new iOS agent and let us know what you think on our <a href=\"https://discuss.elastic.co/c/apm\">discussion forum</a>. If you find an issue, or would like to contribute yourself, visit the <a href=\"https://github.com/elastic/apm-agent-ios\">GitHub repository</a>. </p> <p><a href=\"https://www.elastic.co/solutions/apm\">Elastic APM</a> is an Application Performance Monitoring solution from Elastic and alongside the iOS agent, there are official agents available for <a href=\"https://github.com/elastic/apm-agent-java\">Java</a>, <a href=\"https://github.com/elastic/apm-agent-nodejs\">Node.js</a>, <a href=\"https://github.com/elastic/apm-agent-python\">Python</a>,<a href=\"https://github.com/elastic/apm-agent-ruby\"> Ruby</a>, <a href=\"https://github.com/elastic/apm-agent-js-base\">JavaScript/RUM</a>, <a href=\"https://github.com/elastic/apm-agent-dotnet\">.NET</a>, <a href=\"https://github.com/elastic/apm-agent-php\">PHP</a>, and <a href=\"https://github.com/elastic/apm-agent-go\">Go</a>. Elastic APM helps you to gain insight into the performance of your application, track errors, and gauge the end-user experience in the browser. </p> <p>I’ll be going into the details of the release below, but if you’re ready to jump into the documentation right away you can find it at the <a href=\"https://www.elastic.co/guide/en/apm/agent/swift/current/index.html\">Elastic APM iOS agent documentation</a>. </p> <strong><h2>Supported frameworks</h2></strong> <p>The Elastic APM iOS agent is built on the <a href=\"https://github.com/open-telemetry/opentelemetry-swift\">opentelementry-swift sdk</a>. This means that any frameworks or libraries that are instrumented with Open Telemetry will be captured by the Elastic APM iOS agent. Additionally, any custom OTel instrumentation you add to your application will be picked up by our agent. </p> <p>We are initially providing auto instrumentation of following: </p> <ul> <li aria-level=\"1\">URLSession</li> <li aria-level=\"1\">CPU & Memory usage</li> <li aria-level=\"1\">Network connectivity</li> <li aria-level=\"1\">Device & Application attributes</li> </ul> <p>Our main focus is to provide insight into your backend services from the perspective of your mobile application, automatically displaying distributed traces starting at your mobile app. </p> <strong><h2>Downloading the agent</h2></strong> <p>The agent will initially be provided through the <a href=\"https://swift.org/package-manager/\">Swift Package Manager</a>. It can be added to an iOS project through the <a href=\"https://developer.apple.com/documentation/swift_packages/adding_package_dependencies_to_your_app\">Xcode SPM dependency manager</a> or through a <code>Package.swift</code> file.&nbsp; </p> <p>Simply add the following to your Package.swift dependencies </p> <pre class=\"prettyprint\">         dependencies: [ \n        .package(name: \"apm-agent-ios\", url: \"https://github.com/elastic/apm-agent-ios\", .branch(“v0.1.0\")), \n… </pre> <p>And add “iOSAgent” to the targets you wish to instrument: </p> <pre class=\"prettyprint\">.target( \n            name: \"MyLibrary\", \n            dependencies: [ \n                .product(name: \"iOSAgent\", package: \"apm-agent-ios\") \n            ]), </pre> <strong><h2>The agent API</h2></strong> <p>The Elastic APM iOS Agent has a few project requirements: </p> <ul> <li aria-level=\"1\">It’s only compatible with Swift (sorry Objective-C engineers)&nbsp;</li> <li aria-level=\"1\">It requires Swift v5.3</li> <li aria-level=\"1\">It requires the minimum of iOS v11</li> </ul> <p>The agent API is fairly slim. We provide a configuration object that allows the agent to be set up for an on-prem or cloud solution. </p> <p>If you’re using SwiftUI to build your app, you can set up the agent as follows:&nbsp; </p> <pre class=\"prettyprint\">struct MyApp: App { \n    init() { \n        var config = AgentConfiguration() \n        config.collectorAddress = \"127.0.0.1\"  \n        config.collectorPort = 8200  \n        config.collectorTLS = false  \n        config.secretToken = \"&lt;secret token&gt;\"  \n        Agent.start(with: config) \n    } </pre> <p>&nbsp;Read up more on configuration in the “<a href=\"https://www.elastic.co/guide/en/apm/agent/swift/0.x/setup.html\">Set up the Agent</a>” doc. </p> <p>The agent also captures any data recorded through the OpenTelementry-Swift APIs, including traces and metrics. Here’s an example on how to start a simple trace: </p> <pre class=\"prettyprint\">let instrumentationLibraryName = \"SimpleExporter\" \nlet instrumentationLibraryVersion = \"semver:0.1.0\" \nvar instrumentationLibraryInfo = InstrumentationLibraryInfo(name: instrumentationLibraryName, version: instrumentationLibraryVersion) \nvar tracer = OpenTelemetrySDK.instance.tracerProvider.get(instrumentationName: instrumentationLibraryName, instrumentationVersion: instrumentationLibraryVersion) as! TracerSdk \nfunc simpleSpan() { \n    let span = tracer.spanBuilder(spanName: \"SimpleSpan\").setSpanKind(spanKind: .client).startSpan() \n    span.setAttribute(key: sampleKey, value: sampleValue) \n    Thread.sleep(forTimeInterval: 0.5) \n    span.end() \n} </pre> <p>You can find more examples on how to use the OTel API at <a href=\"https://github.com/open-telemetry/opentelemetry-swift/tree/main/Examples\">OpenTelementry-Swift examples</a>. </p> <p>If you decide to go this route, you may have to add OpenTelemetry-Swift as a dependency to your project as well.&nbsp; </p> <strong><h2>Summary and future</h2></strong> <p>We would be thrilled to receive your feedback in our <a href=\"https://discuss.elastic.co/c/apm\">discussion forum</a> or in <a href=\"https://github.com/elastic/apm-agent-ios\">our GitHub repository</a>. Please keep in mind that the current release is a preview and we may introduce breaking changes. We are excited to be launching this mobile offering and already have many ideas for what comes next, but we want the community to help guide our direction. Check out our <a href=\"https://github.com/elastic/apm-agent-ios/blob/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> and let the PRs fly! </p>","PublishedAt":"2021-09-23 18:00:00+00:00","OriginURL":"https://www.elastic.co/blog/elastic-apm-ios-agent-technical-preview-released","SourceName":"Elastic"}},{"node":{"ID":769,"Title":"Real-Time Exactly-Once Ad Event Processing with Apache Flink, Kafka, and Pinot","Description":"<p><span style=\"font-weight: 400;\">Uber recently launched a new capability: Ads on UberEats. With this new ability came new challenges that needed to be solved at Uber, such as systems for ad auctions, bidding, attribution, reporting, and more. This article focuses on how we </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/real-time-exactly-once-ad-event-processing/\">Real-Time Exactly-Once Ad Event Processing with Apache Flink, Kafka, and Pinot</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-09-23 16:00:42+00:00","OriginURL":"https://eng.uber.com/real-time-exactly-once-ad-event-processing/","SourceName":"Uber"}},{"node":{"ID":65,"Title":"How the French Ministry of Agriculture deploys Elastic to monitor the commercial fishing industry","Description":"<p>Within the French Ministry of Agriculture and Food (the Ministry), our team of architects in the Methods, Support and Quality office (BMSQ) evaluate and supply software solutions to resolve issues encountered by project teams that affect various disciplines.\n</p><p>As data specialists, one area we’ve been involved in includes reconfiguring the traceability of activities for the commercial fishing industry. The aim is to improve the quality, speed and precision of how we collect and analyze large volumes of data connected to the industry — from declared fish hauls, harbor exit manifests, to GPS data tracking vessel locations.\n</p><p>The challenge we have is to provide up-to-date information that is verified, complete, dynamic and can be viewed in various formats depending on the target audience, and Elastic is the solution. Elastic handles ingesting all of our data and render visualizations to make it easy to share and use real-time information about commercial fishing activity. With this integrated data, we can take enforcement action, stop illegal fishing, and negotiate fishing rights with our neighboring countries.\n</p><h1 dir=\"ltr\">Why we choose Elastic over Splunk and Graylog</h1><p>The first stage of the project was to perform a proof of concept with a solution capable of storing, extracting, and presenting the data related to fishing activities in real time.\n</p><p>We benchmarked the <a href=\"https://www.elastic.co/elastic-stack/\">Elastic Stack</a> against other tools, such as Graylog and Splunk. We were ultimately won over by the Elastic Stack’s speed and ease of use, along with its power and scalability. The data presentation and visualization tools, <a href=\"https://www.elastic.co/what-is/kibana-canvas\">Canvas</a>, and <a href=\"https://www.elastic.co/kibana/\">Kibana</a>, have also played crucial roles in this project, enabling us to efficiently provide information for our end users in the context of increasingly strict protective fishing regulations and measures. In addition, our Elastic subscription, reduces our development time and allows us to focus on our real work, thanks to the support team at Elastic.\n</p><h1 dir=\"ltr\">Casting a wide regulatory fishing net with Elastic</h1><p>With GPS systems required on fishing vessels larger than 12 meters (39 feet), we have been able to track boats while at the same time indexing that monitoring data into <a href=\"https://www.elastic.co/elasticsearch/\">Elasticsearch</a>, where it is visualized in either Kibana or Canvas. This enables us to help Ministry officials on several enforcement levels:\n</p><ul>\n\t<li dir=\"ltr\" aria-level=\"1\">Locating activity zones of boats and areas of intense fishing</li>\n\t<li dir=\"ltr\" aria-level=\"1\">Monitoring fishing quotas in FAO (Food and Agriculture Organization) zones&nbsp;</li>\n\t<li dir=\"ltr\" aria-level=\"1\">Flagging infringements of the law</li>\n</ul><em><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltb97730e25592db6c/6164acc6ca79db05abb0f1ad/kibana-presentation-areas-intense-fishing.jpg\" data-sys-asset-uid=\"bltb97730e25592db6c\" alt=\"kibana-presentation-areas-intense-fishing.jpg\">\n</p>Sample Kibana presentation to locate areas of intense fishing&nbsp;&nbsp;<br></em><br><p>With Canvas, we can refine the granularity, quality, and format to ensure the fishery data is presented in the most suitable format for the audience, especially a non-technical audience.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltf4ea8efa140c8790/6164ae0656faa61e63fdd9a9/infographic-quotas-de-peche.png\" data-sys-asset-uid=\"bltf4ea8efa140c8790\" alt=\"infographic-quotas-de-peche.png\"></p><p><em>Example of the infographics generated using Canvas to monitor fishing data of cod, sardine, and tuna\n\t</em>\n</p><p>We could not render presentations like this with our legacy tools, which were conventional databases and a Java application. They were at their limits in terms of the required performance due to the number of filter fields, 300 and counting. Now, once the data has been processed in Logstash, stored and indexed in Elasticsearch, it can be filtered, cross-referenced and correlated in real time.&nbsp;\n</p><p>Elastic gives us the ability to verify the precision and compliance of statements declared by boats compared with actual recorded events.\n</p><p>We are storing our raw data for 10 years. This amounts to 135 million records in Elasticsearch. In addition, each record contains more than 300 filter fields. We receive raw ERS (Electronic Reporting System) data in XML format, as issued by the boats using onboard software or GPS, and we model this data as it flows in so we can integrate it into our Elasticsearch cluster.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt4a80668166d5428f/6164ae5edd1cf90b821de893/diagram-ers-data-xml-format-boats-gps-model.png\" data-sys-asset-uid=\"blt4a80668166d5428f\" alt=\"diagram-ers-data-xml-format-boats-gps-model.png\"></p><h1 dir=\"ltr\">How Elastic fits in the architectural layout of the French Ministry of Agriculture <br></h1><p>This sea of information allows us to pinpoint quantities and species fished, rejections of protected species, type of boat plus its flag, registration and equipment, fishing quotas per territorial area, satellite operator depending on the region of the globe, and much more.&nbsp;\n</p><p>Real-time information detailed by region is the basis for consolidated analyses and discussion to facilitate immediate remedying of any infringements of the law, rapid reaction to media controversy relating to protected marine species, and even the renegotiation of quotas each year within the European Union.\n</p><h1 dir=\"ltr\">Expanding to political, economical and environmental use cases&nbsp;</h1><p>The Ministry is continuing to closely monitor new releases of the Elastic Stack. We are anticipating the availability of a French version of Kibana, which would expand the solution’s user group. The most recent functionalities provided in versions 7.11 and 7.12 of Elastic are being tested with great interest — in particular the addition of the tracks layer in the Maps application. This feature takes an index of point locations, ordered by time, and displays them as a line, enabling us to track the route taken by boats, as shown below:\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt1c263e15a3d96e4d/6164ac5daeba391136e44d0e/dashboard-test-trace.jpg\" data-sys-asset-uid=\"blt1c263e15a3d96e4d\" alt=\"dashboard-test-trace.jpg\">\n</p><p>We have been grateful for the ease of use, flexibility, and creativity of Kibana and Canvas in enabling stakeholders to remain well informed and to react rapidly to increasingly stringent protective regulations and measures. Moreover, the fishing data provided in XML format is modeled by batch, which enables requests to be processed via Elasticsearch on a continuously growing volume of data, without having to wait for all 10 years of the current stored data to be processed. Elastic also enables the indexation process to be repeated each time new data is added to existing fields.&nbsp;\n</p><p>In the short term, the Ministry’s aim is to conclude the roll-out of this solution and open it up to a growing group of users.\n</p><p>Beyond fishing data, we are going to need to store, process, and analyze increasing volumes of tracking data, particularly in regard to food — from farm to table. All of which means that Elastic could be of use for these new development projects with high political, economical and environmental stakes.\n</p><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\"><br>\n</p><hr><p><em><strong>Sébastien Arnaud</strong> — Exchanges & Data architect at the French Ministry of Agriculture</em>\n</p><p>Following initial training in the field of networks and IT security, he has worked on complex data exchange and transformation solutions. He likes to design and integrate innovative architectures for processing, storing and evaluating increasingly large volumes of data.\n</p>","PublishedAt":"2021-09-23 15:00:00+00:00","OriginURL":"https://www.elastic.co/blog/how-the-french-ministry-of-agriculture-deploys-elastic-to-monitor-the-commercial-fishing-industry","SourceName":"Elastic"}},{"node":{"ID":66,"Title":"Elastic 7.15: Create powerful, personalized search experiences in seconds","Description":"<p>We are pleased to announce the general availability of Elastic 7.15, a release that brings a broad set of new capabilities to the Elastic Search Platform (including Elasticsearch and Kibana) and its three built-in solutions — Elastic Enterprise Search, Elastic Observability, and Elastic Security.\n</p><p>With Elastic 7.15 comes the general availability of the Elastic App Search web crawler and tighter integrations with Google Cloud — enabling our customers and community to more quickly create powerful new web search experiences, to ingest data more quickly and securely, and to more easily put their data to work with the power of search.\n</p><p>In addition, with Elastic Observability’s new APM correlations feature, DevOps teams can accelerate root cause analysis and reduce mean time to resolution (MTTR) by automatically surfacing attributes correlated with high-latency or erroneous transactions.\n</p><p>And, as the saying goes, if you’re going to observe... why not (also) protect?\n</p><p>To this end, with Elastic 7.15, Elastic Security enhances Limitless XDR (extended detection and response) with both malicious behavior protection for (nearly) every OS and one-click host isolation for cloud-native Linux environments.\n</p><div class=\"video embed-container\" style=\"height: 319.725px;\">\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/yN5mR9f6pUny82KZNxZAyb.jpg\" data-uuid=\"yN5mR9f6pUny82KZNxZAyb\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-disable_analytics=\"1\" data-hidden_controls=\"1\" data-muted=\"1\" disable_analytics=\"1\" style=\"width: 100%; margin: auto; display: block;\">\n</div><p>Elastic 7.15 is <a href=\"https://cloud.elastic.co/registration?elektra=whats-new-elastic-7-13-blog\">available now on Elastic Cloud</a> — the only hosted Elasticsearch offering to include all of the new features in this latest release. You can, of course, also <a href=\"/downloads/\">download the Elastic Stack</a> and our cloud orchestration products, Elastic Cloud Enterprise and Elastic Cloud for Kubernetes, for a self-managed experience.\n</p><h2>Elastic Enterprise Search</h2><h3>Create powerful new web search experiences in seconds with the general availability of the Elastic App Search web crawler</h3><p>With 7.15, Enterprise Search makes it faster than ever for organizations to get up and running with web search — freeing up technical teams to focus on other important projects. The Elastic App Search web crawler, now generally available, makes implementing search and ingesting website content nearly effortless. In addition to a number of web crawler improvements that make setup a snap, like automatic crawling controls, content extraction tools, and the ability to natively analyze logs and metrics in Kibana, the web crawler now enables customers to use a single platform to search all of their organization’s data — even websites.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt1ce8388dee720102/613cdadbfbe3b8273005fc82/7-15-elastic-co-starting-a-crawl.gif\" data-sys-asset-uid=\"blt1ce8388dee720102\" alt=\"Generally available with Elastic 7.15, the Elastic App Search Web Crawler makes it easy to ingest website content\"><br>\n</p><figcaption>Generally available with Elastic 7.15, the Elastic App Search web crawler makes it easy to ingest website content</figcaption><p>To learn more visit the <a href=\"/blog/whats-new-elastic-enterprise-search-7-15-0\">Elastic Enterprise Search 7.15 blog</a>.\n</p><h2>Elastic Observability</h2><h3>Automate root cause analysis for faster application troubleshooting</h3><p>DevOps teams and site reliability engineers are constantly challenged by the need to sift through overwhelming amounts of data to keep modern applications performant and error-free. More often than not, this is a manual and time-consuming effort. To effectively resolve complex problems, these users need the ability to collect, unify, and analyze an increasing volume of telemetry data and quickly distill meaningful insights. Automation and machine intelligence have become essential components of the troubleshooter’s toolkit.\n</p><p>With Elastic 7.15, we’re excited to announce the general availability of Elastic Observability’s APM correlations feature. This new capability will help DevOps teams and site reliability engineers to accelerate root cause analysis by automatically surfacing attributes of the APM data set that are correlated with high-latency or erroneous transactions.<img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltebe967f6d2648245/613fa0d58540c92b07a99fdf/7-15-animation-apm-latency-correlations.gif\" data-sys-asset-uid=\"bltebe967f6d2648245\" alt=\"Elastic APM correlations, now generally available, accelerate root cause analysis to free up DevOps and SRE teams\">\n</p><figcaption>Elastic APM correlations, now generally available, accelerate root cause analysis to free up DevOps and SRE teams</figcaption><h3>Streamline monitoring of Google Cloud Platform services with frictionless log ingestion</h3><p>Elastic’s new Google Cloud Dataflow integration drives efficiency with the frictionless ingestion of log data directly from the Google Cloud Platform (GCP) console. This agentless approach provides an “easy button” for customers — eliminating the cost and hassle of administrative overhead and further extending Elastic’s ability to more easily monitor&nbsp;native GCP services.\n</p><p>To learn more visit the <a href=\"/blog/whats-new-elastic-observability-7-15-0\">Elastic Observability 7.15 blog</a>.\n</p> <strong><h2>Elastic Security</h2></strong><p>With Elastic 7.15, Elastic Security augments extended detection and response by equipping Elastic Agent to end threats at the endpoint, with new layers of prevention for every OS and host isolation for cloud-native Linux environments.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltb7921b50c291a90c/613fa1703e034728ba0171ea/screenshot-security-detection-host-alert-7-15.jpg\" data-sys-asset-uid=\"bltb7921b50c291a90c\" alt=\"Elastic Security 7.15 powers extended detection and response (XDR) with malicious behavior protection for every OS and host isolation for cloud-native Linux environments\">\n</p><figcaption>Elastic Security 7.15 powers extended detection and response (XDR) with malicious behavior protection for every OS and host isolation for cloud-native Linux environments</figcaption><h3>Stop advanced threats at the endpoint with malicious behavior protection for Linux, Windows, and macOS hosts</h3><p>Malicious behavior protection, new in version 7.15, arms Elastic Agent to stop advanced threats at the endpoint. It provides a new layer of protection for Linux, Windows, and macOS hosts, powered by analytics that prevent attack techniques leveraged by known threats. This capability buttresses <a href=\"/blog/whats-new-elastic-security-7-14-0\">existing malware and ransomware prevention</a> with dynamic prevention of post-execution behavior. Prevention is achieved by pairing post-execution analytics with response actions tailored to disrupt the adversary early in the attack, such as killing a process to stop a payload from being downloaded.\n</p><h3>Contain attacks with one-click host isolation from within Kibana</h3><p>In addition to malicious behavior protection, with the release of Elastic 7.15, Elastic Security enables analysts to quickly and easily quarantine Linux hosts via a remote action from Kibana. With (just) one click, analysts can respond to malicious activity by isolating a host from a network, containing the attack and preventing lateral movements. While <a href=\"/blog/whats-new-elastic-security-7-14-0\">host isolation was introduced for Windows and macOS in version 7.14</a>, it is now available on every OS protected by Elastic Agent.\n</p><p>We’re implementing this capability on Linux systems via <a href=\"https://ebpf.io/\">extended Berkeley Packet Filter (eBPF)</a> technology, a reflection of our commitment to technologies that enable users to observe and protect modern cloud-native systems in the most frictionless way possible.\n</p><p>For more information on our continuing efforts in the realm of cloud security, check out our recent announcements on Elastic joining forces with <a href=\"/blog/elastic-and-build-security-shifting-left-together-to-secure-the-cloud\">build.security</a> and <a href=\"/blog/elastic-and-cmd-join-forces-to-help-you-take-command-of-your-cloud-workloads\">Cmd</a>.\n</p><p>To learn more about what’s new with Elastic Security in 7.15, visit the <a href=\"/blog/whats-new-elastic-security-7-15-0\">Elastic Security 7.15 blog</a>.\n</p><h2>Elastic Cloud</h2><p>Whether customers are looking to quickly find information, gain insights, or protect their technology investments (or all of the above), Elastic Cloud is the best way to experience the Elastic Search Platform. And we continue to improve that experience with new integrations that let customers ingest data into Elastic Cloud even more quickly and securely.\n</p><h3>Ingest data faster with Google Cloud Dataflow</h3><p>With Elastic 7.15, we’re pleased to announce the first-ever native Google Cloud data source integration to Elastic Cloud — Google Cloud Dataflow. This integration enables users to ship Pub/Sub, Big Query, and Cloud Storage&nbsp;data directly into their Elastic Cloud deployments without having to set up an extra intermediary data shipper, utilizing Google Cloud’s native serverless ETL service. The integration simplifies data architectures and helps users ingest data into Elastic Cloud faster.\n</p><h3>Ensure data privacy with the general availability of Google Cloud Private Service Connect</h3><p>We’re also excited to announce that support for Google Private Service Connect is now generally available. Google Private Service Connect provides private connectivity from Google Cloud virtual private clouds (VPCs) to Elastic Cloud deployments. The traffic between Google Cloud and Elastic Cloud deployments on Google Cloud travels only within the Google Cloud network, utilizing Private Service Connect endpoints and ensuring that customer data stays off the (public) internet.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blte6407921f8ae5b16/613fa6b2fbe3b82730060152/7-15-elastic-google-cloud-private-service-connect.jpg\" data-sys-asset-uid=\"blte6407921f8ae5b16\" alt=\"Google Private Service Connect provides easy and private access to Elastic Cloud deployment endpoints while keeping all traffic within the Google network\"><br>\n</p><figcaption>Google Private Service Connect provides easy and private access to Elastic Cloud deployment endpoints while keeping all traffic within the Google network</figcaption><p>To learn more about what’s new with Elastic Cloud, visit the <a href=\"/blog/whats-new-elasticsearch-kibana-cloud-7-15-0\">Elastic Platform 7.15 blog</a>.\n</p><h2>Read more in our latest release blogs</h2><ul>\n\t<li aria-level=\"1\"><a href=\"/blog/whats-new-elastic-enterprise-search-7-15-0\">Elastic Enterprise Search 7.15 released</a></li>\n\t<li aria-level=\"1\"><a href=\"/blog/whats-new-elastic-observability-7-15-0\">Elastic Observability 7.15 released</a></li>\n\t<li aria-level=\"1\"><a href=\"/blog/whats-new-elastic-security-7-15-0\">Elastic Security 7.15 released</a></li>\n\t<li aria-level=\"1\"><a href=\"/blog/whats-new-elasticsearch-kibana-cloud-7-15-0\">Elastic Platform 7.15 released</a></li>\n</ul><h2>Test our mettle</h2><p>Existing Elastic Cloud customers can access many of these features directly from the <a href=\"https://cloud.elastic.co/\">Elastic Cloud console</a>. If you’re new to Elastic Cloud, take a look at our <a href=\"/training/free#quick-starts\">Quick Start guides</a> (bite-sized training videos to get you started quickly) or our <a href=\"/training/free#fundamentals\">free fundamentals training courses</a>. You can always get started for free with a <a href=\"http://cloud.elastic.co/registration?elektra=whats-new-elastic-7-13-blog\">free 14-day trial of Elastic Cloud</a>. Or <a href=\"/downloads/\">download</a> the self-managed version of the Elastic Stack for free.\n</p><p><em>The release and timing of any features or functionality described in this post remain at Elastic's sole discretion. Any features or functionality not currently available may not be delivered on time or at all.</em>\n</p> <em><em></em></em>","PublishedAt":"2021-09-22 16:04:00+00:00","OriginURL":"https://www.elastic.co/blog/whats-new-elastic-7-15-0","SourceName":"Elastic"}},{"node":{"ID":67,"Title":"What's new in Elastic Enterprise Search 7.15: Web crawler GA and personalized Workplace Search","Description":"<p>Elastic Enterprise Search 7.15 introduces general availability for App Search’s web crawler making it quick and effortless to spin up powerful, new search experiences for every use case.\n</p><div class=\"video embed-container shadow m-b-40\" style=\"height: 319.725px;\">\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/z7s4ctMrp4AgVYo9RjY4ox.jpg\" data-uuid=\"z7s4ctMrp4AgVYo9RjY4ox\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-hidden_controls=\"1\" data-muted=\"0\" muted=\"0\" alt=\"\" style=\"width: 100%; margin: auto; display: block;\">\n</div><p>We’re also adding countless ways to personalize Workplace Search to meet the unique needs of your organization with the ability to add custom branding, schedule sync frequency, and configure automatic filter detection.\n</p><p>These updates help teams launch search faster and tailor the search experiences they create:\n</p><ul>\n\t<li>Take the headache out of data ingestion and make your website content instantly searchable with a sophisticated, easy-to-use web crawler</li>\n\t<li>Apply your organization’s branding across all your mission-critical productivity tools</li>\n\t<li>Schedule sync frequency in line with infrastructure demands</li>\n\t<li>Define custom filters specific to your business so your team can search naturally</li>\n\t<li>Create search integrations where your teams spend the most time, and deliver results from any source from Google Drive to Slack, and everything in between.</li>\n</ul>Elastic Enterprise Search 7.15 is <a href=\"https://cloud.elastic.co/registration?elektra=whats-new-elastic-7-15-blog\">available now on Elastic Cloud</a> — the only hosted Elasticsearch offering to include all of the new features in this latest release. You can also <strong><a href=\"https://www.elastic.co/downloads?elektra=whats-new-elastic-7-15-blog\">download the Elastic Stack</a></strong> and our cloud orchestration products, Elastic Cloud Enterprise and Elastic Cloud for Kubernetes, for a self-managed experience.<strong><h2>Set up new search experiences in no time with App Search’s web crawler</h2></strong><p>With 7.15, <a href=\"https://www.elastic.co/enterprise-search\">Elastic Enterprise Search</a> brings general availability to the <a href=\"https://www.elastic.co/web-crawler\">native web crawler</a> in App Search. One common hurdle customers face when setting up website and application search is data indexing. No more! With the web crawler, it’s simple to ingest web content and get new search experiences up and running in no time. And we’ve added features like adding automatic crawling controls and content extraction tools that streamline implementation and free up technical teams. Now you can also analyze crawler logs with Kibana visualizations and Elastic observability tools — so you can use one platform for all of your search data.\n</p><p><img class=\"shadow\" src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt1ce8388dee720102/613cdadbfbe3b8273005fc82/7-15-elastic-co-starting-a-crawl.gif\" data-sys-asset-uid=\"blt1ce8388dee720102\" alt=\"7-15-elastic-co-starting-a-crawl.gif\"><br>\n</p><p>Here’s everything new in the crawler including loads of performance and stability optimizations:\n</p><ul>\n\t<li><strong>Robots.txt support:</strong> Follows the robots exclusion standard, so it knows what pages not to crawl</li>\n\t<li><strong>Sitemap support:</strong> Uses your website’s XML blueprint to efficiently locate and crawl your most important content</li>\n\t<li><strong>Persistent crawling:</strong> Continues web crawling progress even in the instance of a failure or restart</li>\n\t<li><strong>Content extraction utilities:</strong> Lets you identify the exact content you want the web crawler to extract from each page it visits. Also covers:\n\t<ul>\n\t\t<li aria-level=\"2\">Meta tag and data-attribute rules</li>\n\t\t<li aria-level=\"2\">Include/exclude rules in the document body</li>\n\t</ul></li>\n\t<li><strong>Domain validation:</strong> Checks that a domain is valid and can be reached without indexing restrictions to prevent issues with starting a crawl</li>\n\t<li><strong>Deduplication control:</strong> Ensures that only the best version of each page appears in your search engine index</li>\n\t<li><strong>Automatic crawling controls:</strong> Allows you to define how frequently you want to perform automatic crawls</li>\n\t<li><strong>Process crawls:</strong> Allows you to remove documents on-demand from your index according to crawl rules</li>\n\t<li><strong>URL debugging API:</strong> A comprehensive way to troubleshoot problematic URLs, allowing you to understand what the web crawler encounters when it visits a given page</li>\n</ul> <strong><h2>Make your mark on Workplace Search</h2></strong><p>Personalize internal search with your very own branding assets so you can have a consistent look and feel across all of your organization’s essential applications. Make unified search your own and give it instant credibility with the team when you add your organization’s branding without having to build a custom interface. All it takes is a simple .png upload.\n</p><div class=\"video embed-container shadow m-b-40\" style=\"height: 319.725px;\">\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/qZxn6eWxQwmuZDmtMyTV4Y.jpg\" data-uuid=\"qZxn6eWxQwmuZDmtMyTV4Y\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-hidden_controls=\"1\" data-muted=\"0\" muted=\"0\" alt=\"\" style=\"width: 100%; margin: auto; display: block;\">\n</div><p><strong></strong></p><h2><strong>Your timetable, your data, your way with Workplace Search</strong></h2><p>Now you can also schedule Workplace Search sync frequency according to your organization’s needs. When you use Workplace Search’s enhanced sync configurability, you can ensure that computing resources are on par with infrastructure demands. What’s more, you can get real-time results when syncs correspond to your org’s data refresh patterns. No one will miss the team’s latest and greatest content when it’s instantly indexed. Customers on Elastic’s Platinum tier also get added convenience with the ability to schedule syncs by content source and by using the scheduling API.\n</p> <strong><h2>Get instant recognition with configurable automatic filter detection in Workplace Search</h2></strong><p>Natural language queries are at the heart of making search experiences intuitive and effective. But how do you also capture the terms and phrases essential to an organization’s communal intelligence? You need configurable filters, of course. Let your team search naturally and find information faster with filters defined for your organization. Take these examples:\n</p><ul> <strong>\n\t<li><strong>Pull requests </strong>from <strong>last week</strong></li></strong> <strong>\n\t<li><strong>Product team notes </strong>updated by <strong>me</strong></li></strong> <strong>\n\t<li>Monthly <strong>board presentations </strong>in <strong>Google Drive</strong></li></strong>\n</ul><p>Deliver relevant results to everyone on the team when you create custom filters using natural language queries that get automatically recognized. No need for anyone to pick up a complex query language just to find your latest presentation deck.\n</p> <strong><h2>Present common search experiences in Workplace Search</h2></strong><p>Workplace Search offers the convenience of a fully featured desktop and mobile search experience, but also provides all the necessary tools and endpoints for designing and developing bespoke search integrations embedded within high-traffic applications like intranets and workflow applications. Several improvements to the Search API endpoints allow for a more consistent experience across data sources. Slack and Gmail are now available for custom search experience development along with SharePoint Online, Google Drive and more than a dozen more native data integrations. No matter what information is most relevant to your team, you can design an immersive experience without constraints.\n</p> <strong><h2>Try it out</h2></strong><p>Existing Elastic Cloud customers can access many of these features directly from the <a href=\"https://cloud.elastic.co/\">Elastic Cloud console</a>. If you’re new to Elastic Cloud, take a look at our <a href=\"https://www.elastic.co/training/free#quick-starts\">Quick Start guides</a> (bite-sized training videos to get you started quickly, including the <a href=\"https://www.elastic.co/training/app-search-web-crawler-quick-start\">Web crawler Quick Start</a>) or our <a href=\"https://www.elastic.co/training/free#fundamentals\">free fundamentals training courses</a> (including the <a href=\"https://www.elastic.co/training/app-search-web-crawler-fundamentals\">App Search Web Crawler fundamentals course</a>). You can always get started for free with a <a href=\"http://cloud.elastic.co/registration?elektra=whats-new-elastic-7-15-blog\">free 14-day trial of Elastic Enterprise Search</a>. Or <a href=\"https://www.elastic.co/downloads?elektra=whats-new-elastic-7-15-blog\">download</a> the self-managed version of the Elastic Stack for free.\n</p><p>Read about these capabilities and more in the <a href=\"https://www.elastic.co/guide/en/enterprise-search/7.15/release-notes-7.15.0.html\">release notes</a>, and other Elastic Stack highlights in the <a href=\"https://www.elastic.co/blog/whats-new-elastic-7-15-0\">Elastic 7.15 announcement post</a>.\n</p><p><em>The release and timing of any features or functionality described in this post remain at Elastic's sole discretion. Any features or functionality not currently available may not be delivered on time or at all.</em>\n</p>","PublishedAt":"2021-09-22 16:03:00+00:00","OriginURL":"https://www.elastic.co/blog/whats-new-elastic-enterprise-search-7-15-0","SourceName":"Elastic"}},{"node":{"ID":68,"Title":"What’s new in Elasticsearch, Kibana, and Elastic Cloud for 7.15","Description":"<p>Elastic Cloud customers can now ingest data more simply, quickly, and securely, and the latest updates to the core Elastic Stack provide users with new tools for maximizing performance and exploring their data.\n</p><p>The 7.15 release of Elastic Cloud brings new integrations with Google Cloud that allow customers to ingest Google Cloud services data directly into their Elastic Cloud deployments and take advantage of additional network security with Google Cloud Private Service Connect. Plus, the Elastic Stack brings enhancements to Elasticsearch and Kibana including improved data transfer, better resiliency, and more flexible data ingest and analysis.&nbsp;\n</p><p>Ready to roll up your sleeves and get started? We have the links you need:\n</p><ul>\n\t<li aria-level=\"1\">Try out the new features on <a href=\"https://cloud.elastic.co/registration?blade=blog&gambit=7-15-stack-and-cloud-blog\">Elastic Cloud</a>&nbsp;</li>\n\t<li aria-level=\"1\">Download the <a href=\"/downloads?elektra=stack-and-cloud-7-15-blog\">latest versions of Elasticsearch, Kibana, Elastic Cloud Enterprise, Elastic Cloud on Kubernetes</a></li>\n\t<li aria-level=\"1\">Release notes: <a href=\"/guide/en/elasticsearch/reference/7.15/release-notes-7.15.0.html?elektra=stack-and-cloud-7-15-blog\">Elasticsearch</a>, <a href=\"/guide/en/kibana/7.15/release-notes-7.15.0.html?elektra=stack-and-cloud-7-15-blog\">Kibana</a>, <a href=\"/guide/en/cloud/current/ec-release-notes.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud</a>, <a href=\"/guide/en/cloud-enterprise/current/ece-release-notes-2.12.0.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud Enterprise</a>, <a href=\"/guide/en/cloud-on-k8s/1.8/release-notes-1.8.0.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud on Kubernetes</a></li>\n\t<li aria-level=\"1\"><a href=\"/guide/en/elasticsearch/reference/7.15/migrating-7.15.html?elektra=stack-and-cloud-7-15-blog\">Elasticsearch breaking changes</a></li>\n</ul> <strong><h2 id=\"elastic-cloud\">What’s new in Elastic Cloud for 7.15</h2></strong> <strong><p>\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/FdFg5APpxL7jp46QG4yNiy.jpg\" data-uuid=\"FdFg5APpxL7jp46QG4yNiy\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-disable_analytics=\"1\" data-hidden_controls=\"1\" data-muted=\"1\" disable_analytics=\"1\" alt=\"Check out the new Google Cloud Dataflow native integration in Elastic Cloud\" style=\"width: 100%; margin: auto; display: block;\">\n</p><h3>Google Cloud Dataflow native integration</h3></strong><p>Introducing the first ever native Google Cloud data source integration for Elastic Cloud — Google Cloud Dataflow. This integration allows customers to ship Pub/Sub, Big Query, and Cloud Storage data directly into Elastic Cloud deployments without having to set up an extra intermediary data shipper, utilizing Google Cloud’s native serverless extract, transform, load (ETL) service. Customers benefit from simplified data architecture and increased speed when ingesting data into Elastic Cloud. Read our&nbsp;<a href=\"https://www.elastic.co/blog/elastic-and-google-cloud-now-offer-tighter-data-integration\">blog post on these integrations</a>&nbsp;to learn more.</p> <strong><h3>Google Cloud Private Service Connect</h3></strong><p>We’re excited to announce that support for Google Private Service Connect is now generally available. Google Private Service Connect provides private connectivity from Google Cloud virtual private cloud (VPC) to Elastic Cloud deployments. The traffic between Google Cloud and Elastic Cloud deployments on Google Cloud travels only within the Google Cloud network, utilizing Private Service Connect endpoints and ensuring that customer data stays off the Internet. Read the <a href=\"/blog/secure-your-deployments-on-elastic-cloud-with-google-cloud-private-service-connect\">blog post</a> to learn more.\n</p> <strong><h3>ARM-based (Graviton2) instances on AWS&nbsp;</h3></strong><p>Soon, customers will be able to leverage Amazon Web Services (AWS) ARM-based Graviton2 virtual machines (VMs) for Elastic Cloud deployments running on AWS. VMs running on Graviton2 hardware provide up to 40% better price performance compared to previous generation x86-based instances. Check out the&nbsp;<a href=\"https://www.elastic.co/blog/new-aws-instance-types-on-elastic-cloud\">blog post</a>&nbsp;to learn more.</p> <strong><h2 id=\"elasticsearch\">What’s new in Elasticsearch 7.15</h2></strong> <strong><h3>Improved data resiliency and reduced data transfer traffic</h3></strong><p>Since the inception of Elasticsearch, we’ve been on a mission to be the best and fastest search engine around. To further this mission, we’ve <a href=\"/elasticsearch/elasticsearch-searchable-snapshots\">lowered the costs</a> of storing and searching data, <a href=\"/blog/a-new-era-for-cluster-coordination-in-elasticsearch\">improved cluster resiliency</a> and <a href=\"/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time\">search performance</a>, <a href=\"/blog/elasticsearch-7-7-0-released\">lowered memory heap usage</a>, <a href=\"/blog/save-space-and-money-with-improved-storage-efficiency-in-elasticsearch-7-10\">improved storage efficiency</a>, and introduced <a href=\"/blog/whats-new-elasticsearch-7-14-0\">faster aggregations</a> in <a href=\"/blog/how-we-made-date-histogram-aggregations-faster-than-ever-in-elasticsearch-7-11\">multiple</a> Elasticsearch <a href=\"/blog/new-in-elasticsearch-7-13-even-faster-aggregations\">releases</a>. In this release, we not only improve data resiliency but also reduce data transfer traffic — a change designed specifically to lower our customers’ Elastic Cloud bills.&nbsp;\n</p><p>\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/Uspe6FkqGYdYJqhiRC6EVv.jpg\" data-uuid=\"Uspe6FkqGYdYJqhiRC6EVv\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-disable_analytics=\"1\" data-hidden_controls=\"1\" data-muted=\"1\" disable_analytics=\"1\" alt=\"Improved data resiliency and reduced data transfer traffic with Elasticsearch\" style=\"width: 100%; margin: auto; display: block;\">\n</p><p>By <a href=\"https://github.com/elastic/elasticsearch/issues/73497\">compressing specific inter-node traffic</a> and using snapshot storage to shortcut relocating <a href=\"https://github.com/elastic/elasticsearch/issues/73496\">shards between nodes</a>, we have reduced the amount of network traffic that traverses across the cluster, resulting in a reduction in Data Transfer and Storage (DTS) cost. This change will be most prominent for Elastic Cloud customers with heavy indexing or data migration between tiers.&nbsp;\n</p> <strong><h3>New APIs to help optimize and improve Elasticsearch performance</h3></strong><p>The best decisions are always data driven. Three new experimental APIs in 7.15 give you the tools to help analyze how you are using Elasticsearch usage and ultimately drive improved performance.&nbsp;\n</p><p>The <a href=\"/guide/en/elasticsearch/reference/7.15/field-usage-stats.html\">field usage API</a> helps you decide how to index a <a href=\"/guide/en/elasticsearch/reference/7.15/mapping-types.html\">field</a> based on usage statistics. For example, if a field is used frequently, it should be created with schema on write or at ingest time by using a <a href=\"/guide/en/elasticsearch/reference/7.15/explicit-mapping.html\">mapping</a>. If the field is used infrequently, consider defining it at query time with <a href=\"/guide/en/elasticsearch/reference/7.15/runtime.html\">runtime fields</a>. Changing a text field with an <code>inverted_index.term_frequencies</code> of zero and low <code>inverted_index.positions</code> to <a href=\"/guide/en/elasticsearch/reference/7.15/text.html#match-only-text-field-type\"><code>match_only_text</code></a> (added in <a href=\"/blog/whats-new-elasticsearch-7-14-0\">7.14</a>) can <a href=\"/blog/save-10-percent-disk-space-on-your-logging-datasets-with-match-only-text\">save around 10% of disk</a>.\n</p><p>With the <a href=\"/guide/en/elasticsearch/reference/7.15/indices-disk-usage.html\">index disk usage API</a> you can see how much disk space is consumed by every field in your index. Knowing what fields take up disk, you can decide which indexing option or field type is best. For example, <a href=\"/guide/en/elasticsearch/reference/7.15/keyword.html\"><code>keyword</code></a> or <a href=\"/guide/en/elasticsearch/reference/7.15/text.html#match-only-text-field-type\"><code>match_only_text </code></a> may be better than <a href=\"/guide/en/elasticsearch/reference/7.15/text.html\"><code>text</code></a> for certain fields where scoring and positional information is not important. Or, use runtime fields to create a <code>keyword</code> at query time for flexibility and saving space.\n</p><p>Finally, the <a href=\"/guide/en/elasticsearch/reference/7.15/search-vector-tile-api.html\">vector tiles API</a> provides a huge performance and scalability improvement when searching geo_points and geo_shapes drawn to a map (through use of <a href=\"https://en.wikipedia.org/wiki/Vector_tiles\">vector tiles</a>). Offloading these calculations to the local GPU significantly improves performance while also lowering costs by reducing network traffic both within the cluster and to the client.&nbsp;\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt9e30423c748276df/614a8b52f725af79f53fd555/losangeles.gif\" data-sys-asset-uid=\"blt9e30423c748276df\" alt=\"losangeles.gif\" style=\"display: block; margin: auto;\">\n</p> <strong><h3>Composite runtime fields</h3></strong><p>Elastic 7.15 continues to evolve the implementation of <a href=\"https://www.elastic.co/elasticsearch/elasticsearch-runtime-fields?elektra=stack-and-cloud-7-15-blog\">runtime fields</a> in Elasticsearch and Kibana.&nbsp;\n</p><p>In Elasticsearch, composite runtime fields enable users to streamline field creation using one Painless script to emit multiple fields, with added efficiencies for field management. Use patterns like <a href=\"/guide/en/elasticsearch/reference/7.15/runtime-examples.html#runtime-examples-grok\">grok</a> or <a href=\"/guide/en/elasticsearch/reference/7.15/runtime-examples.html#runtime-examples-dissect\">dissect</a> to emit multiple fields using one script instead of creating and maintaining multiple scripts. Using existing grok patterns also makes it faster to create new runtime fields and reduces the time and complexity of creating and maintaining regex expressions. This development makes it easier and more intuitive for users to ingest new data like custom logs. See more on runtime fields in Kibana 7.15 below.\n</p> <strong><h2 id=\"kibana\">What’s new in Kibana 7.15</h2></strong> <strong><h3>Runtime fields editor preview pane</h3></strong><p>Combined with the introduction of composite fields for Elasticsearch (above), a new preview pane in the runtime fields editor in Kibana 7.15 makes it even easier to create fields on the fly. The preview pane empowers users to test and preview new fields before creating them — for example, by evaluating a new script against documents to check accuracy in Index Patterns, Discover, or Lens. In addition, pinning specific fields in the preview pane simplifies script creation. This enhancement also includes better error handling for the editor, all to help streamline the field creation process and allow users to create runtime fields more quickly. More developments for runtime fields are on the horizon as we continue to make previously ingested data easier to parse from Kibana.\n</p><div class=\"video embed-container\" style=\"height: 319.725px;\">\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/2t7rLk7ZRn1QJhmVcYxsBp.jpg\" data-uuid=\"2t7rLk7ZRn1QJhmVcYxsBp\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-disable_analytics=\"1\" data-hidden_controls=\"1\" data-muted=\"1\" disable_analytics=\"1\" alt=\"Use the Kibana runtime fields editor preview pane to evaluate sample documents before creating a new field.\" style=\"width: 100%; margin: auto; display: block;\">\n</div><h2 id=\"stack-and-cloud-features\">Other updates across the Elastic Stack and Elastic Cloud</h2><h4>Elastic Cloud\n</h4><ul>\n\t<li aria-level=\"1\"><strong>Leverage more cost-effective hardware options on GCP:</strong> Google Compute Engine’s (GCE) N2 VMs for Elastic Cloud deployments running on Google Cloud offer up to 20% better CPU performance compared to the previous generation N1 machine types. Learn more in the <a href=\"/blog/introducing-new-google-cloud-instance-types-on-elastic-cloud\">blog post</a>.</li>\n</ul><h4>Elasticsearch\n</h4><ul>\n\t<li aria-level=\"1\"><strong>Build complex flows with API keys:</strong> Search and pagination for API keys allow you to build complex management flows for keys, based on your own metadata.</li>\n</ul><h4>Kibana\n</h4><ul>\n\t<li aria-level=\"1\"><strong>Sync across time and (dashboard) space with your cursor:</strong> A new hover feature in Kibana charts that highlights corresponding data across multiple charts makes it easier for users to home in on specific time periods to observe and explore trends. In addition to time series, this will also highlight the same non-time data on multiple dashboard panels.</li>\n\t<li aria-level=\"1\"><strong>Customize charts with legend-ary updates:</strong> Legends inside charts (great for busy dashboards) and multi-line series names in legends make it easier for teams to follow the data story on a dashboard.</li>\n\t<li aria-level=\"1\"><strong>Get a head start on Maps exploration:</strong> Metadata for points and shapes is now auto-generated in Elastic Maps when a user creates an index and explores with edit tools. The user and timestamp data is saved for further exploration and management. Also, a new layer action allows users to view only the specific layer they are interested in.</li>\n\t<li aria-level=\"1\">Learn more in the <a href=\"/guide/en/kibana/7.15/whats-new.html?elektra=stack-and-cloud-7-15-blog\">Kibana docs</a>.</li>\n</ul><h4>Machine learning</h4><ul>\n\t<li aria-level=\"1\"><strong>Monitor machine learning jobs easily:</strong> Operational alerts for machine learning jobs simplify the process of managing machine learning jobs and models, and alerts in Kibana make it easier to track and follow up on errors.&nbsp;</li>\n\t<li aria-level=\"1\"><strong>Adjust and reset models without the fuss:</strong> The reset jobs API makes working with models much easier across Kibana, from the Logs app to Elastic Security.</li>\n\t<li aria-level=\"1\"><strong>Reuse and scale machine learning jobs:</strong> Jobs can now be imported and exported, allowing users to reuse jobs created in lab environments or in multiple-cluster environments. Sharing jobs across deployments makes jobs more consistent and easier to scale.</li>\n\t<li aria-level=\"1\"><strong>Investigate transaction latency:</strong> Elastic APM correlations, powered by machine learning, streamline root cause analysis. The Elasticsearch significant terms aggregation was enhanced with a p_value scoring heuristic, and Kibana’s new transaction investigation page for APM aids analysts in a holistic exploration of transaction data. To learn more, read the <a href=\"/blog/whats-new-elastic-observability-7-15-0\">Observability 7.15 blog</a>.</li>\n\t<li aria-level=\"1\">Learn more in the <a href=\"/guide/en/kibana/7.15/whats-new.html?elektra=stack-and-cloud-7-15-blog\">Kibana</a> and <a href=\"/guide/en/elasticsearch/reference/7.15/release-highlights.html?elektra=stack-and-cloud-7-15-blog\">Elasticsearch</a> docs.</li>\n</ul><h4>Integrations\n</h4><ul>\n\t<li aria-level=\"1\"><strong>Run Elastic Package Registry (EPR) as a Docker image:</strong> now you can run your own EPR to provide information on external data sources to air-gapped environments. By using the EPR Docker image, you can integrate, collect and visualize data using Elastic Agents. For more information, <a href=\"/guide/en/integrations-developer/current/air-gapped.html?elektra=stack-and-cloud-7-15-blog\">please refer to this Elastic guide.</a></li>\n</ul> <strong><h2>Try it out</h2></strong><p>Existing Elastic Cloud customers can access many of these features directly from the <a href=\"https://cloud.elastic.co/registration?blade=blog&gambit=stack-and-cloud-7-15-blog\">Elastic Cloud console</a>. If you’re new to Elastic Cloud, take a look at our <a href=\"/training/free#quick-starts?elektra=stack-and-cloud-7-15-blog\">Quick Start guides</a> (bite-sized training videos to get you started quickly) or our <a href=\"https://www.elastic.co/training/free#fundamentals?elektra=stack-and-cloud-7-15-blog\">free fundamentals training courses</a>. You can always get started for free with a <a href=\"http://cloud.elastic.co/registration?blade=blog&gambit=stack-and-cloud-7-15-blog\">free 14-day trial of Elastic Cloud</a>. Or <a href=\"/downloads?elektra=stack-and-cloud-7-15-blog\">download</a> the self-managed version of the Elastic Stack for free.\n</p><p>Read about these capabilities and more in the 7.15 release notes (<a href=\"/guide/en/elasticsearch/reference/7.15/release-notes-7.15.0.html?elektra=stack-and-cloud-7-15-blog\">Elasticsearch</a>, <a href=\"/guide/en/kibana/7.15/release-notes-7.15.0.html?elektra=stack-and-cloud-7-15-blog\">Kibana</a>, <a href=\"/guide/en/cloud/current/ec-release-notes.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud</a>, <a href=\"/guide/en/cloud-enterprise/current/ece-release-notes-2.12.0.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud Enterprise</a>, <a href=\"/guide/en/cloud-on-k8s/1.8/release-notes-1.8.0.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud on Kubernetes</a>), and other Elastic 7.15 highlights in the <a href=\"/blog/whats-new-elastic-7-15-0\">Elastic 7.15 announcement post</a>.\n</p><p><i>The release and timing of any features or functionality described in this post remain at Elastic's sole discretion. Any features or functionality not currently available may not be delivered on time or at all.\n\t</i>\n</p>","PublishedAt":"2021-09-22 16:02:00+00:00","OriginURL":"https://www.elastic.co/blog/whats-new-elasticsearch-kibana-cloud-7-15-0","SourceName":"Elastic"}},{"node":{"ID":69,"Title":"Elastic Observability 7.15: Automated correlations, frictionless log ingestion from Google Cloud","Description":"<p>Elastic Observability 7.15 introduces the general availability of automated correlations, unified views across application service logs and dependencies, and agentless log ingestion from Google Cloud Platform (GCP), accelerating troubleshooting of root causes of application issues and making it even easier to ingest telemetry from cloud services.&nbsp;\n</p><p>These new features allow customers to:\n</p><ul>\n\t<li>Automatically surface attributes of the APM data set that are correlated with high-latency or erroneous transactions</li>\n\t<li>Effortlessly troubleshoot application issues by viewing all associated application or service logs from within the APM user interface&nbsp;</li>\n\t<li>Seamlessly ingest log data into Elastic from within the Google Cloud console and extend monitoring to native Google Cloud services</li>\n</ul><p>Elastic Observability 7.15 is <a href=\"https://cloud.elastic.co/registration?elektra=whats-new-elastic-7-13-blog\" target=\"_blank\">available now on Elastic Cloud</a> — the only hosted Elasticsearch offering to include all of the new features in this latest release. You can also <a href=\"https://www.elastic.co/downloads/\" target=\"_blank\">download the Elastic Stack</a> and our cloud orchestration products, Elastic Cloud Enterprise and Elastic Cloud for Kubernetes, for a self-managed experience.\n</p><h2>Automated root cause analysis with APM correlations is now GA\n</h2><p>DevOps and SRE teams are constantly challenged with an overwhelming amount of data and dependencies to sift through to keep modern applications performant and error-free. As such, automation and machine learning have become essential components of the troubleshooter’s toolkit. <a href=\"https://www.elastic.co/guide/en/kibana/7.15/correlations.html\" target=\"_blank\">Elastic APM correlations</a> accelerate root cause analysis by automatically surfacing attributes of the APM data set (such as infrastructure components, versions, locations, and custom metadata) that are correlated with high-latency or erroneous transactions and have the most significant impact on overall service performance. Visualize the latency distribution of any attribute compared to overall latency and use these attributes to filter and isolate the root causes of performance problems.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt27dff0e7a27e4f81/61423a368440e97ef5826acf/animation-apm-latency-correlations.gif\" data-sys-asset-uid=\"blt27dff0e7a27e4f81\" alt=\"animation-apm-latency-correlations.gif\">\n</p><h2>Unified observability for APM troubleshooting across logs, third-party dependencies, and backend services\n</h2><p>Elastic is the only observability solution built on a search platform that natively ingests high dimensionality and cardinality telemetry data of any type or source, adds context, and correlates it for fast, relevant analysis. Over the last twelve months we have reworked almost the entire user experience within the APM user interface&nbsp;and&nbsp;will continue to deliver visualization and workflow improvements for unified visibility and analysis across the entire application ecosystem.&nbsp;\n</p><p>Two new troubleshooting views have been added in 7.15.&nbsp;Logs are now&nbsp;available on any level, at the top level for the service, as well as at&nbsp;the level of&nbsp;specific transactions&nbsp;and&nbsp;container or pod instances. We're now also able to&nbsp;show external dependencies, such as&nbsp;backends, caches, and databases, including how they are&nbsp;performing, their upstream dependencies, and how they have&nbsp;changed over time.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltf180dffa4d9ce8db/61423a4c564bf37c154f77c9/screenshot-apm-service-logs.png\" data-sys-asset-uid=\"bltf180dffa4d9ce8db\" alt=\"screenshot-apm-service-logs.png\" \"=\"\">\n</p><figcaption>Get an integrated roll-up view of application logs across application services running on ephemeral infrastructure to quickly find errors and other causes of application issues.</figcaption><p><em><br></em>\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltec7d31bd64c02a0d/61423a679d27cf7da4ba02a9/screenshot-dependencies-redis.png\" data-sys-asset-uid=\"bltec7d31bd64c02a0d\" alt=\"screenshot-dependencies-redis.png\"><br>\n</p><figcaption>Identify issues with third-party and backend service dependencies, and leverage detailed drilldowns for comparing historical performance and impact on&nbsp;upstream services.</figcaption><p><span style=\"background-color: initial;\"></span><span style=\"background-color: initial;\">We’ve also enhanced the existing transaction latency distribution chart and trace selection with more granular buckets and the flexibility to drag-select all application traces that fall within a desired range of latencies.</span>\n</p><h2>Agentless ingestion of logs from Google Cloud Platform (GCP) for frictionless observability&nbsp;&nbsp;\n</h2><p>Elastic’s new GCP Dataflow integration drives efficiency with frictionless ingestion of log data directly from the Google Cloud console. The agentless approach provides an “easy button” option for customers who want to avoid the cost and hassle of managing and maintaining agents, and further extends monitoring to native GCP services.&nbsp;\n</p><p style=\"text-align: center;\"><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltb459bb911fdbaf61/6148be340332d478b9d30bd0/blog-gcp-integration-pubsub-1.png\" data-sys-asset-uid=\"bltb459bb911fdbaf61\" alt=\"blog-gcp-integration-pubsub-1.png\" \"=\"\"><br>\n\n</p><figcaption>The Google and Elastic teams worked together to develop an out-of-the-box Dataflow template that a user can select to push logs and events from Pub/Sub to Elastic.</figcaption><h2>Additional data sources: JVM metrics support for JRuby, Azure Spring Cloud logs integration, and Osquery metrics in host details panel</h2><p>With the 7.15 release, we have&nbsp;also enhanced our application and cloud data collection for JRuby and Azure. Now you can get visibility into system and JVM metrics for JRuby applications and continuously monitor and quickly debug issues encountered in Spring boot applications running on Azure (beta).&nbsp;\n</p><p>Osquery provides a flexible and powerful way to collect any data from a target host it's installed on.&nbsp;The Osquery integration&nbsp;with the&nbsp;Elastic Agent,&nbsp;introduced in 7.13,&nbsp;opened&nbsp;up a spectrum of capabilities to support troubleshooting of security and observability use cases. Previously,&nbsp;Osquery could&nbsp;be used via Kibana to perform live and scheduled queries, with the query results stored in a dedicated data stream. With 7.15, Osquery is now directly integrated into the enhanced host details panel and delivers&nbsp;ad hoc querying capabilities on the target host.\n</p><h2>Self-managed version of Elastic Package Registry (EPR) now available for air-gapped deployments</h2><p>If you host your Elastic Stack in an air-gapped environment and want to take advantage of the recently GA <a href=\"https://www.elastic.co/blog/elastic-agent-and-fleet-make-it-easier-to-integrate-your-systems-with-elastic\" target=\"_blank\">Elastic Agent and Fleet</a>, we have good news for you. Elastic Package Registry (EPR) is now available as a Docker image that can be run and hosted in any infrastructure setting of your choice.&nbsp;In environments where&nbsp;network traffic restrictions are mandatory&nbsp;deploying your own instance of EPR enables&nbsp;Kibana to download package metadata and content in order to&nbsp;access&nbsp;all available integrations and deliver the relevant out-of-box components and documentation. Currently, the EPR Docker image is a beta&nbsp;standalone server that will continue to grow and evolve. For more information, check out the Elastic guide for <a href=\"https://www.elastic.co/guide/en/integrations-developer/current/air-gapped.html\" target=\"_blank\">running EPR in air-gapped environments</a>.&nbsp;\n</p><h2>Try it out\n</h2><p>Existing Elastic Cloud customers can access many of these features directly from the <a href=\"https://cloud.elastic.co/\" target=\"_blank\">Elastic Cloud console</a>, or, if you'd prefer, you can <a href=\"https://www.elastic.co/downloads/\" target=\"_blank\">download</a> the latest version.\n</p><p>If you’re new to Elastic Cloud, take a look at our <a href=\"https://www.elastic.co/training/free#quick-starts\" target=\"_blank\">Quick Start guides</a> (bite-sized training videos to get you started quickly) or <a href=\"https://www.elastic.co/training/free#fundamentals\" target=\"_blank\">our free fundamentals training courses</a>. You can always get started for free with a <a href=\"http://cloud.elastic.co/registration?blade=blog&gambit=whats-new-enterprise-search-7-12\" target=\"_blank\">free 14-day trial of Elastic Cloud</a>.&nbsp;\n</p><p>Read about these capabilities and more in the <a href=\"https://www.elastic.co/guide/en/observability/7.15/whats-new.html\" target=\"_blank\">Elastic Observability 7.15 release notes</a>, and other Elastic Stack highlights in the <a href=\"https://www.elastic.co/blog/whats-new-elastic-7-15-0\" target=\"_blank\">Elastic 7.15 announcement post</a>.\n</p><p><em>The release and timing of any features or functionality described in this post remain at Elastic's sole discretion. Any features or functionality not currently available may not be delivered on time or at all.&nbsp;</em>\n</p>","PublishedAt":"2021-09-22 16:01:00+00:00","OriginURL":"https://www.elastic.co/blog/whats-new-elastic-observability-7-15-0","SourceName":"Elastic"}},{"node":{"ID":785,"Title":"Service Architecture at SoundCloud — Part 3: Domain Gateways","Description":"This article is the last part in a series of posts aiming to cast some light onto how service architecture has evolved at SoundCloud over…","PublishedAt":"2021-09-17 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/service-architecture-3","SourceName":"Soundcloud"}},{"node":{"ID":770,"Title":"YAML Generator for Funnel YAML Files: Streamlining the Mobile Data Workflow Process","Description":"<p><span style=\"font-weight: 400;\">At Uber, real-time mobile analytics events—generated by button taps, page views, and more—form the backbone of the mobile data workflow process.</span></p>\n<p><span style=\"font-weight: 400;\">To process these events, our Mobile Data Platform Team designed and developed the Fontana library, which converts the nearly-one-million-QPS </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/streamlining-mobile-data-workflow-process/\">YAML Generator for Funnel YAML Files: Streamlining the Mobile Data Workflow Process</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-09-16 16:00:32+00:00","OriginURL":"https://eng.uber.com/streamlining-mobile-data-workflow-process/","SourceName":"Uber"}},{"node":{"ID":129,"Title":"Solving Cumulative Layout Shifts At Scale","Description":"","PublishedAt":"2021-09-16 10:50:08+00:00","OriginURL":"https://medium.com/engineering-housing/solving-cumulative-layout-shifts-at-scale-e91f0d3b3be4?source=rss----3a69e32e2594---4","SourceName":"Housing.com"}},{"node":{"ID":1271,"Title":"Paying technical debt in the front-end","Description":"","PublishedAt":"2021-09-16 08:30:14+00:00","OriginURL":"https://medium.com/miro-engineering/paying-technical-debt-in-the-front-end-8666ef0c32d1?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":475,"Title":"Product analytics for health tech","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/09/MetricsThatMatter_Design@2x-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>Health tech represents a new way to address everything from personal mental health to the inefficiencies of the healthcare system.&#160; But, without the right level of insight, health tech companies may be overcome by the challenges of growing a niche solution—namely, retaining an engaged user base for a delicate use case.&#160; Our guiding question: How</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/metrics-that-matter-product-analytics-for-the-up-and-coming-health-tech-sector/\">Product analytics for health tech</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-09-14 18:22:00+00:00","OriginURL":"https://mixpanel.com/blog/metrics-that-matter-product-analytics-for-the-up-and-coming-health-tech-sector/","SourceName":"Mixpanel"}},{"node":{"ID":1255,"Title":"Blog: Introducing Single Pod Access Mode for PersistentVolumes","Description":"<p><strong>Author:</strong> Chris Henzie (Google)</p>\n<p>Last month's release of Kubernetes v1.22 introduced a new ReadWriteOncePod access mode for <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistent-volumes\">PersistentVolumes</a> and <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims\">PersistentVolumeClaims</a>.\nWith this alpha feature, Kubernetes allows you to restrict volume access to a single pod in the cluster.</p>\n<h2 id=\"what-are-access-modes-and-why-are-they-important\">What are access modes and why are they important?</h2>\n<p>When using storage, there are different ways to model how that storage is consumed.</p>\n<p>For example, a storage system like a network file share can have many users all reading and writing data simultaneously.\nIn other cases maybe everyone is allowed to read data but not write it.\nFor highly sensitive data, maybe only one user is allowed to read and write data but nobody else.</p>\n<p>In the world of Kubernetes, <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes\">access modes</a> are the way you can define how durable storage is consumed.\nThese access modes are a part of the spec for PersistentVolumes (PVs) and PersistentVolumeClaims (PVCs).</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>shared-cache<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteMany<span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># Allow many nodes to access shared-cache simultaneously.</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>1Gi<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Before v1.22, Kubernetes offered three access modes for PVs and PVCs:</p>\n<ul>\n<li>ReadWriteOnce – the volume can be mounted as read-write by a single node</li>\n<li>ReadOnlyMany – the volume can be mounted read-only by many nodes</li>\n<li>ReadWriteMany – the volume can be mounted as read-write by many nodes</li>\n</ul>\n<p>These access modes are enforced by Kubernetes components like the <code>kube-controller-manager</code> and <code>kubelet</code> to ensure only certain pods are allowed to access a given PersistentVolume.</p>\n<h2 id=\"what-is-this-new-access-mode-and-how-does-it-work\">What is this new access mode and how does it work?</h2>\n<p>Kubernetes v1.22 introduced a fourth access mode for PVs and PVCs, that you can use for CSI volumes:</p>\n<ul>\n<li>ReadWriteOncePod – the volume can be mounted as read-write by a single pod</li>\n</ul>\n<p>If you create a pod with a PVC that uses the ReadWriteOncePod access mode, Kubernetes ensures that pod is the only pod across your whole cluster that can read that PVC or write to it.</p>\n<p>If you create another pod that references the same PVC with this access mode, the pod will fail to start because the PVC is already in use by another pod.\nFor example:</p>\n<pre tabindex=\"0\"><code>Events:\nType Reason Age From Message\n---- ------ ---- ---- -------\nWarning FailedScheduling 1s default-scheduler 0/1 nodes are available: 1 node has pod using PersistentVolumeClaim with the same name and ReadWriteOncePod access mode.\n</code></pre><h3 id=\"how-is-this-different-than-the-readwriteonce-access-mode\">How is this different than the ReadWriteOnce access mode?</h3>\n<p>The ReadWriteOnce access mode restricts volume access to a single <em>node</em>, which means it is possible for multiple pods on the same node to read from and write to the same volume.\nThis could potentially be a major problem for some applications, especially if they require at most one writer for data safety guarantees.</p>\n<p>With ReadWriteOncePod these issues go away.\nSet the access mode on your PVC, and Kubernetes guarantees that only a single pod has access.</p>\n<h2 id=\"how-do-i-use-it\">How do I use it?</h2>\n<p>The ReadWriteOncePod access mode is in alpha for Kubernetes v1.22 and is only supported for CSI volumes.\nAs a first step you need to enable the ReadWriteOncePod <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates\">feature gate</a> for <code>kube-apiserver</code>, <code>kube-scheduler</code>, and <code>kubelet</code>.\nYou can enable the feature by setting command line arguments:</p>\n<pre tabindex=\"0\"><code>--feature-gates=&#34;...,ReadWriteOncePod=true&#34;\n</code></pre><p>You also need to update the following CSI sidecars to these versions or greater:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes-csi/external-provisioner/releases/tag/v3.0.0\">csi-provisioner:v3.0.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-attacher/releases/tag/v3.3.0\">csi-attacher:v3.3.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-resizer/releases/tag/v1.3.0\">csi-resizer:v1.3.0+</a></li>\n</ul>\n<h3 id=\"creating-a-persistentvolumeclaim\">Creating a PersistentVolumeClaim</h3>\n<p>In order to use the ReadWriteOncePod access mode for your PVs and PVCs, you will need to create a new PVC with the access mode:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>single-writer-only<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOncePod<span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># Allow only a single pod to access single-writer-only.</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>1Gi<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>If your storage plugin supports <a href=\"https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/\">dynamic provisioning</a>, new PersistentVolumes will be created with the ReadWriteOncePod access mode applied.</p>\n<h4 id=\"migrating-existing-persistentvolumes\">Migrating existing PersistentVolumes</h4>\n<p>If you have existing PersistentVolumes, they can be migrated to use ReadWriteOncePod.</p>\n<p>In this example, we already have a &quot;cat-pictures-pvc&quot; PersistentVolumeClaim that is bound to a &quot;cat-pictures-pv&quot; PersistentVolume, and a &quot;cat-pictures-writer&quot; Deployment that uses this PersistentVolumeClaim.</p>\n<p>As a first step, you need to edit your PersistentVolume's <code>spec.persistentVolumeReclaimPolicy</code> and set it to <code>Retain</code>.\nThis ensures your PersistentVolume will not be deleted when we delete the corresponding PersistentVolumeClaim:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl patch pv cat-pictures-pv -p <span style=\"color:#b44\">&#39;{&#34;spec&#34;:{&#34;persistentVolumeReclaimPolicy&#34;:&#34;Retain&#34;}}&#39;</span>\n</span></span></code></pre></div><p>Next you need to stop any workloads that are using the PersistentVolumeClaim bound to the PersistentVolume you want to migrate, and then delete the PersistentVolumeClaim.</p>\n<p>Once that is done, you need to clear your PersistentVolume's <code>spec.claimRef.uid</code> to ensure PersistentVolumeClaims can bind to it upon recreation:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl scale --replicas<span style=\"color:#666\">=</span><span style=\"color:#666\">0</span> deployment cat-pictures-writer\n</span></span><span style=\"display:flex;\"><span>kubectl delete pvc cat-pictures-pvc\n</span></span><span style=\"display:flex;\"><span>kubectl patch pv cat-pictures-pv -p <span style=\"color:#b44\">&#39;{&#34;spec&#34;:{&#34;claimRef&#34;:{&#34;uid&#34;:&#34;&#34;}}}&#39;</span>\n</span></span></code></pre></div><p>After that you need to replace the PersistentVolume's access modes with ReadWriteOncePod:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl patch pv cat-pictures-pv -p <span style=\"color:#b44\">&#39;{&#34;spec&#34;:{&#34;accessModes&#34;:[&#34;ReadWriteOncePod&#34;]}}&#39;</span>\n</span></span></code></pre></div><div class=\"alert alert-info note callout\" role=\"alert\">\n<strong>Note:</strong> The ReadWriteOncePod access mode cannot be combined with other access modes.\nMake sure ReadWriteOncePod is the only access mode on the PersistentVolume when updating, otherwise the request will fail.\n</div>\n<p>Next you need to modify your PersistentVolumeClaim to set ReadWriteOncePod as the only access mode.\nYou should also set your PersistentVolumeClaim's <code>spec.volumeName</code> to the name of your PersistentVolume.</p>\n<p>Once this is done, you can recreate your PersistentVolumeClaim and start up your workloads:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># IMPORTANT: Make sure to edit your PVC in cat-pictures-pvc.yaml before applying. You need to:</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># - Set ReadWriteOncePod as the only access mode</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># - Set spec.volumeName to &#34;cat-pictures-pv&#34;</span>\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span>kubectl apply -f cat-pictures-pvc.yaml\n</span></span><span style=\"display:flex;\"><span>kubectl apply -f cat-pictures-writer-deployment.yaml\n</span></span></code></pre></div><p>Lastly you may edit your PersistentVolume's <code>spec.persistentVolumeReclaimPolicy</code> and set to it back to <code>Delete</code> if you previously changed it.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl patch pv cat-pictures-pv -p <span style=\"color:#b44\">&#39;{&#34;spec&#34;:{&#34;persistentVolumeReclaimPolicy&#34;:&#34;Delete&#34;}}&#39;</span>\n</span></span></code></pre></div><p>You can read <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/\">Configure a Pod to Use a PersistentVolume for Storage</a> for more details on working with PersistentVolumes and PersistentVolumeClaims.</p>\n<h2 id=\"what-volume-plugins-support-this\">What volume plugins support this?</h2>\n<p>The only volume plugins that support this are CSI drivers.\nSIG Storage does not plan to support this for in-tree plugins because they are being deprecated as part of <a href=\"https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-csi-migration-beta/#what-is-the-timeline-status\">CSI migration</a>.\nSupport may be considered for beta for users that prefer to use the legacy in-tree volume APIs with CSI migration enabled.</p>\n<h2 id=\"as-a-storage-vendor-how-do-i-add-support-for-this-access-mode-to-my-csi-driver\">As a storage vendor, how do I add support for this access mode to my CSI driver?</h2>\n<p>The ReadWriteOncePod access mode will work out of the box without any required updates to CSI drivers, but <a href=\"#update-your-csi-sidecars\">does require updates to CSI sidecars</a>.\nWith that being said, if you would like to stay up to date with the latest changes to the CSI specification (v1.5.0+), read on.</p>\n<p>Two new access modes were introduced to the CSI specification in order to disambiguate the legacy <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/csi.proto#L418-L420\"><code>SINGLE_NODE_WRITER</code></a> access mode.\nThey are <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/csi.proto#L437-L447\"><code>SINGLE_NODE_SINGLE_WRITER</code> and <code>SINGLE_NODE_MULTI_WRITER</code></a>.\nIn order to communicate to sidecars (like the <a href=\"https://github.com/kubernetes-csi/external-provisioner\">external-provisioner</a>) that your driver understands and accepts these two new CSI access modes, your driver will also need to advertise the <code>SINGLE_NODE_MULTI_WRITER</code> capability for the <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/csi.proto#L1073-L1081\">controller service</a> and <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/csi.proto#L1515-L1524\">node service</a>.</p>\n<p>If you'd like to read up on the motivation for these access modes and capability bits, you can also read the <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/2485-read-write-once-pod-pv-access-mode/README.md#csi-specification-changes-volume-capabilities\">CSI Specification Changes, Volume Capabilities</a> section of KEP-2485 (ReadWriteOncePod PersistentVolume Access Mode).</p>\n<h3 id=\"update-your-csi-driver-to-use-the-new-interface\">Update your CSI driver to use the new interface</h3>\n<p>As a first step you will need to update your driver's <code>container-storage-interface</code> dependency to v1.5.0+, which contains support for these new access modes and capabilities.</p>\n<h3 id=\"accept-new-csi-access-modes\">Accept new CSI access modes</h3>\n<p>If your CSI driver contains logic for validating CSI access modes for requests , it may need updating.\nIf it currently accepts <code>SINGLE_NODE_WRITER</code>, it should be updated to also accept <code>SINGLE_NODE_SINGLE_WRITER</code> and <code>SINGLE_NODE_MULTI_WRITER</code>.</p>\n<p>Using the <a href=\"https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver/blob/v1.2.2/pkg/gce-pd-csi-driver/utils.go#L116-L130\">GCP PD CSI driver validation logic</a> as an example, here is how it can be extended:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-diff\" data-lang=\"diff\"><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">diff --git a/pkg/gce-pd-csi-driver/utils.go b/pkg/gce-pd-csi-driver/utils.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">index 281242c..b6c5229 100644\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\"></span><span style=\"color:#a00000\">--- a/pkg/gce-pd-csi-driver/utils.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#a00000\"></span><span style=\"color:#00a000\">+++ b/pkg/gce-pd-csi-driver/utils.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span><span style=\"color:#800080;font-weight:bold\">@@ -123,6 +123,8 @@ func validateAccessMode(am *csi.VolumeCapability_AccessMode) error {\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#800080;font-weight:bold\"></span> case csi.VolumeCapability_AccessMode_SINGLE_NODE_READER_ONLY:\n</span></span><span style=\"display:flex;\"><span> case csi.VolumeCapability_AccessMode_MULTI_NODE_READER_ONLY:\n</span></span><span style=\"display:flex;\"><span> case csi.VolumeCapability_AccessMode_MULTI_NODE_MULTI_WRITER:\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ case csi.VolumeCapability_AccessMode_SINGLE_NODE_SINGLE_WRITER:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ case csi.VolumeCapability_AccessMode_SINGLE_NODE_MULTI_WRITER:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span> default:\n</span></span><span style=\"display:flex;\"><span> return fmt.Errorf(&#34;%v access mode is not supported for for PD&#34;, am.GetMode())\n</span></span><span style=\"display:flex;\"><span> }\n</span></span></code></pre></div><h3 id=\"advertise-new-csi-controller-and-node-service-capabilities\">Advertise new CSI controller and node service capabilities</h3>\n<p>Your CSI driver will also need to return the new <code>SINGLE_NODE_MULTI_WRITER</code> capability as part of the <code>ControllerGetCapabilities</code> and <code>NodeGetCapabilities</code> RPCs.</p>\n<p>Using the <a href=\"https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver/blob/v1.2.2/pkg/gce-pd-csi-driver/gce-pd-driver.go#L54-L77\">GCP PD CSI driver capability advertisement logic</a> as an example, here is how it can be extended:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-diff\" data-lang=\"diff\"><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">diff --git a/pkg/gce-pd-csi-driver/gce-pd-driver.go b/pkg/gce-pd-csi-driver/gce-pd-driver.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">index 45903f3..0d7ea26 100644\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\"></span><span style=\"color:#a00000\">--- a/pkg/gce-pd-csi-driver/gce-pd-driver.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#a00000\"></span><span style=\"color:#00a000\">+++ b/pkg/gce-pd-csi-driver/gce-pd-driver.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span><span style=\"color:#800080;font-weight:bold\">@@ -56,6 +56,8 @@ func (gceDriver *GCEDriver) SetupGCEDriver(name, vendorVersion string, extraVolu\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#800080;font-weight:bold\"></span> csi.VolumeCapability_AccessMode_SINGLE_NODE_WRITER,\n</span></span><span style=\"display:flex;\"><span> csi.VolumeCapability_AccessMode_MULTI_NODE_READER_ONLY,\n</span></span><span style=\"display:flex;\"><span> csi.VolumeCapability_AccessMode_MULTI_NODE_MULTI_WRITER,\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ csi.VolumeCapability_AccessMode_SINGLE_NODE_SINGLE_WRITER,\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ csi.VolumeCapability_AccessMode_SINGLE_NODE_MULTI_WRITER,\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span> }\n</span></span><span style=\"display:flex;\"><span> gceDriver.AddVolumeCapabilityAccessModes(vcam)\n</span></span><span style=\"display:flex;\"><span> csc := []csi.ControllerServiceCapability_RPC_Type{\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#800080;font-weight:bold\">@@ -67,12 +69,14 @@ func (gceDriver *GCEDriver) SetupGCEDriver(name, vendorVersion string, extraVolu\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#800080;font-weight:bold\"></span> csi.ControllerServiceCapability_RPC_EXPAND_VOLUME,\n</span></span><span style=\"display:flex;\"><span> csi.ControllerServiceCapability_RPC_LIST_VOLUMES,\n</span></span><span style=\"display:flex;\"><span> csi.ControllerServiceCapability_RPC_LIST_VOLUMES_PUBLISHED_NODES,\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ csi.ControllerServiceCapability_RPC_SINGLE_NODE_MULTI_WRITER,\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span> }\n</span></span><span style=\"display:flex;\"><span> gceDriver.AddControllerServiceCapabilities(csc)\n</span></span><span style=\"display:flex;\"><span> ns := []csi.NodeServiceCapability_RPC_Type{\n</span></span><span style=\"display:flex;\"><span> csi.NodeServiceCapability_RPC_STAGE_UNSTAGE_VOLUME,\n</span></span><span style=\"display:flex;\"><span> csi.NodeServiceCapability_RPC_EXPAND_VOLUME,\n</span></span><span style=\"display:flex;\"><span> csi.NodeServiceCapability_RPC_GET_VOLUME_STATS,\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ csi.NodeServiceCapability_RPC_SINGLE_NODE_MULTI_WRITER,\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span> }\n</span></span><span style=\"display:flex;\"><span> gceDriver.AddNodeServiceCapabilities(ns)\n</span></span></code></pre></div><h3 id=\"implement-nodepublishvolume-behavior\">Implement <code>NodePublishVolume</code> behavior</h3>\n<p>The CSI spec outlines expected behavior for the <code>NodePublishVolume</code> RPC when called more than once for the same volume but with different arguments (like the target path).\nPlease refer to <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/spec.md#nodepublishvolume\">the second table in the NodePublishVolume section of the CSI spec</a> for more details on expected behavior when implementing in your driver.</p>\n<h3 id=\"update-your-csi-sidecars\">Update your CSI sidecars</h3>\n<p>When deploying your CSI drivers, you must update the following CSI sidecars to versions that depend on CSI spec v1.5.0+ and the Kubernetes v1.22 API.\nThe minimum required versions are:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes-csi/external-provisioner/releases/tag/v3.0.0\">csi-provisioner:v3.0.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-attacher/releases/tag/v3.3.0\">csi-attacher:v3.3.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-resizer/releases/tag/v1.3.0\">csi-resizer:v1.3.0+</a></li>\n</ul>\n<h2 id=\"what-s-next\">What’s next?</h2>\n<p>As part of the beta graduation for this feature, SIG Storage plans to update the Kubernetes scheduler to support pod preemption in relation to ReadWriteOncePod storage.\nThis means if two pods request a PersistentVolumeClaim with ReadWriteOncePod, the pod with highest priority will gain access to the PersistentVolumeClaim and any pod with lower priority will be preempted from the node and be unable to access the PersistentVolumeClaim.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>Please see <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/2485-read-write-once-pod-pv-access-mode/README.md\">KEP-2485</a> for more details on the ReadWriteOncePod access mode and motivations for CSI spec changes.</p>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>The <a href=\"https://kubernetes.slack.com/messages/csi\">Kubernetes #csi Slack channel</a> and any of the <a href=\"https://github.com/kubernetes/community/blob/master/sig-storage/README.md#contact\">standard SIG Storage communication channels</a> are great mediums to reach out to the SIG Storage and the CSI teams.</p>\n<p>Special thanks to the following people for their insightful reviews and design considerations:</p>\n<ul>\n<li>Abdullah Gharaibeh (ahg-g)</li>\n<li>Aldo Culquicondor (alculquicondor)</li>\n<li>Ben Swartzlander (bswartz)</li>\n<li>Deep Debroy (ddebroy)</li>\n<li>Hemant Kumar (gnufied)</li>\n<li>Humble Devassy Chirammal (humblec)</li>\n<li>James DeFelice (jdef)</li>\n<li>Jan Šafránek (jsafrane)</li>\n<li>Jing Xu (jingxu97)</li>\n<li>Jordan Liggitt (liggitt)</li>\n<li>Michelle Au (msau42)</li>\n<li>Saad Ali (saad-ali)</li>\n<li>Tim Hockin (thockin)</li>\n<li>Xing Yang (xing-yang)</li>\n</ul>\n<p>If you’re interested in getting involved with the design and development of CSI or any part of the Kubernetes storage system, join the <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group</a> (SIG).\nWe’re rapidly growing and always welcome new contributors.</p>","PublishedAt":"2021-09-13 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/09/13/read-write-once-pod-access-mode-alpha/","SourceName":"Kubernetes"}}]}},"pageContext":{"limit":30,"skip":5160,"numPages":193,"currentPage":173}},"staticQueryHashes":["3649515864"]}