{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/161","result":{"data":{"allPost":{"edges":[{"node":{"ID":8,"Title":"Dynamic Kubernetes Cluster Scaling at Airbnb","Description":"","PublishedAt":"2022-05-23 17:35:24+00:00","OriginURL":"https://medium.com/airbnb-engineering/dynamic-kubernetes-cluster-scaling-at-airbnb-d79ae3afa132?source=rss----53c7c27702d5---4","SourceName":"Airbnb"}},{"node":{"ID":1216,"Title":"Blog: Kubernetes 1.24: Avoid Collisions Assigning IP Addresses to Services","Description":"<p><strong>Author:</strong> Antonio Ojea (Red Hat)</p>\n<p>In Kubernetes, <a href=\"https://kubernetes.io/docs/concepts/services-networking/service/\">Services</a> are an abstract way to expose\nan application running on a set of Pods. Services\ncan have a cluster-scoped virtual IP address (using a Service of <code>type: ClusterIP</code>).\nClients can connect using that virtual IP address, and Kubernetes then load-balances traffic to that\nService across the different backing Pods.</p>\n<h2 id=\"how-service-clusterips-are-allocated\">How Service ClusterIPs are allocated?</h2>\n<p>A Service <code>ClusterIP</code> can be assigned:</p>\n<dl>\n<dt><em>dynamically</em></dt>\n<dd>the cluster's control plane automatically picks a free IP address from within the configured IP range for <code>type: ClusterIP</code> Services.</dd>\n<dt><em>statically</em></dt>\n<dd>you specify an IP address of your choice, from within the configured IP range for Services.</dd>\n</dl>\n<p>Across your whole cluster, every Service <code>ClusterIP</code> must be unique.\nTrying to create a Service with a specific <code>ClusterIP</code> that has already\nbeen allocated will return an error.</p>\n<h2 id=\"why-do-you-need-to-reserve-service-cluster-ips\">Why do you need to reserve Service Cluster IPs?</h2>\n<p>Sometimes you may want to have Services running in well-known IP addresses, so other components and\nusers in the cluster can use them.</p>\n<p>The best example is the DNS Service for the cluster. Some Kubernetes installers assign the 10th address from\nthe Service IP range to the DNS service. Assuming you configured your cluster with Service IP range\n10.96.0.0/16 and you want your DNS Service IP to be 10.96.0.10, you'd have to create a Service like\nthis:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Service<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">labels</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">k8s-app</span>:<span style=\"color:#bbb\"> </span>kube-dns<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kubernetes.io/cluster-service</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;true&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kubernetes.io/name</span>:<span style=\"color:#bbb\"> </span>CoreDNS<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>kube-dns<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>kube-system<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">clusterIP</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">10.96.0.10</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ports</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>dns<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">53</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">protocol</span>:<span style=\"color:#bbb\"> </span>UDP<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">targetPort</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">53</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>dns-tcp<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">53</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">protocol</span>:<span style=\"color:#bbb\"> </span>TCP<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">targetPort</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">53</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">selector</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">k8s-app</span>:<span style=\"color:#bbb\"> </span>kube-dns<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>ClusterIP<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>but as I explained before, the IP address 10.96.0.10 has not been reserved; if other Services are created\nbefore or in parallel with dynamic allocation, there is a chance they can allocate this IP, hence,\nyou will not be able to create the DNS Service because it will fail with a conflict error.</p>\n<h2 id=\"avoid-ClusterIP-conflict\">How can you avoid Service ClusterIP conflicts?</h2>\n<p>In Kubernetes 1.24, you can enable a new feature gate <code>ServiceIPStaticSubrange</code>.\nTurning this on allows you to use a different IP\nallocation strategy for Services, reducing the risk of collision.</p>\n<p>The <code>ClusterIP</code> range will be divided, based on the formula <code>min(max(16, cidrSize / 16), 256)</code>,\ndescribed as <em>never less than 16 or more than 256 with a graduated step between them</em>.</p>\n<p>Dynamic IP assignment will use the upper band by default, once this has been exhausted it will\nuse the lower range. This will allow users to use static allocations on the lower band with a low\nrisk of collision.</p>\n<p>Examples:</p>\n<h4 id=\"service-ip-cidr-block-10-96-0-0-24\">Service IP CIDR block: 10.96.0.0/24</h4>\n<p>Range Size: 2<sup>8</sup> - 2 = 254<br>\nBand Offset: <code>min(max(16, 256/16), 256)</code> = <code>min(16, 256)</code> = 16<br>\nStatic band start: 10.96.0.1<br>\nStatic band end: 10.96.0.16<br>\nRange end: 10.96.0.254</p>\n<figure>\n<div class=\"mermaid\">\npie showData\ntitle 10.96.0.0/24\n\"Static\" : 16\n\"Dynamic\" : 238\n</div>\n</figure>\n<noscript>\n<div class=\"alert alert-secondary callout\" role=\"alert\">\n<em class=\"javascript-required\">JavaScript must be <a href=\"https://www.enable-javascript.com/\">enabled</a> to view this content</em>\n</div>\n</noscript>\n<h4 id=\"service-ip-cidr-block-10-96-0-0-20\">Service IP CIDR block: 10.96.0.0/20</h4>\n<p>Range Size: 2<sup>12</sup> - 2 = 4094<br>\nBand Offset: <code>min(max(16, 4096/16), 256)</code> = <code>min(256, 256)</code> = 256<br>\nStatic band start: 10.96.0.1<br>\nStatic band end: 10.96.1.0<br>\nRange end: 10.96.15.254</p>\n<figure>\n<div class=\"mermaid\">\npie showData\ntitle 10.96.0.0/20\n\"Static\" : 256\n\"Dynamic\" : 3838\n</div>\n</figure>\n<noscript>\n<div class=\"alert alert-secondary callout\" role=\"alert\">\n<em class=\"javascript-required\">JavaScript must be <a href=\"https://www.enable-javascript.com/\">enabled</a> to view this content</em>\n</div>\n</noscript>\n<h4 id=\"service-ip-cidr-block-10-96-0-0-16\">Service IP CIDR block: 10.96.0.0/16</h4>\n<p>Range Size: 2<sup>16</sup> - 2 = 65534<br>\nBand Offset: <code>min(max(16, 65536/16), 256)</code> = <code>min(4096, 256)</code> = 256<br>\nStatic band start: 10.96.0.1<br>\nStatic band ends: 10.96.1.0<br>\nRange end: 10.96.255.254</p>\n<figure>\n<div class=\"mermaid\">\npie showData\ntitle 10.96.0.0/16\n\"Static\" : 256\n\"Dynamic\" : 65278\n</div>\n</figure>\n<noscript>\n<div class=\"alert alert-secondary callout\" role=\"alert\">\n<em class=\"javascript-required\">JavaScript must be <a href=\"https://www.enable-javascript.com/\">enabled</a> to view this content</em>\n</div>\n</noscript>\n<h2 id=\"get-involved-with-sig-network\">Get involved with SIG Network</h2>\n<p>The current SIG-Network <a href=\"https://github.com/orgs/kubernetes/projects/10\">KEPs</a> and <a href=\"https://github.com/kubernetes/kubernetes/issues?q=is%3Aopen+is%3Aissue+label%3Asig%2Fnetwork\">issues</a> on GitHub illustrate the SIG’s areas of emphasis.</p>\n<p><a href=\"https://github.com/kubernetes/community/tree/master/sig-network\">SIG Network meetings</a> are a friendly, welcoming venue for you to connect with the community and share your ideas.\nLooking forward to hearing from you!</p>","PublishedAt":"2022-05-23 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/05/23/service-ip-dynamic-and-static-allocation/","SourceName":"Kubernetes"}},{"node":{"ID":516,"Title":"A Survey of Causal Inference Applications at Netflix","Description":"","PublishedAt":"2022-05-21 15:02:49+00:00","OriginURL":"https://netflixtechblog.com/a-survey-of-causal-inference-applications-at-netflix-b62d25175e6f?source=rss----2615bd06b42e---4","SourceName":"Netflix"}},{"node":{"ID":524,"Title":"Modernizing Nextdoor Search Stack — Part 2","Description":"","PublishedAt":"2022-05-20 20:36:28+00:00","OriginURL":"https://engblog.nextdoor.com/modernizing-nextdoor-search-stack-part-2-82192221ad3b?source=rss----5e54f11cdfdf---4","SourceName":"Nextdoor"}},{"node":{"ID":735,"Title":"Migrating millions of lines of code to TypeScript","Description":"On Sunday, March 6, we migrated Stripe’s largest JavaScript codebase from Flow to TypeScript. In a single pull request, we converted more than 3.7 million lines of code. The next day, hundreds of engineers came in to start writing TypeScript for their projects.","PublishedAt":"2022-05-20 00:00:00+00:00","OriginURL":"https://stripe.com/blog/migrating-to-typescript","SourceName":"Stripe"}},{"node":{"ID":1217,"Title":"Blog: Kubernetes 1.24: Introducing Non-Graceful Node Shutdown Alpha","Description":"<p><strong>Authors</strong> Xing Yang and Yassine Tijani (VMware)</p>\n<p>Kubernetes v1.24 introduces alpha support for <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/2268-non-graceful-shutdown\">Non-Graceful Node Shutdown</a>. This feature allows stateful workloads to failover to a different node after the original node is shutdown or in a non-recoverable state such as hardware failure or broken OS.</p>\n<h2 id=\"how-is-this-different-from-graceful-node-shutdown\">How is this different from Graceful Node Shutdown</h2>\n<p>You might have heard about the <a href=\"https://kubernetes.io/docs/concepts/architecture/nodes/#graceful-node-shutdown\">Graceful Node Shutdown</a> capability of Kubernetes,\nand are wondering how the Non-Graceful Node Shutdown feature is different from that. Graceful Node Shutdown\nallows Kubernetes to detect when a node is shutting down cleanly, and handles that situation appropriately.\nA Node Shutdown can be &quot;graceful&quot; only if the node shutdown action can be detected by the kubelet ahead\nof the actual shutdown. However, there are cases where a node shutdown action may not be detected by\nthe kubelet. This could happen either because the shutdown command does not trigger the systemd inhibitor\nlocks mechanism that kubelet relies upon, or because of a configuration error\n(the <code>ShutdownGracePeriod</code> and <code>ShutdownGracePeriodCriticalPods</code> are not configured properly).</p>\n<p>Graceful node shutdown relies on Linux-specific support. The kubelet does not watch for upcoming\nshutdowns on Windows nodes (this may change in a future Kubernetes release).</p>\n<p>When a node is shutdown but without the kubelet detecting it, pods on that node\nalso shut down ungracefully. For stateless apps, that's often not a problem (a ReplicaSet adds a new pod once\nthe cluster detects that the affected node or pod has failed). For stateful apps, the story is more complicated.\nIf you use a StatefulSet and have a pod from that StatefulSet on a node that fails uncleanly, that affected pod\nwill be marked as terminating; the StatefulSet cannot create a replacement pod because the pod\nstill exists in the cluster.\nAs a result, the application running on the StatefulSet may be degraded or even offline. If the original, shut\ndown node comes up again, the kubelet on that original node reports in, deletes the existing pods, and\nthe control plane makes a replacement pod for that StatefulSet on a different running node.\nIf the original node has failed and does not come up, those stateful pods would be stuck in a\nterminating status on that failed node indefinitely.</p>\n<pre tabindex=\"0\"><code>$ kubectl get pod -o wide\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\nweb-0 1/1 Running 0 100m 10.244.2.4 k8s-node-876-1639279816 &lt;none&gt; &lt;none&gt;\nweb-1 1/1 Terminating 0 100m 10.244.1.3 k8s-node-433-1639279804 &lt;none&gt; &lt;none&gt;\n</code></pre><h2 id=\"try-out-the-new-non-graceful-shutdown-handling\">Try out the new non-graceful shutdown handling</h2>\n<p>To use the non-graceful node shutdown handling, you must enable the <code>NodeOutOfServiceVolumeDetach</code>\n<a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gate</a> for the <code>kube-controller-manager</code>\ncomponent.</p>\n<p>In the case of a node shutdown, you can manually taint that node as out of service. You should make certain that\nthe node is truly shutdown (not in the middle of restarting) before you add that taint. You could add that\ntaint following a shutdown that the kubelet did not detect and handle in advance; another case where you\ncan use that taint is when the node is in a non-recoverable state due to a hardware failure or a broken OS.\nThe values you set for that taint can be <code>node.kubernetes.io/out-of-service=nodeshutdown: &quot;NoExecute&quot;</code>\nor <code>node.kubernetes.io/out-of-service=nodeshutdown:&quot; NoSchedule&quot;</code>.\nProvided you have enabled the feature gate mentioned earlier, setting the out-of-service taint on a Node\nmeans that pods on the node will be deleted unless if there are matching tolerations on the pods.\nPersistent volumes attached to the shutdown node will be detached, and for StatefulSets, replacement pods will\nbe created successfully on a different running node.</p>\n<pre tabindex=\"0\"><code>$ kubectl taint nodes &lt;node-name&gt; node.kubernetes.io/out-of-service=nodeshutdown:NoExecute\n$ kubectl get pod -o wide\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\nweb-0 1/1 Running 0 150m 10.244.2.4 k8s-node-876-1639279816 &lt;none&gt; &lt;none&gt;\nweb-1 1/1 Running 0 10m 10.244.1.7 k8s-node-433-1639279804 &lt;none&gt; &lt;none&gt;\n</code></pre><p>Note: Before applying the out-of-service taint, you <strong>must</strong> verify that a node is already in shutdown or power off state (not in the middle of restarting), either because the user intentionally shut it down or the node is down due to hardware failures, OS issues, etc.</p>\n<p>Once all the workload pods that are linked to the out-of-service node are moved to a new running node, and the shutdown node has been recovered, you should remove\nthat taint on the affected node after the node is recovered.\nIf you know that the node will not return to service, you could instead delete the node from the cluster.</p>\n<h2 id=\"what-s-next\">What’s next?</h2>\n<p>Depending on feedback and adoption, the Kubernetes team plans to push the Non-Graceful Node Shutdown implementation to Beta in either 1.25 or 1.26.</p>\n<p>This feature requires a user to manually add a taint to the node to trigger workloads failover and remove the taint after the node is recovered. In the future, we plan to find ways to automatically detect and fence nodes that are shutdown/failed and automatically failover workloads to another node.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>Check out the <a href=\"https://kubernetes.io/docs/concepts/architecture/nodes/#non-graceful-node-shutdown\">documentation</a>\nfor non-graceful node shutdown.</p>\n<h2 id=\"how-to-get-involved\">How to get involved?</h2>\n<p>This feature has a long story. Yassine Tijani (<a href=\"https://github.com/yastij\">yastij</a>) started the KEP more than two years ago. Xing Yang (<a href=\"https://github.com/xing-yang\">xing-yang</a>) continued to drive the effort. There were many discussions among SIG Storage, SIG Node, and API reviewers to nail down the design details. Ashutosh Kumar (<a href=\"https://github.com/sonasingh46\">sonasingh46</a>) did most of the implementation and brought it to Alpha in Kubernetes 1.24.</p>\n<p>We want to thank the following people for their insightful reviews: Tim Hockin (<a href=\"https://github.com/thockin\">thockin</a>) for his guidance on the design, Jing Xu (<a href=\"https://github.com/jingxu97\">jingxu97</a>), Hemant Kumar (<a href=\"https://github.com/gnufied\">gnufied</a>), and Michelle Au (<a href=\"https://github.com/msau42\">msau42</a>) for reviews from SIG Storage side, and Mrunal Patel (<a href=\"https://github.com/mrunalp\">mrunalp</a>), David Porter (<a href=\"https://github.com/bobbypage\">bobbypage</a>), Derek Carr (<a href=\"https://github.com/derekwaynecarr\">derekwaynecarr</a>), and Danielle Endocrimes (<a href=\"https://github.com/endocrimes\">endocrimes</a>) for reviews from SIG Node side.</p>\n<p>There are many people who have helped review the design and implementation along the way. We want to thank everyone who has contributed to this effort including the about 30 people who have reviewed the <a href=\"https://github.com/kubernetes/enhancements/pull/1116\">KEP</a> and implementation over the last couple of years.</p>\n<p>This feature is a collaboration between SIG Storage and SIG Node. For those interested in getting involved with the design and development of any part of the Kubernetes Storage system, join the <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group</a> (SIG). For those interested in getting involved with the design and development of the components that support the controlled interactions between pods and host resources, join the <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">Kubernetes Node SIG</a>.</p>","PublishedAt":"2022-05-20 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/05/20/kubernetes-1-24-non-graceful-node-shutdown-alpha/","SourceName":"Kubernetes"}},{"node":{"ID":447,"Title":"Mobile app event tracking: Telling the story of how your app works (or doesn’t work)","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2022/05/MXP-Blog-MobileAppEventTracking-1920x1080-1-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>Event tracking is how you know what’s happening in your mobile apps. It’s the primary technique used to capture usage information by product analytics platforms like Mixpanel. It’s, therefore, essential for you, as a product manager, designer, or any kind of product stakeholder, to have a good understanding of how event tracking works so you</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/what-is-mobile-app-event-tracking/\">Mobile app event tracking: Telling the story of how your app works (or doesn&#8217;t work)</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2022-05-19 19:22:14+00:00","OriginURL":"https://mixpanel.com/blog/what-is-mobile-app-event-tracking/","SourceName":"Mixpanel"}},{"node":{"ID":177,"Title":"#ClouderaLife Spotlight: Margot Tien, Software Engineer","Description":"<p>A career in transition, a community in need, navigating uncharted territory to solve for both</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/clouderalife-spotlight-margot-tien-software-engineer/\">#ClouderaLife Spotlight: Margot Tien, Software Engineer</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-05-19 18:38:10+00:00","OriginURL":"https://blog.cloudera.com/clouderalife-spotlight-margot-tien-software-engineer/","SourceName":"Cloudera"}},{"node":{"ID":402,"Title":"Refactoring and Optimizing a High Traffic API at PayPal","Description":"","PublishedAt":"2022-05-19 15:44:52+00:00","OriginURL":"https://medium.com/paypal-tech/refactoring-and-optimizing-a-high-traffic-api-at-paypal-eb11c373d795?source=rss----6423323524ba---4","SourceName":"Paypal"}},{"node":{"ID":1052,"Title":"Terraform CI code execution restrictions","Description":"<p>This article is part of the Security Tech Blog Series: Spring Cleaning for Security series, brought to you by Maximilian Frank (@max-frank) from the Security Engineering team. Background At Mercari, we utilize many microservices developed across multiple different teams. Each team has ownership over not only their code, but also the infrastructure necessary to run [&hellip;]</p>\n","PublishedAt":"2022-05-19 13:28:08+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20220519-terraform-ci-code-execution-restrictions/","SourceName":"Mercari"}},{"node":{"ID":393,"Title":"Tooling to Find More Items, More Quickly","Description":"","PublishedAt":"2022-05-18 16:03:32+00:00","OriginURL":"https://tech.instacart.com/tooling-to-find-more-items-more-quickly-26ff6196e821?source=rss----587883b5d2ee---4","SourceName":"Instacart"}},{"node":{"ID":178,"Title":"Becoming AI-First: How to Get There","Description":"<p>Deciding to adopt an AI-first strategy is the easy part. Figuring out how to implement it takes a little more effort. It requires a clear-eyed vision built around well-defined goals and a realistic execution plan. Being AI-first means setting up your organization for the future. By leveraging data, analytics, and automation, a company can gain [&#8230;]</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/becoming-ai-first-how-to-get-there/\">Becoming AI-First: How to Get There</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-05-18 14:43:12+00:00","OriginURL":"https://blog.cloudera.com/becoming-ai-first-how-to-get-there/","SourceName":"Cloudera"}},{"node":{"ID":736,"Title":"Stripe Data Pipeline","Description":"Sync your Stripe data with your Redshift or Snowflake data warehouse.","PublishedAt":"2022-05-18 00:00:00+00:00","OriginURL":"https://stripe.com/data-pipeline","SourceName":"Stripe"}},{"node":{"ID":1218,"Title":"Blog: Kubernetes 1.24: Prevent unauthorised volume mode conversion","Description":"<p><strong>Author:</strong> Raunak Pradip Shah (Mirantis)</p>\n<p>Kubernetes v1.24 introduces a new alpha-level feature that prevents unauthorised users\nfrom modifying the volume mode of a <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/\"><code>PersistentVolumeClaim</code></a> created from an\nexisting <a href=\"https://kubernetes.io/docs/concepts/storage/volume-snapshots/\"><code>VolumeSnapshot</code></a> in the Kubernetes cluster.</p>\n<h3 id=\"the-problem\">The problem</h3>\n<p>The <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#volume-mode\">Volume Mode</a> determines whether a volume\nis formatted into a filesystem or presented as a raw block device.</p>\n<p>Users can leverage the <code>VolumeSnapshot</code> feature, which has been stable since Kubernetes v1.20,\nto create a <code>PersistentVolumeClaim</code> (shortened as PVC) from an existing <code>VolumeSnapshot</code> in\nthe Kubernetes cluster. The PVC spec includes a <code>dataSource</code> field, which can point to an\nexisting <code>VolumeSnapshot</code> instance.\nVisit <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#create-persistent-volume-claim-from-volume-snapshot\">Create a PersistentVolumeClaim from a Volume Snapshot</a> for more details.</p>\n<p>When leveraging the above capability, there is no logic that validates whether the mode of the\noriginal volume, whose snapshot was taken, matches the mode of the newly created volume.</p>\n<p>This presents a security gap that allows malicious users to potentially exploit an\nas-yet-unknown vulnerability in the host operating system.</p>\n<p>Many popular storage backup vendors convert the volume mode during the course of a\nbackup operation, for efficiency purposes, which prevents Kubernetes from blocking\nthe operation completely and presents a challenge in distinguishing trusted\nusers from malicious ones.</p>\n<h3 id=\"preventing-unauthorised-users-from-converting-the-volume-mode\">Preventing unauthorised users from converting the volume mode</h3>\n<p>In this context, an authorised user is one who has access rights to perform <code>Update</code>\nor <code>Patch</code> operations on <code>VolumeSnapshotContents</code>, which is a cluster-level resource.<br>\nIt is upto the cluster administrator to provide these rights only to trusted users\nor applications, like backup vendors.</p>\n<p>If the alpha feature is <a href=\"https://kubernetes-csi.github.io/docs/\">enabled</a> in\n<code>snapshot-controller</code>, <code>snapshot-validation-webhook</code> and <code>external-provisioner</code>,\nthen unauthorised users will not be allowed to modify the volume mode of a PVC\nwhen it is being created from a <code>VolumeSnapshot</code>.</p>\n<p>To convert the volume mode, an authorised user must do the following:</p>\n<ol>\n<li>Identify the <code>VolumeSnapshot</code> that is to be used as the data source for a newly\ncreated PVC in the given namespace.</li>\n<li>Identify the <code>VolumeSnapshotContent</code> bound to the above <code>VolumeSnapshot</code>.</li>\n</ol>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl get volumesnapshot -n &lt;namespace&gt;\n</span></span></code></pre></div><ol start=\"3\">\n<li>\n<p>Add the annotation <a href=\"https://kubernetes.io/docs/reference/labels-annotations-taints/#snapshot-storage-kubernetes-io-allowvolumemodechange\"><code>snapshot.storage.kubernetes.io/allowVolumeModeChange</code></a>\nto the <code>VolumeSnapshotContent</code>.</p>\n</li>\n<li>\n<p>This annotation can be added either via software or manually by the authorised\nuser. The <code>VolumeSnapshotContent</code> annotation must look like following manifest fragment:</p>\n</li>\n</ol>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>VolumeSnapshotContent<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">annotations</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">snapshot.storage.kubernetes.io/allowVolumeModeChange</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;true&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#00f;font-weight:bold\">...</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p><strong>Note</strong>: For pre-provisioned <code>VolumeSnapshotContents</code>, you must take an extra\nstep of setting <code>spec.sourceVolumeMode</code> field to either <code>Filesystem</code> or <code>Block</code>,\ndepending on the mode of the volume from which this snapshot was taken.</p>\n<p>An example is shown below:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>snapshot.storage.k8s.io/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>VolumeSnapshotContent<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">annotations</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">snapshot.storage.kubernetes.io/allowVolumeModeChange</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;true&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>new-snapshot-content-test<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">deletionPolicy</span>:<span style=\"color:#bbb\"> </span>Delete<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">driver</span>:<span style=\"color:#bbb\"> </span>hostpath.csi.k8s.io<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">source</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">snapshotHandle</span>:<span style=\"color:#bbb\"> </span>7bdd0de3-aaeb-11e8-9aae-0242ac110002<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">sourceVolumeMode</span>:<span style=\"color:#bbb\"> </span>Filesystem<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeSnapshotRef</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>new-snapshot-test<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>default<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Repeat steps 1 to 3 for all <code>VolumeSnapshotContents</code> whose volume mode needs to be\nconverted during a backup or restore operation.</p>\n<p>If the annotation shown in step 4 above is present on a <code>VolumeSnapshotContent</code>\nobject, Kubernetes will not prevent the volume mode from being converted.\nUsers should keep this in mind before they attempt to add the annotation\nto any <code>VolumeSnapshotContent</code>.</p>\n<h3 id=\"what-s-next\">What's next</h3>\n<p><a href=\"https://kubernetes-csi.github.io/docs/\">Enable this feature</a> and let us know\nwhat you think!</p>\n<p>We hope this feature causes no disruption to existing workflows while preventing\nmalicious users from exploiting security vulnerabilities in their clusters.</p>\n<p>For any queries or issues, join <a href=\"https://slack.k8s.io/\">Kubernetes on Slack</a> and\ncreate a thread in the #sig-storage channel. Alternately, create an issue in the\nCSI external-snapshotter <a href=\"https://github.com/kubernetes-csi/external-snapshotter\">repository</a>.</p>","PublishedAt":"2022-05-18 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/05/18/prevent-unauthorised-volume-mode-conversion-alpha/","SourceName":"Kubernetes"}},{"node":{"ID":748,"Title":"Better Load Balancing: Real-Time Dynamic Subsetting","Description":"<h1><span style=\"font-weight: 400;\">Overview</span></h1>\n<p><span style=\"font-weight: 400;\">Subsetting is a common technique used in load balancing for large-scale distributed systems. In this blog post, we will briefly introduce Uber’s current service mesh architecture that has been powering thousands of critical microservices in Uber since 2016. We </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/better-load-balancing-real-time-dynamic-subsetting/\">Better Load Balancing: Real-Time Dynamic Subsetting</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2022-05-17 16:30:26+00:00","OriginURL":"https://eng.uber.com/better-load-balancing-real-time-dynamic-subsetting/","SourceName":"Uber"}},{"node":{"ID":1053,"Title":"What We Talk About When We Talk About Quality Assurance.","Description":"<p>* This article is a translation of the Japanese article written on September 16, 2021. Hello! This is @myajiri, a QA engineer at Merpay. This article is for day 12 of Merpay Tech Openness Month 2021. After joining Merpay, PMs and engineers undergo a process of onboarding (training to understand our products and work). I&#8217;m [&hellip;]</p>\n","PublishedAt":"2022-05-17 11:00:22+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20210915-c9577ca624/","SourceName":"Mercari"}},{"node":{"ID":141,"Title":"Fighting the forces of clock skew when syncing password payloads","Description":"","PublishedAt":"2022-05-17 10:00:00+00:00","OriginURL":"https://dropbox.tech/application/dropbox-passwords-clock-skew-payload-sync-merge","SourceName":"Dropbox"}},{"node":{"ID":603,"Title":"WARP - A Web Application Rewrite Project","Description":"","PublishedAt":"2022-05-16 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2022-05-16-warp-a-web-application-rewrite-project/","SourceName":"Trivago"}},{"node":{"ID":1219,"Title":"Blog: Kubernetes 1.24: Volume Populators Graduate to Beta","Description":"<p><strong>Author:</strong>\nBen Swartzlander (NetApp)</p>\n<p>The volume populators feature is now two releases old and entering beta! The <code>AnyVolumeDataSource</code> feature\ngate defaults to enabled in Kubernetes v1.24, which means that users can specify any custom resource\nas the data source of a PVC.</p>\n<p>An <a href=\"https://kubernetes.io/blog/2021/08/30/volume-populators-redesigned/\">earlier blog article</a> detailed how the\nvolume populators feature works. In short, a cluster administrator can install a CRD and\nassociated populator controller in the cluster, and any user who can create instances of\nthe CR can create pre-populated volumes by taking advantage of the populator.</p>\n<p>Multiple populators can be installed side by side for different purposes. The SIG storage\ncommunity is already seeing some implementations in public, and more prototypes should\nappear soon.</p>\n<p>Cluster administrations are <strong>strongly encouraged</strong> to install the\nvolume-data-source-validator controller and associated <code>VolumePopulator</code> CRD before installing\nany populators so that users can get feedback about invalid PVC data sources.</p>\n<h2 id=\"new-features\">New Features</h2>\n<p>The <a href=\"https://github.com/kubernetes-csi/lib-volume-populator\">lib-volume-populator</a> library\non which populators are built now includes metrics to help operators monitor and detect\nproblems. This library is now beta and latest release is v1.0.1.</p>\n<p>The <a href=\"https://github.com/kubernetes-csi/volume-data-source-validator\">volume data source validator</a>\ncontroller also has metrics support added, and is in beta. The <code>VolumePopulator</code> CRD is\nbeta and the latest release is v1.0.1.</p>\n<h2 id=\"trying-it-out\">Trying it out</h2>\n<p>To see how this works, you can install the sample &quot;hello&quot; populator and try it\nout.</p>\n<p>First install the volume-data-source-validator controller.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/volume-data-source-validator/v1.0.1/client/config/crd/populator.storage.k8s.io_volumepopulators.yaml\n</span></span><span style=\"display:flex;\"><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/volume-data-source-validator/v1.0.1/deploy/kubernetes/rbac-data-source-validator.yaml\n</span></span><span style=\"display:flex;\"><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/volume-data-source-validator/v1.0.1/deploy/kubernetes/setup-data-source-validator.yaml\n</span></span></code></pre></div><p>Next install the example populator.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/lib-volume-populator/v1.0.1/example/hello-populator/crd.yaml\n</span></span><span style=\"display:flex;\"><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/lib-volume-populator/87a47467b86052819e9ad13d15036d65b9a32fbb/example/hello-populator/deploy.yaml\n</span></span></code></pre></div><p>Your cluster now has a new CustomResourceDefinition that provides a test API named Hello.\nCreate an instance of the <code>Hello</code> custom resource, with some text:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>hello.example.com/v1alpha1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">fileName</span>:<span style=\"color:#bbb\"> </span>example.txt<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">fileContents</span>:<span style=\"color:#bbb\"> </span>Hello, world!<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Create a PVC that refers to that CR as its data source.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-pvc<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOnce<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>10Mi<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">dataSourceRef</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiGroup</span>:<span style=\"color:#bbb\"> </span>hello.example.com<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeMode</span>:<span style=\"color:#bbb\"> </span>Filesystem<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Next, run a Job that reads the file in the PVC.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>batch/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Job<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-job<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">template</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">containers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-container<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>busybox:latest<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">command</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- cat<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- /mnt/example.txt<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeMounts</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>vol<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">mountPath</span>:<span style=\"color:#bbb\"> </span>/mnt<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">restartPolicy</span>:<span style=\"color:#bbb\"> </span>Never<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>vol<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">persistentVolumeClaim</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">claimName</span>:<span style=\"color:#bbb\"> </span>example-pvc<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Wait for the job to complete (including all of its dependencies).</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl <span style=\"color:#a2f\">wait</span> --for<span style=\"color:#666\">=</span><span style=\"color:#b8860b\">condition</span><span style=\"color:#666\">=</span>Complete job/example-job\n</span></span></code></pre></div><p>And last examine the log from the job.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl logs job/example-job\n</span></span></code></pre></div><p>The output should be:</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">Hello, world!\n</code></pre><p>Note that the volume already contained a text file with the string contents from\nthe CR. This is only the simplest example. Actual populators can set up the volume\nto contain arbitrary contents.</p>\n<h2 id=\"how-to-write-your-own-volume-populator\">How to write your own volume populator</h2>\n<p>Developers interested in writing new poplators are encouraged to use the\n<a href=\"https://github.com/kubernetes-csi/lib-volume-populator\">lib-volume-populator</a> library\nand to only supply a small controller wrapper around the library, and a pod image\ncapable of attaching to volumes and writing the appropriate data to the volume.</p>\n<p>Individual populators can be extremely generic such that they work with every type\nof PVC, or they can do vendor specific things to rapidly fill a volume with data\nif the volume was provisioned by a specific CSI driver from the same vendor, for\nexample, by communicating directly with the storage for that volume.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>The enhancement proposal,\n<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/1495-volume-populators\">Volume Populators</a>, includes lots of detail about the history and technical implementation\nof this feature.</p>\n<p><a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#volume-populators-and-data-sources\">Volume populators and data sources</a>, within the documentation topic about persistent volumes,\nexplains how to use this feature in your cluster.</p>\n<p>Please get involved by joining the Kubernetes storage SIG to help us enhance this\nfeature. There are a lot of good ideas already and we'd be thrilled to have more!</p>","PublishedAt":"2022-05-16 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/05/16/volume-populators-beta/","SourceName":"Kubernetes"}},{"node":{"ID":1054,"Title":"Detection Engineering and SOAR at Mercari","Description":"<p>This article is part of the Security Tech Blog Series: Spring Cleaning for Security, brought to you by David from the Security Engineering team. We hope this article can provide you with some useful pointers to kickstart your journey in threat detection, and get familiar with Mercari’s own SOC (security operations center) initiatives. Introduction In [&hellip;]</p>\n","PublishedAt":"2022-05-13 21:52:08+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20220513-detection-engineering-and-soar-at-mercari/","SourceName":"Mercari"}},{"node":{"ID":179,"Title":"Fine-Tune Fair to Capacity Scheduler in Relative Mode","Description":"<p>How to fine-tune CDP Capacity Scheduler configs in relative mode after fs2cs migration</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/fine-tune-fair-to-capacity-scheduler-in-relative-mode/\">Fine-Tune Fair to Capacity Scheduler in Relative Mode</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-05-13 15:00:14+00:00","OriginURL":"https://blog.cloudera.com/fine-tune-fair-to-capacity-scheduler-in-relative-mode/","SourceName":"Cloudera"}},{"node":{"ID":1220,"Title":"Blog: Kubernetes 1.24: gRPC container probes in beta","Description":"<p><strong>Author</strong>: Sergey Kanzhelev (Google)</p>\n<p>With Kubernetes 1.24 the gRPC probes functionality entered beta and is available by default.\nNow you can configure startup, liveness, and readiness probes for your gRPC app\nwithout exposing any HTTP endpoint, nor do you need an executable. Kubernetes can natively connect to your your workload via gRPC and query its status.</p>\n<h2 id=\"some-history\">Some history</h2>\n<p>It's useful to let the system managing your workload check that the app is\nhealthy, has started OK, and whether the app considers itself good to accept\ntraffic. Before the gRPC support was added, Kubernetes already allowed you to\ncheck for health based on running an executable from inside the container image,\nby making an HTTP request, or by checking whether a TCP connection succeeded.</p>\n<p>For most apps, those checks are enough. If your app provides a gRPC endpoint\nfor a health (or readiness) check, it is easy\nto repurpose the <code>exec</code> probe to use it for gRPC health checking.\nIn the blog article <a href=\"https://kubernetes.io/blog/2018/10/01/health-checking-grpc-servers-on-kubernetes/\">Health checking gRPC servers on Kubernetes</a>,\nAhmet Alp Balkan described how you can do that — a mechanism that still works today.</p>\n<p>There is a commonly used tool to enable this that was <a href=\"https://github.com/grpc-ecosystem/grpc-health-probe/commit/2df4478982e95c9a57d5fe3f555667f4365c025d\">created</a>\non August 21, 2018, and with\nthe first release at <a href=\"https://github.com/grpc-ecosystem/grpc-health-probe/releases/tag/v0.1.0-alpha.1\">Sep 19, 2018</a>.</p>\n<p>This approach for gRPC apps health checking is very popular. There are <a href=\"https://github.com/search?l=Dockerfile&amp;q=grpc_health_probe&amp;type=code\">3,626 Dockerfiles</a>\nwith the <code>grpc_health_probe</code> and <a href=\"https://github.com/search?l=YAML&amp;q=grpc_health_probe&amp;type=Code\">6,621 yaml</a> files that are discovered with the\nbasic search on GitHub (at the moment of writing). This is good indication of the tool popularity\nand the need to support this natively.</p>\n<p>Kubernetes v1.23 introduced an alpha-quality implementation of native support for\nquerying a workload status using gRPC. Because it was an alpha feature,\nthis was disabled by default for the v1.23 release.</p>\n<h2 id=\"using-the-feature\">Using the feature</h2>\n<p>We built gRPC health checking in similar way with other probes and believe\nit will be <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-grpc-liveness-probe\">easy to use</a>\nif you are familiar with other probe types in Kubernetes.\nThe natively supported health probe has many benefits over the workaround involving <code>grpc_health_probe</code> executable.</p>\n<p>With the native gRPC support you don't need to download and carry <code>10MB</code> of an additional executable with your image.\nExec probes are generally slower than a gRPC call as they require instantiating a new process to run an executable.\nIt also makes the checks less sensible for edge cases when the pod is running at maximum resources and has troubles\ninstantiating new processes.</p>\n<p>There are a few limitations though. Since configuring a client certificate for probes is hard,\nservices that require client authentication are not supported. The built-in probes are also\nnot checking the server certificates and ignore related problems.</p>\n<p>Built-in checks also cannot be configured to ignore certain types of errors\n(<code>grpc_health_probe</code> returns different exit codes for different errors),\nand cannot be &quot;chained&quot; to run the health check on multiple services in a single probe.</p>\n<p>But all these limitations are quite standard for gRPC and there are easy workarounds\nfor those.</p>\n<h2 id=\"try-it-for-yourself\">Try it for yourself</h2>\n<h3 id=\"cluster-level-setup\">Cluster-level setup</h3>\n<p>You can try this feature today. To try native gRPC probes, you can spin up a Kubernetes cluster\nyourself with the <code>GRPCContainerProbe</code> feature gate enabled, there are many <a href=\"https://kubernetes.io/docs/tasks/tools/\">tools available</a>.</p>\n<p>Since the feature gate <code>GRPCContainerProbe</code> is enabled by default in 1.24,\nmany vendors will have this functionality working out of the box.\nSo you may just create an 1.24 cluster on platform of your choice. Some vendors\nallow to enable alpha features on 1.23 clusters.</p>\n<p>For example, at the moment of writing, you can spin up the test cluster on GKE for a quick test.\nOther vendors may also have similar capabilities, especially if you\nare reading this blog post long after the Kubernetes 1.24 release.</p>\n<p>On GKE use the following command (note, version is <code>1.23</code> and <code>enable-kubernetes-alpha</code> are specified).</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>gcloud container clusters create test-grpc <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> --enable-kubernetes-alpha <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> --no-enable-autorepair <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> --no-enable-autoupgrade <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> --release-channel<span style=\"color:#666\">=</span>rapid <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> --cluster-version<span style=\"color:#666\">=</span>1.23\n</span></span></code></pre></div><p>You will also need to configure <code>kubectl</code> to access the cluster:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>gcloud container clusters get-credentials test-grpc\n</span></span></code></pre></div><h3 id=\"trying-the-feature-out\">Trying the feature out</h3>\n<p>Let's create the pod to test how gRPC probes work. For this test we will use the <code>agnhost</code> image.\nThis is a k8s maintained image with that can be used for all sorts of workload testing.\nFor example, it has a useful <a href=\"https://github.com/kubernetes/kubernetes/blob/b2c5bd2a278288b5ef19e25bf7413ecb872577a4/test/images/agnhost/README.md#grpc-health-checking\">grpc-health-checking</a> module\nthat exposes two ports - one is serving health checking service,\nanother - http port to react on commands <code>make-serving</code> and <code>make-not-serving</code>.</p>\n<p>Here is an example pod definition. It starts the <code>grpc-health-checking</code> module,\nexposes ports <code>5000</code> and <code>8080</code>, and configures gRPC readiness probe:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#00f;font-weight:bold\">---</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-grpc<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">containers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>agnhost<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>k8s.gcr.io/e2e-test-images/agnhost:2.35<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">command</span>:<span style=\"color:#bbb\"> </span>[<span style=\"color:#b44\">&#34;/agnhost&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;grpc-health-checking&#34;</span>]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ports</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">containerPort</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">5000</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">containerPort</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">8080</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">readinessProbe</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">grpc</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">5000</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>If the file called <code>test.yaml</code>, you can create the pod and check it's status.\nThe pod will be in ready state as indicated by the snippet of the output.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl apply -f test.yaml\n</span></span><span style=\"display:flex;\"><span>kubectl describe test-grpc\n</span></span></code></pre></div><p>The output will contain something like this:</p>\n<pre tabindex=\"0\"><code>Conditions:\nType Status\nInitialized True\nReady True\nContainersReady True\nPodScheduled True\n</code></pre><p>Now let's change the health checking endpoint status to NOT_SERVING.\nIn order to call the http port of the Pod, let's create a port forward:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl port-forward test-grpc 8080:8080\n</span></span></code></pre></div><p>You can <code>curl</code> to call the command...</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>curl http://localhost:8080/make-not-serving\n</span></span></code></pre></div><p>... and in a few seconds the port status will switch to not ready.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl describe pod test-grpc\n</span></span></code></pre></div><p>The output now will have:</p>\n<pre tabindex=\"0\"><code>Conditions:\nType Status\nInitialized True\nReady False\nContainersReady False\nPodScheduled True\n...\nWarning Unhealthy 2s (x6 over 42s) kubelet Readiness probe failed: service unhealthy (responded with &#34;NOT_SERVING&#34;)\n</code></pre><p>Once it is switched back, in about one second the Pod will get back to ready status:</p>\n<pre tabindex=\"0\"><code class=\"language-bsh\" data-lang=\"bsh\">curl http://localhost:8080/make-serving\nkubectl describe test-grpc\n</code></pre><p>The output indicates that the Pod went back to being <code>Ready</code>:</p>\n<pre tabindex=\"0\"><code>Conditions:\nType Status\nInitialized True\nReady True\nContainersReady True\nPodScheduled True\n</code></pre><p>This new built-in gRPC health probing on Kubernetes makes implementing a health-check via gRPC\nmuch easier than the older approach that relied on using a separate <code>exec</code> probe. Read through\nthe official\n<a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-grpc-liveness-probe\">documentation</a>\nto learn more and provide feedback before the feature will be promoted to GA.</p>\n<h2 id=\"summary\">Summary</h2>\n<p>Kubernetes is a popular workload orchestration platform and we add features based on feedback and demand.\nFeatures like gRPC probes support is a minor improvement that will make life of many app developers\neasier and apps more resilient. Try it today and give feedback, before the feature went into GA.</p>","PublishedAt":"2022-05-13 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/05/13/grpc-probes-now-in-beta/","SourceName":"Kubernetes"}},{"node":{"ID":448,"Title":"Ask an expert: Getting users to an ‘aha’ moment—fast","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2022/05/AskAnExpert-PulkitAgrawal-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>When you&#8217;re poking around inside of a new app, there&#8217;s no better feeling than finally getting it up and running and seeing firsthand how it can be useful to you. This is called an &#8220;aha&#8221; moment, and it&#8217;s something that all product leaders should be working toward getting their users to as fast as possible.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/getting-to-the-aha-moment-fast/\">Ask an expert: Getting users to an &#8216;aha&#8217; moment—fast</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2022-05-12 20:49:16+00:00","OriginURL":"https://mixpanel.com/blog/getting-to-the-aha-moment-fast/","SourceName":"Mixpanel"}},{"node":{"ID":505,"Title":"Improving Distributed Caching Performance and Efficiency at Pinterest","Description":"","PublishedAt":"2022-05-12 18:11:47+00:00","OriginURL":"https://medium.com/pinterest-engineering/improving-distributed-caching-performance-and-efficiency-at-pinterest-92484b5fe39b?source=rss----4c5a5f6279b6---4","SourceName":"Pinterest"}},{"node":{"ID":403,"Title":"What are we optimizing for?","Description":"","PublishedAt":"2022-05-12 14:03:20+00:00","OriginURL":"https://medium.com/paypal-tech/what-are-we-optimizing-for-78583958701b?source=rss----6423323524ba---4","SourceName":"Paypal"}},{"node":{"ID":1055,"Title":"Improving the engineer experience","Description":"<p>This article is a translation of the Japanese article written on December 16, 2020. I’m yhanada from the Merpay Android Team, and I&#8217;m responsible for day 16 of Merpay Advent Calendar 2020. I&#8217;ve worked as a Mercari/Merpay Android engineer for four years as of this December. In addition to my normal team role developing features, [&hellip;]</p>\n","PublishedAt":"2022-05-12 11:00:16+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20201216-merpay-android-dex/","SourceName":"Mercari"}},{"node":{"ID":9,"Title":"My Journey to Airbnb — Kamini Dandapani","Description":"","PublishedAt":"2022-05-11 19:35:36+00:00","OriginURL":"https://medium.com/airbnb-engineering/my-journey-to-airbnb-kamini-dandapani-7f51f1fbb2bb?source=rss----53c7c27702d5---4","SourceName":"Airbnb"}},{"node":{"ID":540,"Title":"Delivering the ultimate Tinder Swipe Night experience by leveraging personalization at scale","Description":"","PublishedAt":"2022-05-11 18:38:36+00:00","OriginURL":"https://medium.com/tinder/delivering-the-ultimate-tinder-swipe-night-experience-by-leveraging-personalization-at-scale-e128ead42957?source=rss----906928af8599---4","SourceName":"Tinder"}},{"node":{"ID":1056,"Title":"Running distributed testing to reduce testing time","Description":"<p>* This article is a translation of the Japanese article written on December 6, 2021. Introduction Hello! I&#8217;m @goccy, from Merpay’s Architect Team. In this article, I would like to introduce a tool developed to accelerate our daily integration testing between microservices. Integration testing between microservices @zoncoen has written here in detail about our integration [&hellip;]</p>\n","PublishedAt":"2022-05-11 11:00:49+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211206-5aa2ac7efc/","SourceName":"Mercari"}},{"node":{"ID":737,"Title":"Stripe Tax is available for more businesses","Description":"Stripe Tax can now be added to all Stripe Payments integrations to automatically calculate and collect sales tax, VAT, and GST via the new Orders API.","PublishedAt":"2022-05-10 00:00:00+00:00","OriginURL":"https://stripe.com/docs/orders","SourceName":"Stripe"}}]}},"pageContext":{"limit":30,"skip":4800,"numPages":193,"currentPage":161}},"staticQueryHashes":["3649515864"]}