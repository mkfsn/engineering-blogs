{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/78","result":{"data":{"allPost":{"edges":[{"node":{"ID":3449,"Title":"ChatGPT and Elasticsearch: OpenAI meets private data","Description":"","PublishedAt":"2023-04-19 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/chatgpt-elasticsearch-openai-meets-private-data","SourceName":"Elastic"}},{"node":{"ID":3443,"Title":"Datadog Expands Application Security Capabilities to Automatically Uncover Vulnerabilities in Production Code","Description":"NEW YORK &ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the general availability of Application Vulnerability Management, which expands Datadog&rsquo;s application security capabilities by automatically uncovering and prioritizing the most important vulnerabilities in open-source libraries.According to Forrester, open-source code makes up at least 70% of all software. While open-source libraries accelerate software delivery, they increase security risk if the vulnerabilities associated with them are not well understood.","PublishedAt":"2023-04-18 20:05:23+00:00","OriginURL":"https://www.datadoghq.com/about/latest-news/press-releases/datadog-expands-application-security-capabilities-to-automatically-uncover-vulnerabilities-in-production-code/","SourceName":"Datadog"}},{"node":{"ID":3445,"Title":"Identifying vulnerabilities in GitHub Actions & AWS OIDC Configurations","Description":"","PublishedAt":"2023-04-18 19:57:43+00:00","OriginURL":"https://medium.com/tinder/identifying-vulnerabilities-in-github-actions-aws-oidc-configurations-8067c400d5b8?source=rss----906928af8599---4","SourceName":"Tinder"}},{"node":{"ID":3444,"Title":"Blog: Kubernetes 1.27: Efficient SELinux volume relabeling (Beta)","Description":"<p><strong>Author:</strong> Jan Šafránek (Red Hat)</p>\n<h1 id=\"the-problem\">The problem</h1>\n<p>On Linux with Security-Enhanced Linux (SELinux) enabled, it's traditionally\nthe container runtime that applies SELinux labels to a Pod and all its volumes.\nKubernetes only passes the SELinux label from a Pod's <code>securityContext</code> fields\nto the container runtime.</p>\n<p>The container runtime then recursively changes SELinux label on all files that\nare visible to the Pod's containers. This can be time-consuming if there are\nmany files on the volume, especially when the volume is on a remote filesystem.</p>\n<div class=\"alert alert-info\" role=\"alert\">\n<h4 class=\"alert-heading\">Note</h4>\nIf a container uses <code>subPath</code> of a volume, only that <code>subPath</code> of the whole\nvolume is relabeled. This allows two pods that have two different SELinux labels\nto use the same volume, as long as they use different subpaths of it.\n</div>\n<p>If a Pod does not have any SELinux label assigned in Kubernetes API, the\ncontainer runtime assigns a unique random one, so a process that potentially\nescapes the container boundary cannot access data of any other container on the\nhost. The container runtime still recursively relabels all pod volumes with this\nrandom SELinux label.</p>\n<h1 id=\"improvement-using-mount-options\">Improvement using mount options</h1>\n<p>If a Pod and its volume meet <strong>all</strong> of the following conditions, Kubernetes will\n<em>mount</em> the volume directly with the right SELinux label. Such mount will happen\nin a constant time and the container runtime will not need to recursively\nrelabel any files on it.</p>\n<ol>\n<li>\n<p>The operating system must support SELinux.</p>\n<p>Without SELinux support detected, kubelet and the container runtime do not\ndo anything with regard to SELinux.</p>\n</li>\n<li>\n<p>The <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gates</a>\n<code>ReadWriteOncePod</code> and <code>SELinuxMountReadWriteOncePod</code> must be enabled.\nThese feature gates are Beta in Kubernetes 1.27 and Alpha in 1.25.</p>\n<p>With any of these feature gates disabled, SELinux labels will be always\napplied by the container runtime by a recursive walk through the volume\n(or its subPaths).</p>\n</li>\n<li>\n<p>The Pod must have at least <code>seLinuxOptions.level</code> assigned in its <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context\">Pod Security Context</a> or all Pod containers must have it set in their <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-1\">Security Contexts</a>.\nKubernetes will read the default <code>user</code>, <code>role</code> and <code>type</code> from the operating\nsystem defaults (typically <code>system_u</code>, <code>system_r</code> and <code>container_t</code>).</p>\n<p>Without Kubernetes knowing at least the SELinux <code>level</code>, the container\nruntime will assign a random one <em>after</em> the volumes are mounted. The\ncontainer runtime will still relabel the volumes recursively in that case.</p>\n</li>\n<li>\n<p>The volume must be a Persistent Volume with\n<a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes\">Access Mode</a>\n<code>ReadWriteOncePod</code>.</p>\n<p>This is a limitation of the initial implementation. As described above,\ntwo Pods can have a different SELinux label and still use the same volume,\nas long as they use a different <code>subPath</code> of it. This use case is not\npossible when the volumes are <em>mounted</em> with the SELinux label, because the\nwhole volume is mounted and most filesystems don't support mounting a single\nvolume multiple times with multiple SELinux labels.</p>\n<p>If running two Pods with two different SELinux contexts and using\ndifferent <code>subPaths</code> of the same volume is necessary in your deployments,\nplease comment in the <a href=\"https://github.com/kubernetes/enhancements/issues/1710\">KEP</a>\nissue (or upvote any existing comment - it's best not to duplicate).\nSuch pods may not run when the feature is extended to cover all volume access modes.</p>\n</li>\n<li>\n<p>The volume plugin or the CSI driver responsible for the volume supports\nmounting with SELinux mount options.</p>\n<p>These in-tree volume plugins support mounting with SELinux mount options:\n<code>fc</code>, <code>iscsi</code>, and <code>rbd</code>.</p>\n<p>CSI drivers that support mounting with SELinux mount options must announce\nthat in their\n<a href=\"https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/csi-driver-v1/\">CSIDriver</a>\ninstance by setting <code>seLinuxMount</code> field.</p>\n<p>Volumes managed by other volume plugins or CSI drivers that don't\nset <code>seLinuxMount: true</code> will be recursively relabelled by the container\nruntime.</p>\n</li>\n</ol>\n<h2 id=\"mounting-with-selinux-context\">Mounting with SELinux context</h2>\n<p>When all aforementioned conditions are met, kubelet will\npass <code>-o context=&lt;SELinux label&gt;</code> mount option to the volume plugin or CSI\ndriver. CSI driver vendors must ensure that this mount option is supported\nby their CSI driver and, if necessary, the CSI driver appends other mount\noptions that are needed for <code>-o context</code> to work.</p>\n<p>For example, NFS may need <code>-o context=&lt;SELinux label&gt;,nosharecache</code>, so each\nvolume mounted from the same NFS server can have a different SELinux label\nvalue. Similarly, CIFS may need <code>-o context=&lt;SELinux label&gt;,nosharesock</code>.</p>\n<p>It's up to the CSI driver vendor to test their CSI driver in a SELinux enabled\nenvironment before setting <code>seLinuxMount: true</code> in the CSIDriver instance.</p>\n<h1 id=\"how-can-i-learn-more\">How can I learn more?</h1>\n<p>SELinux in containers: see excellent\n<a href=\"https://opensource.com/business/13/11/selinux-policy-guide\">visual SELinux guide</a>\nby Daniel J Walsh. Note that the guide is older than Kubernetes, it describes\n<em>Multi-Category Security</em> (MCS) mode using virtual machines as an example,\nhowever, a similar concept is used for containers.</p>\n<p>See a series of blog posts for details how exactly SELinux is applied to\ncontainers by container runtimes:</p>\n<ul>\n<li><a href=\"https://www.redhat.com/en/blog/how-selinux-separates-containers-using-multi-level-security\">How SELinux separates containers using Multi-Level Security</a></li>\n<li><a href=\"https://www.redhat.com/en/blog/why-you-should-be-using-multi-category-security-your-linux-containers\">Why you should be using Multi-Category Security for your Linux containers</a></li>\n</ul>\n<p>Read the KEP: <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/1710-selinux-relabeling\">Speed up SELinux volume relabeling using mounts</a></p>","PublishedAt":"2023-04-18 18:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/","SourceName":"Kubernetes"}},{"node":{"ID":3439,"Title":"Building a Flink Self-Serve Platform on Kubernetes at Scale","Description":"","PublishedAt":"2023-04-18 17:21:02+00:00","OriginURL":"https://tech.instacart.com/building-a-flink-self-serve-platform-on-kubernetes-at-scale-c11ef19aef10?source=rss----587883b5d2ee---4","SourceName":"Instacart"}},{"node":{"ID":3442,"Title":"What’s happening at KubeCon Europe 2023","Description":"Attending KubeCon EU, either in person or online? Check out what HashiCorp is doing and talking about at the event, and learn about recent Kubernetes-related product features.","PublishedAt":"2023-04-18 17:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/what-s-happening-at-kubecon-europe-2023","SourceName":"HashiCorp"}},{"node":{"ID":3438,"Title":"CDK for Terraform 0.16 improves automatic HCL conversion","Description":"CDK for Terraform v0.16 improves automatic conversion of configuration code from HCL to supported languages by enabling type coercion and providing better support for iterators and functions.","PublishedAt":"2023-04-18 16:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/cdk-for-terraform-0-16-improves-automatic-hcl-conversion","SourceName":"HashiCorp"}},{"node":{"ID":3440,"Title":"Scaling Salt for Remote Execution to support LinkedIn Infra growth","Description":"At LinkedIn, site engineers like to automate operational tasks at various infrastructure layers to minimize manual interventions, which can scale well and be easy to operate. Certain automations are performed via onDemand job executions. LinkedIn engineers have been using Salt, a Python-based, open source software, for executing tasks on hosts for more than a decade now, due to its high performance and pluggability. Because it comes with a rich set of execution modules which can be used directly or within custom modules, it works well for tasks such as OS upgrades, auto remediations [&#8230;]","PublishedAt":"2023-04-18 15:00:00+00:00","OriginURL":"https://engineering.linkedin.com/blog/2023/scaling-salt-for-remote-execution-to-support-linkedin-infra-grow","SourceName":"Linkedin"}},{"node":{"ID":3499,"Title":"Scaling Salt for Remote Execution to support LinkedIn Infra growth","Description":"At LinkedIn, site engineers like to automate operational tasks at various infrastructure layers to minimize manual interventions, which can scale well and be easy to operate. Certain automations are performed via onDemand job executions. LinkedIn engineers have been using Salt, a Python-based, open source software, for executing tasks on hosts for more than a decade now, due to its high performance and pluggability. Because it comes with a rich set of execution modules which can be used directly or within custom modules, it works well for tasks such as OS upgrades, auto remediations [&#8230;]","PublishedAt":"2023-04-18 15:00:00+00:00","OriginURL":"https://engineering.linkedin.com/content/engineering/en-us/blog/2023/scaling-salt-for-remote-execution-to-support-linkedin-infra-grow","SourceName":"Linkedin"}},{"node":{"ID":3455,"Title":"We bought a university: how one coding school doubled down on brick and mortar (Ep. 561)","Description":"<p>Paulo and Guilherme Silveira, brothers and cofounders of edtech platform Alura, join the home team for a conversation about polyglot programming, edtech, and the role of generative AI.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2023/04/18/we-bought-a-university-how-one-coding-school-doubled-down-on-brick-and-mortar-ep-555/\">We bought a university: how one coding school doubled down on brick and mortar (Ep. 561)</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2023-04-18 14:40:28+00:00","OriginURL":"https://stackoverflow.blog/2023/04/18/we-bought-a-university-how-one-coding-school-doubled-down-on-brick-and-mortar-ep-555/","SourceName":"Stack Overflow"}},{"node":{"ID":3435,"Title":"Apple Pay Integration Options with PayPal","Description":"","PublishedAt":"2023-04-18 13:11:06+00:00","OriginURL":"https://medium.com/paypal-tech/apple-pay-integration-options-with-paypal-75456ee61f25?source=rss----6423323524ba---4","SourceName":"Paypal"}},{"node":{"ID":3436,"Title":"Introducing Communities on Teams: where domain, practice, and community come together with purpose","Description":"<p>Communities on Teams is a new way to bring people and knowledge together within a specific topic or focus to share valuable resources and collaborate in meaningful ways.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2023/04/18/introducing-communities-on-teams-where-domain-practice-and-community-come-together-with-purpose/\">Introducing Communities on Teams: where domain, practice, and community come together with purpose</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2023-04-18 13:05:08+00:00","OriginURL":"https://stackoverflow.blog/2023/04/18/introducing-communities-on-teams-where-domain-practice-and-community-come-together-with-purpose/","SourceName":"Stack Overflow"}},{"node":{"ID":3432,"Title":"Consent management made easy and clear with Cloudflare Zaraz","Description":"Cloudflare Zaraz now can also help you with gathering and managing consent. With this new tool, you can easily collect user’s consent preferences on your website, using a consent modal, and apply your consent policy on third-party tools you load via Cloudflare Zaraz","PublishedAt":"2023-04-18 13:01:00+00:00","OriginURL":"https://blog.cloudflare.com/consent-manager/","SourceName":"Cloudflare"}},{"node":{"ID":3550,"Title":"Consent management made easy and clear with Cloudflare Zaraz","Description":"Cloudflare Zaraz now can also help you with gathering and managing consent. With this new tool, you can easily collect user’s consent preferences on your website, using a consent modal, and apply your consent policy on third-party tools you load via Cloudflare Zaraz","PublishedAt":"2023-04-18 13:01:00+00:00","OriginURL":"http://blog.cloudflare.com/consent-manager/","SourceName":"Cloudflare"}},{"node":{"ID":3433,"Title":"Measuring network quality to better understand the end-user experience","Description":"Starting today, you don’t have to be a network engineer to figure out what your Internet is good for. Let’s tell you how we’re doing it.","PublishedAt":"2023-04-18 13:00:00+00:00","OriginURL":"https://blog.cloudflare.com/aim-database-for-internet-quality/","SourceName":"Cloudflare"}},{"node":{"ID":3434,"Title":"Making home Internet faster has little to do with “speed”","Description":"The speed of an Internet connection is more about decreasing real-world latency than adding underutilized bandwidth","PublishedAt":"2023-04-18 13:00:00+00:00","OriginURL":"https://blog.cloudflare.com/making-home-internet-faster/","SourceName":"Cloudflare"}},{"node":{"ID":3551,"Title":"Making home Internet faster has little to do with “speed”","Description":"The speed of an Internet connection is more about decreasing real-world latency than adding underutilized bandwidth","PublishedAt":"2023-04-18 13:00:00+00:00","OriginURL":"http://blog.cloudflare.com/making-home-internet-faster/","SourceName":"Cloudflare"}},{"node":{"ID":3552,"Title":"Measuring network quality to better understand the end-user experience","Description":"Starting today, you don’t have to be a network engineer to figure out what your Internet is good for. Let’s tell you how we’re doing it.","PublishedAt":"2023-04-18 13:00:00+00:00","OriginURL":"http://blog.cloudflare.com/aim-database-for-internet-quality/","SourceName":"Cloudflare"}},{"node":{"ID":3431,"Title":"Audio Accessibility in Miro: A Hackathon Story in 3 Acts","Description":"","PublishedAt":"2023-04-18 07:27:26+00:00","OriginURL":"https://medium.com/miro-engineering/audio-accessibility-in-miro-a-hackathon-story-in-3-acts-c65e31e10de1?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":3429,"Title":"Elastic Common Schema and OpenTelemetry — A path to better observability and security with no vendor lock-in","Description":"","PublishedAt":"2023-04-18 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/ecs-elastic-common-schema-otel-opentelemetry-faq","SourceName":"Elastic"}},{"node":{"ID":3430,"Title":"Elastic contributes Elastic Common Schema (ECS) to OpenTelemetry (OTel), helping accelerate adoption of OTel-based observability and security","Description":"","PublishedAt":"2023-04-18 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/ecs-elastic-common-schema-otel-opentelemetry-announcement","SourceName":"Elastic"}},{"node":{"ID":3437,"Title":"Automate common security tasks and stay ahead of threats with Datadog Workflows and Cloud SIEM","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/automate-security-tasks-with-workflows-and-cloud-siem/hero-r2.png\" width=\"100%\"/>Detecting and remediating security threats is a constantly evolving concern for modern DevSecOps and security operations center (SOC) teams. Moreover, manually investigating and responding to vulnerabilities and threats is time-consuming, laborious, and knowledge-intensive. Datadog Workflows, which is now available in the Service Management and Integrations menus, can be used in concert with Cloud SIEM to automate repetitive security tasks—such as triaging security signals or detecting emerging vulnerabilities.Using Datadog Cloud SIEM and Workflows together reduces the burden on security engineers, allowing them to focus on more complex tasks, and helps teams stay ahead of novel threats by automating the classification of emerging vulnerabilities.","PublishedAt":"2023-04-18 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/automate-security-tasks-with-workflows-and-cloud-siem/","SourceName":"Datadog"}},{"node":{"ID":3441,"Title":"Proactively track, triage, and assign issues with Datadog Case Management","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/track-issues-datadog-case-management/case-management_feature-announcement.png\" width=\"100%\"/>Complex systems require many different monitors to assess the health of their infrastructure and applications, creating a wealth of alerts that can be hard to track. Due to a lack of effective triage processes, many organizations page engineers for every alert that comes in, making it difficult to separate false positives from issues that actually require immediate attention. In an ideal system, on-call engineers would be paged only for major incidents, and issues that don’t have any urgent customer impact could be left to longer-term investigations.","PublishedAt":"2023-04-18 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/track-issues-datadog-case-management/","SourceName":"Datadog"}},{"node":{"ID":3428,"Title":"AWS Week in Review: New Service for Generative AI and Amazon EC2 Trn1n, Inf2, and CodeWhisperer now GA – April 17, 2023","Description":"I could almost title this blog post the “AWS AI/ML Week in Review.” This past week, we announced several new innovations and tools for building with generative AI on AWS. Let’s dive right into it. Last Week’s Launches Here are some launches that got my attention during the previous week: Announcing Amazon Bedrock and Amazon […]","PublishedAt":"2023-04-17 19:12:09+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/aws-week-in-review-new-service-for-generative-ai-and-amazon-ec2-trn1n-inf2-and-codewhisperer-now-ga-april-17-2023/","SourceName":"AWS"}},{"node":{"ID":3423,"Title":"A fine-grained network traffic analysis with Millisampler","Description":"<p>What the research is:  Millisampler is one of Meta’s latest characterization tools and allows us to observe, characterize, and debug network performance at high-granularity timescales efficiently. This lightweight network traffic characterization tool for continual monitoring operates at fine, configurable timescales. It collects time series of ingress and egress traffic volumes, number of active flows, incoming [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2023/04/17/networking-traffic/millisampler-network-traffic-analysis/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2023/04/17/networking-traffic/millisampler-network-traffic-analysis/\">A fine-grained network traffic analysis with Millisampler</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n","PublishedAt":"2023-04-17 16:15:48+00:00","OriginURL":"https://engineering.fb.com/2023/04/17/networking-traffic/millisampler-network-traffic-analysis/","SourceName":"Facebook"}},{"node":{"ID":3469,"Title":"Organizing a Successful Internal Hackathon: Mercari Hack Fest Spring 2023","Description":"<p>Hello! I am afroscript from the Mercari Engineering Office. Since September 2019, Mercari has been regularly organizing a biannual internal technology festival for its engineers called “Hack Fest.” We are currently in the process of preparing the 7th Hack Fest, which will take place from April 19 to April 21, 2023. We have been gradually [&hellip;]</p>\n","PublishedAt":"2023-04-17 16:00:22+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20230410-b286fe9577/","SourceName":"Mercari"}},{"node":{"ID":3426,"Title":"Community is the future of AI","Description":"<p>To keep knowledge open and accessible to all, we must come together to build the future of AI.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2023/04/17/community-is-the-future-of-ai/\">Community is the future of AI</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2023-04-17 15:00:42+00:00","OriginURL":"https://stackoverflow.blog/2023/04/17/community-is-the-future-of-ai/","SourceName":"Stack Overflow"}},{"node":{"ID":3425,"Title":"Preventing insecure deserialization in Node.js","Description":"This article demonstrates how to patch deserialization vulnerabilities in Node.js. We’ll create vulnerable code, demonstrate an attack, and then fix the vulnerabilities.","PublishedAt":"2023-04-17 14:00:00+00:00","OriginURL":"https://snyk.io/blog/preventing-insecure-deserialization-node-js","SourceName":"Snyk"}},{"node":{"ID":3470,"Title":"Model management for client side ML powered by Firebase","Description":"<p>Hi everyone! I am Rakesh from the Mercari’s Seller Engagement team. Recently I had the opportunity to mentor an Intern at Mercari. His name is Priyansh and this article summarizes part of his work on using Firebase for client side machine learning models. Introduction The availability of huge data, advances in powerful processing and storage, [&hellip;]</p>\n","PublishedAt":"2023-04-17 13:00:42+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20230417-model-management-for-client-side-ml-powered-by-firebase/","SourceName":"Mercari"}},{"node":{"ID":3419,"Title":"Blog: Kubernetes 1.27: More fine-grained pod topology spread policies reached beta","Description":"<p><strong>Authors:</strong> <a href=\"https://github.com/denkensk\">Alex Wang</a> (Shopee), <a href=\"https://github.com/kerthcet\">Kante Yin</a> (DaoCloud), <a href=\"https://github.com/sanposhiho\">Kensei Nakada</a> (Mercari)</p>\n<p>In Kubernetes v1.19, <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\">Pod topology spread constraints</a>\nwent to general availability (GA).</p>\n<p>As time passed, we - SIG Scheduling - received feedback from users,\nand, as a result, we're actively working on improving the Topology Spread feature via three KEPs.\nAll of these features have reached beta in Kubernetes v1.27 and are enabled by default.</p>\n<p>This blog post introduces each feature and the use case behind each of them.</p>\n<h2 id=\"kep-3022-min-domains-in-pod-topology-spread\">KEP-3022: min domains in Pod Topology Spread</h2>\n<p>Pod Topology Spread has the <code>maxSkew</code> parameter to define the degree to which Pods may be unevenly distributed.</p>\n<p>But, there wasn't a way to control the number of domains over which we should spread.\nSome users want to force spreading Pods over a minimum number of domains, and if there aren't enough already present, make the cluster-autoscaler provision them.</p>\n<p>Kubernetes v1.24 introduced the <code>minDomains</code> parameter for pod topology spread constraints,\nas an alpha feature.\nVia <code>minDomains</code> parameter, you can define the minimum number of domains.</p>\n<p>For example, assume there are 3 Nodes with the enough capacity,\nand a newly created ReplicaSet has the following <code>topologySpreadConstraints</code> in its Pod template.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#00f;font-weight:bold\">...</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">topologySpreadConstraints</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span>- <span style=\"color:#008000;font-weight:bold\">maxSkew</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">1</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">minDomains</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">5</span><span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># requires 5 Nodes at least (because each Node has a unique hostname).</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">whenUnsatisfiable</span>:<span style=\"color:#bbb\"> </span>DoNotSchedule<span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># minDomains is valid only when DoNotSchedule is used.</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">topologyKey</span>:<span style=\"color:#bbb\"> </span>kubernetes.io/hostname<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">labelSelector</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">matchLabels</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">foo</span>:<span style=\"color:#bbb\"> </span>bar<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>In this case, 3 Pods will be scheduled to those 3 Nodes,\nbut other 2 Pods from this replicaset will be unschedulable until more Nodes join the cluster.</p>\n<p>You can imagine that the cluster autoscaler provisions new Nodes based on these unschedulable Pods,\nand as a result, the replicas are finally spread over 5 Nodes.</p>\n<h2 id=\"kep-3094-take-taints-tolerations-into-consideration-when-calculating-podtopologyspread-skew\">KEP-3094: Take taints/tolerations into consideration when calculating podTopologySpread skew</h2>\n<p>Before this enhancement, when you deploy a pod with <code>podTopologySpread</code> configured, kube-scheduler would\ntake the Nodes that satisfy the Pod's nodeAffinity and nodeSelector into consideration\nin filtering and scoring, but would not care about whether the node taints are tolerated by the incoming pod or not.\nThis may lead to a node with untolerated taint as the only candidate for spreading, and as a result,\nthe pod will stuck in Pending if it doesn't tolerate the taint.</p>\n<p>To allow more fine-gained decisions about which Nodes to account for when calculating spreading skew,\nKubernetes 1.25 introduced two new fields within <code>topologySpreadConstraints</code> to define node inclusion policies:\n<code>nodeAffinityPolicy</code> and <code>nodeTaintPolicy</code>.</p>\n<p>A manifest that applies these policies looks like the following:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># Configure a topology spread constraint</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">topologySpreadConstraints</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">maxSkew</span>:<span style=\"color:#bbb\"> </span>&lt;integer&gt;<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># ...</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">nodeAffinityPolicy</span>:<span style=\"color:#bbb\"> </span>[Honor|Ignore]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">nodeTaintsPolicy</span>:<span style=\"color:#bbb\"> </span>[Honor|Ignore]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># other Pod fields go here</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>The <code>nodeAffinityPolicy</code> field indicates how Kubernetes treats a Pod's <code>nodeAffinity</code> or <code>nodeSelector</code> for\npod topology spreading.\nIf <code>Honor</code>, kube-scheduler filters out nodes not matching <code>nodeAffinity</code>/<code>nodeSelector</code> in the calculation of\nspreading skew.\nIf <code>Ignore</code>, all nodes will be included, regardless of whether they match the Pod's <code>nodeAffinity</code>/<code>nodeSelector</code>\nor not.</p>\n<p>For backwards compatibility, <code>nodeAffinityPolicy</code> defaults to <code>Honor</code>.</p>\n<p>The <code>nodeTaintsPolicy</code> field defines how Kubernetes considers node taints for pod topology spreading.\nIf <code>Honor</code>, only tainted nodes for which the incoming pod has a toleration, will be included in the calculation of spreading skew.\nIf <code>Ignore</code>, kube-scheduler will not consider the node taints at all in the calculation of spreading skew, so a node with\npod untolerated taint will also be included.</p>\n<p>For backwards compatibility, <code>nodeTaintsPolicy</code> defaults to <code>Ignore</code>.</p>\n<p>The feature was introduced in v1.25 as alpha. By default, it was disabled, so if you want to use this feature in v1.25,\nyou had to explictly enable the feature gate <code>NodeInclusionPolicyInPodTopologySpread</code>. In the following v1.26\nrelease, that associated feature graduated to beta and is enabled by default.</p>\n<h2 id=\"kep-3243-respect-pod-topology-spread-after-rolling-upgrades\">KEP-3243: Respect Pod topology spread after rolling upgrades</h2>\n<p>Pod Topology Spread uses the field <code>labelSelector</code> to identify the group of pods over which\nspreading will be calculated. When using topology spreading with Deployments, it is common\npractice to use the <code>labelSelector</code> of the Deployment as the <code>labelSelector</code> in the topology\nspread constraints. However, this implies that all pods of a Deployment are part of the spreading\ncalculation, regardless of whether they belong to different revisions. As a result, when a new revision\nis rolled out, spreading will apply across pods from both the old and new ReplicaSets, and so by the\ntime the new ReplicaSet is completely rolled out and the old one is rolled back, the actual spreading\nwe are left with may not match expectations because the deleted pods from the older ReplicaSet will cause\nskewed distribution for the remaining pods. To avoid this problem, in the past users needed to add a\nrevision label to Deployment and update it manually at each rolling upgrade (both the label on the\npod template and the <code>labelSelector</code> in the <code>topologySpreadConstraints</code>).</p>\n<p>To solve this problem with a simpler API, Kubernetes v1.25 introduced a new field named\n<code>matchLabelKeys</code> to <code>topologySpreadConstraints</code>. <code>matchLabelKeys</code> is a list of pod label keys to select\nthe pods over which spreading will be calculated. The keys are used to lookup values from the labels of\nthe Pod being scheduled, those key-value labels are ANDed with <code>labelSelector</code> to select the group of\nexisting pods over which spreading will be calculated for the incoming pod.</p>\n<p>With <code>matchLabelKeys</code>, you don't need to update the <code>pod.spec</code> between different revisions.\nThe controller or operator managing rollouts just needs to set different values to the same label key for different revisions.\nThe scheduler will assume the values automatically based on <code>matchLabelKeys</code>.\nFor example, if you are configuring a Deployment, you can use the label keyed with\n<a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#pod-template-hash-label\">pod-template-hash</a>,\nwhich is added automatically by the Deployment controller, to distinguish between different\nrevisions in a single Deployment.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">topologySpreadConstraints</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">maxSkew</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">1</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">topologyKey</span>:<span style=\"color:#bbb\"> </span>kubernetes.io/hostname<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">whenUnsatisfiable</span>:<span style=\"color:#bbb\"> </span>DoNotSchedule<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">labelSelector</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">matchLabels</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">app</span>:<span style=\"color:#bbb\"> </span>foo<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">matchLabelKeys</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- pod-template-hash<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><h2 id=\"getting-involved\">Getting involved</h2>\n<p>These features are managed by Kubernetes <a href=\"https://github.com/kubernetes/community/tree/master/sig-scheduling\">SIG Scheduling</a>.</p>\n<p>Please join us and share your feedback. We look forward to hearing from you!</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<ul>\n<li><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\">Pod Topology Spread Constraints</a> in the Kubernetes documentation</li>\n<li><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/3022-min-domains-in-pod-topology-spread\">KEP-3022: min domains in Pod Topology Spread</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/3094-pod-topology-spread-considering-taints\">KEP-3094: Take taints/tolerations into consideration when calculating PodTopologySpread skew</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/3243-respect-pod-topology-spread-after-rolling-upgrades\">KEP-3243: Respect PodTopologySpread after rolling upgrades</a></li>\n</ul>","PublishedAt":"2023-04-17 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/04/17/fine-grained-pod-topology-spread-features-beta/","SourceName":"Kubernetes"}}]}},"pageContext":{"limit":30,"skip":2310,"numPages":193,"currentPage":78}},"staticQueryHashes":["3649515864"]}