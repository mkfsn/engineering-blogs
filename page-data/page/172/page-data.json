{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/172","result":{"data":{"allPost":{"edges":[{"node":{"ID":469,"Title":"Re-build vs. buy—or how to turn a legacy tool into a new data stack","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/11/Blog-36-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>Build vs. buy is one of those “evergreen” debates. When building a data stack and figuring out its respective components, it seems like it’ll never be out of style to ask: Wouldn’t it just be easier to buy? But there&#8217;s another, similar scenario that&#8217;s much less talked about even though it&#8217;s probably equally as important</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/re-build-vs-buy-or-how-to-turn-a-legacy-tool-into-a-data-stack/\">Re-build vs. buy—or how to turn a legacy tool into a new data stack</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-11-30 04:19:00+00:00","OriginURL":"https://mixpanel.com/blog/re-build-vs-buy-or-how-to-turn-a-legacy-tool-into-a-data-stack/","SourceName":"Mixpanel"}},{"node":{"ID":1246,"Title":"Blog: Quality-of-Service for Memory Resources","Description":"<p><strong>Authors:</strong> Tim Xu (Tencent Cloud)</p>\n<p>Kubernetes v1.22, released in August 2021, introduced a new alpha feature that improves how Linux nodes implement memory resource requests and limits.</p>\n<p>In prior releases, Kubernetes did not support memory quality guarantees.\nFor example, if you set container resources as follows:</p>\n<pre tabindex=\"0\"><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: example\nspec:\ncontainers:\n- name: nginx\nresources:\nrequests:\nmemory: &#34;64Mi&#34;\ncpu: &#34;250m&#34;\nlimits:\nmemory: &#34;64Mi&#34;\ncpu: &#34;500m&#34;\n</code></pre><p><code>spec.containers[].resources.requests</code>(e.g. cpu, memory) is designed for scheduling. When you create a Pod, the Kubernetes scheduler selects a node for the Pod to run on. Each node has a maximum capacity for each of the resource types: the amount of CPU and memory it can provide for Pods. The scheduler ensures that, for each resource type, the sum of the resource requests of the scheduled Containers is less than the capacity of the node.</p>\n<p><code>spec.containers[].resources.limits</code> is passed to the container runtime when the kubelet starts a container. CPU is considered a &quot;compressible&quot; resource. If your app starts hitting your CPU limits, Kubernetes starts throttling your container, giving your app potentially worse performance. However, it won’t be terminated. That is what &quot;compressible&quot; means.</p>\n<p>In cgroup v1, and prior to this feature, the container runtime never took into account and effectively ignored spec.containers[].resources.requests[&quot;memory&quot;]. This is unlike CPU, in which the container runtime consider both requests and limits. Furthermore, memory actually can't be compressed in cgroup v1. Because there is no way to throttle memory usage, if a container goes past its memory limit it will be terminated by the kernel with an OOM (Out of Memory) kill.</p>\n<p>Fortunately, cgroup v2 brings a new design and implementation to achieve full protection on memory. The new feature relies on cgroups v2 which most current operating system releases for Linux already provide. With this experimental feature, <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/\">quality-of-service for pods and containers</a> extends to cover not just CPU time but memory as well.</p>\n<h2 id=\"how-does-it-work\">How does it work?</h2>\n<p>Memory QoS uses the memory controller of cgroup v2 to guarantee memory resources in Kubernetes. Memory requests and limits of containers in pod are used to set specific interfaces <code>memory.min</code> and <code>memory.high</code> provided by the memory controller. When <code>memory.min</code> is set to memory requests, memory resources are reserved and never reclaimed by the kernel; this is how Memory QoS ensures the availability of memory for Kubernetes pods. And if memory limits are set in the container, this means that the system needs to limit container memory usage, Memory QoS uses <code>memory.high</code> to throttle workload approaching it's memory limit, ensuring that the system is not overwhelmed by instantaneous memory allocation.</p>\n<p><img src=\"./memory-qos-cal.svg\" alt=\"\"></p>\n<p>The following table details the specific functions of these two parameters and how they correspond to Kubernetes container resources.</p>\n<table>\n<tr>\n<th style=\"text-align:center\">File</th>\n<th style=\"text-align:center\">Description</th>\n</tr>\n<tr>\n<td>memory.min</td>\n<td><code>memory.min</code> specifies a minimum amount of memory the cgroup must always retain, i.e., memory that can never be reclaimed by the system. If the cgroup's memory usage reaches this low limit and can’t be increased, the system OOM killer will be invoked.\n<br>\n<br>\n<i>We map it to the container's memory request</i>\n</td>\n</tr>\n<tr>\n<td>memory.high</td>\n<td><code>memory.high</code> is the memory usage throttle limit. This is the main mechanism to control a cgroup's memory use. If a cgroup's memory use goes over the high boundary specified here, the cgroup’s processes are throttled and put under heavy reclaim pressure. The default is max, meaning there is no limit.\n<br>\n<br>\n<i>We use a formula to calculate <code>memory.high</code>, depending on container's memory limit or node allocatable memory (if container's memory limit is empty) and a throttling factor. Please refer to the KEP for more details on the formula.</i>\n</td>\n</tr>\n</table>\n<p>When container memory requests are made, kubelet passes <code>memory.min</code> to the back-end CRI runtime (possibly containerd, cri-o) via the <code>Unified</code> field in CRI during container creation. The <code>memory.min</code> in container level cgroup will be set to:</p>\n<p><img src=\"./container-memory-min.svg\" alt=\"\"><br>\n<sub>i: the i<sup>th</sup> container in one pod</sub></p>\n<p>Since the <code>memory.min</code> interface requires that the ancestor cgroup directories are all set, the pod and node cgroup directories need to be set correctly.</p>\n<p><code>memory.min</code> in pod level cgroup:<br>\n<img src=\"./pod-memory-min.svg\" alt=\"\"><br>\n<sub>i: the i<sup>th</sup> container in one pod</sub></p>\n<p><code>memory.min</code> in node level cgroup:<br>\n<img src=\"./node-memory-min.svg\" alt=\"\"><br>\n<sub>i: the i<sup>th</sup> pod in one node, j: the j<sup>th</sup> container in one pod</sub></p>\n<p>Kubelet will manage the cgroup hierarchy of the pod level and node level cgroups directly using runc libcontainer library, while container cgroup limits are managed by the container runtime.</p>\n<p>For memory limits, in addition to the original way of limiting memory usage, Memory QoS adds an additional feature of throttling memory allocation. A throttling factor is introduced as a multiplier (default is 0.8). If the result of multiplying memory limits by the factor is greater than memory requests, kubelet will set <code>memory.high</code> to the value and use <code>Unified</code> via CRI. And if the container does not specify memory limits, kubelet will use node allocatable memory instead. The <code>memory.high</code> in container level cgroup is set to:</p>\n<p><img src=\"./container-memory-high.svg\" alt=\"\"><br>\n<sub>i: the i<sup>th</sup> container in one pod</sub></p>\n<p>This can can help improve stability when pod memory usage increases, ensuring that memory is throttled as it approaches the memory limit.</p>\n<h2 id=\"how-do-i-use-it\">How do I use it?</h2>\n<p>Here are the prerequisites for enabling Memory QoS on your Linux node, some of these are related to <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2254-cgroup-v2\">Kubernetes support for cgroup v2</a>.</p>\n<ol>\n<li>Kubernetes since v1.22</li>\n<li><a href=\"https://github.com/opencontainers/runc\">runc</a> since v1.0.0-rc93; <a href=\"https://containerd.io/\">containerd</a> since 1.4; <a href=\"https://cri-o.io/\">cri-o</a> since 1.20</li>\n<li>Linux kernel minimum version: 4.15, recommended version: 5.2+</li>\n<li>Linux image with cgroupv2 enabled or enabling cgroupv2 unified_cgroup_hierarchy manually</li>\n</ol>\n<p>OCI runtimes such as runc and crun already support cgroups v2 <a href=\"https://github.com/opencontainers/runtime-spec/blob/master/config-linux.md#unified\"><code>Unified</code></a>, and Kubernetes CRI has also made the desired changes to support passing <a href=\"https://github.com/kubernetes/kubernetes/pull/102578\"><code>Unified</code></a>. However, CRI Runtime support is required as well. Memory QoS in Alpha phase is designed to support containerd and cri-o. Related PR <a href=\"https://github.com/containerd/containerd/pull/5627\">Feature: containerd-cri support LinuxContainerResources.Unified #5627</a> has been merged and will be released in containerd 1.6. CRI-O <a href=\"https://github.com/cri-o/cri-o/pull/5207\">implement kube alpha features for 1.22 #5207</a> is still in WIP.</p>\n<p>With those prerequisites met, you can enable the memory QoS feature gate (see <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/\">Set kubelet parameters via a config file</a>).</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>You can find more details as follows:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2570-memory-qos/#readme\">Support Memory QoS with cgroup v2</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2254-cgroup-v2/#readme\">cgroup v2</a></li>\n</ul>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>You can reach SIG Node by several means:</p>\n<ul>\n<li>Slack: <a href=\"https://kubernetes.slack.com/messages/sig-node\">#sig-node</a></li>\n<li><a href=\"https://groups.google.com/forum/#!forum/kubernetes-sig-node\">Mailing list</a></li>\n<li><a href=\"https://github.com/kubernetes/community/labels/sig%2Fnode\">Open Community Issues/PRs</a></li>\n</ul>\n<p>You can also contact me directly:</p>\n<ul>\n<li>GitHub / Slack: @xiaoxubeii</li>\n<li>Email: <a href=\"mailto:xiaoxubeii@gmail.com\">xiaoxubeii@gmail.com</a></li>\n</ul>","PublishedAt":"2021-11-26 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/11/26/qos-memory-resources/","SourceName":"Kubernetes"}},{"node":{"ID":1128,"Title":"Mercari Advent Calendar 2021 is coming up!","Description":"<p>Hello! I’m @afroscript of the Mercari Engineering Office. We have our annual Advent Calendar event in December every year and we’ll be hosting it again this year! We have both Mercari and Merpay Advent Calendar at the same time. ▶ Merpay Advent Calendar 2021 is here What is the Advent Calendar? The original meaning of [&hellip;]</p>\n","PublishedAt":"2021-11-25 14:30:17+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211125-mercari-advent-calendar-2021/","SourceName":"Mercari"}},{"node":{"ID":1266,"Title":"How to switch between Java LTS versions 8, 11 and 17 on Mac","Description":"","PublishedAt":"2021-11-25 11:59:25+00:00","OriginURL":"https://medium.com/miro-engineering/how-to-switch-between-java-lts-versions-8-11-and-17-on-mac-cb6717d1272?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":146,"Title":"How Dropbox Replay keeps everyone in sync","Description":"","PublishedAt":"2021-11-23 14:00:00+00:00","OriginURL":"https://dropbox.tech/application/how-dropbox-replay-keeps-everyone-in-sync","SourceName":"Dropbox"}},{"node":{"ID":1267,"Title":"Agile Data Engineering at Miro","Description":"","PublishedAt":"2021-11-22 12:53:21+00:00","OriginURL":"https://medium.com/miro-engineering/agile-data-engineering-at-miro-ec2dcc8a3fcb?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":610,"Title":"trivago Tech Check-in: Meet Mohammad","Description":"","PublishedAt":"2021-11-22 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2021-11-22-trivagotechcheckinmeetmohammad/","SourceName":"Trivago"}},{"node":{"ID":1129,"Title":"Next Direction of Engineering Office","Description":"<p>Hello, everyone. I’m @hisahiko, Engineering Office Director. For this article, I wanted to write about the work we’re doing to prepare Mercari’s Engineering Division for the future. I also wrote an article about how the Engineering Office is working to strengthen our Engineering Div as part of the “Mercari Advent Calendar” project at the end [&hellip;]</p>\n","PublishedAt":"2021-11-21 13:12:56+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211115-next-direction-of-engineering-office/","SourceName":"Mercari"}},{"node":{"ID":764,"Title":"CRISP: Critical Path Analysis for Microservice Architectures","Description":"<p><span style=\"font-weight: 400;\">Uber’s backend is an exemplar of microservice architecture. Each microservice is a small, individually deployable program performing a specific business logic (operation). The microservice architecture is a type of distributed computing system, which is suitable for independent deployments and scaling </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/crisp-critical-path-analysis-for-microservice-architectures/\">CRISP: Critical Path Analysis for Microservice Architectures</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-11-18 18:00:39+00:00","OriginURL":"https://eng.uber.com/crisp-critical-path-analysis-for-microservice-architectures/","SourceName":"Uber"}},{"node":{"ID":252,"Title":"Giphy SDK: Bridging Native SDKs in React Native","Description":"To make it easier for React Native developers to implement GIPHY and let their users share GIFs, Clips, and more, we released the GIPHY SDK for React Native a few months ago.","PublishedAt":"2021-11-17 15:06:46+00:00","OriginURL":"https://engineering.giphy.com/giphy-sdk-bridging-native-sdks-in-react-native/","SourceName":"GIPHY"}},{"node":{"ID":1268,"Title":"How we use Miro at Miro","Description":"","PublishedAt":"2021-11-16 05:31:07+00:00","OriginURL":"https://medium.com/miro-engineering/how-we-use-miro-at-miro-17f7f2c1b8a5?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":1247,"Title":"Blog: Dockershim removal is coming. Are you ready?","Description":"<p><strong>Authors:</strong> Sergey Kanzhelev, Google. With reviews from Davanum Srinivas, Elana Hashman, Noah Kantrowitz, Rey Lejano.</p>\n<div class=\"alert alert-info\" role=\"alert\">\n<h4 class=\"alert-heading\">Poll closed</h4>\nThis poll closed on January 7, 2022.\n</div>\n<p>Last year we <a href=\"https://kubernetes.io/blog/2020/12/08/kubernetes-1-20-release-announcement/#dockershim-deprecation\">announced</a>\nthat Kubernetes' dockershim component (which provides a built-in integration for\nDocker Engine) is deprecated.</p>\n<p><em>Update: There's a <a href=\"https://kubernetes.io/blog/2020/12/02/dockershim-faq/\">Dockershim Deprecation FAQ</a>\nwith more information, and you can also discuss the deprecation via a dedicated\n<a href=\"https://github.com/kubernetes/kubernetes/issues/106917\">GitHub issue</a>.</em></p>\n<p>Our current plan is to remove dockershim from the Kubernetes codebase soon.\nWe are looking for feedback from you whether you are ready for dockershim\nremoval and to ensure that you are ready when the time comes.</p>\n<p><del>Please fill out this survey: <a href=\"https://forms.gle/svCJmhvTv78jGdSx8\">https://forms.gle/svCJmhvTv78jGdSx8</a></del></p>\n<p>The dockershim component that enables Docker as a Kubernetes container runtime is\nbeing deprecated in favor of runtimes that directly use the <a href=\"https://kubernetes.io/blog/2016/12/container-runtime-interface-cri-in-kubernetes/\">Container Runtime Interface</a>\ncreated for Kubernetes. Many Kubernetes users have migrated to\nother container runtimes without problems. However we see that dockershim is\nstill very popular. You may see some public numbers in recent <a href=\"https://www.datadoghq.com/container-report/#8\">Container Report</a> from DataDog.\nSome Kubernetes hosting vendors just recently enabled other runtimes support\n(especially for Windows nodes). And we know that many third party tools vendors\nare still not ready: <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/migrating-from-dockershim/migrating-telemetry-and-security-agents/#telemetry-and-security-agent-vendors\">migrating telemetry and security agents</a>.</p>\n<p>At this point, we believe that there is feature parity between Docker and the\nother runtimes. Many end-users have used our <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/migrating-from-dockershim/\">migration guide</a>\nand are running production workload using these different runtimes. The plan of\nrecord today is that dockershim will be removed in version 1.24, slated for\nrelease around April of next year. For those developing or running alpha and\nbeta versions, dockershim will be removed in December at the beginning of the\n1.24 release development cycle.</p>\n<p>There is only one month left to give us feedback. We want you to tell us how\nready you are.</p>\n<p><del>We are collecting opinions through this survey: <a href=\"https://forms.gle/svCJmhvTv78jGdSx8\">https://forms.gle/svCJmhvTv78jGdSx8</a></del>\nTo better understand preparedness for the dockershim removal, our survey is\nasking the version of Kubernetes you are currently using, and an estimate of\nwhen you think you will adopt Kubernetes 1.24. All the aggregated information\non dockershim removal readiness will be published.\nFree form comments will be reviewed by SIG Node leadership. If you want to\ndiscuss any details of migrating from dockershim, report bugs or adoption\nblockers, you can use one of the SIG Node contact options any time:\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-node#contact\">https://github.com/kubernetes/community/tree/master/sig-node#contact</a></p>\n<p>Kubernetes is a mature project. This deprecation is another\nstep in the effort to get away from permanent beta features and providing more\nstability and compatibility guarantees. With the migration from dockershim you\nwill get more flexibility and choice of container runtime features as well as\nless dependencies of your apps on specific underlying technology. Please take\ntime to review the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/migrating-from-dockershim/\">dockershim migration documentation</a>\nand consult your Kubernetes hosting vendor (if you have one) what container runtime options are available for you.\nRead up <a href=\"https://kubernetes.io/docs/setup/production-environment/container-runtimes/#container-runtimes\">container runtime documentation with instructions on how to use containerd and CRI-O</a>\nto help prepare you when you're ready to upgrade to 1.24. CRI-O, containerd, and\nDocker with <a href=\"https://github.com/Mirantis/cri-dockerd\">Mirantis cri-dockerd</a> are\nnot the only container runtime options, we encourage you to explore the <a href=\"https://landscape.cncf.io/card-mode?category=container-runtime&amp;grouping=category\">CNCF landscape on container runtimes</a>\nin case another suits you better.</p>\n<p>Thank you!</p>","PublishedAt":"2021-11-12 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/11/12/are-you-ready-for-dockershim-removal/","SourceName":"Kubernetes"}},{"node":{"ID":83,"Title":"The Responsibility of Tech: Reflections from Grace Hopper Celebration","Description":"","PublishedAt":"2021-11-11 15:33:52+00:00","OriginURL":"https://medium.com/groupon-eng/the-responsibility-of-tech-reflections-from-grace-hopper-celebration-bc2a4c84775f?source=rss----5c13a88f9872---4","SourceName":"Groupon"}},{"node":{"ID":765,"Title":"How Uber Migrated Financial Data from DynamoDB to Docstore","Description":"<h1><span style=\"font-weight: 400;\">Introduction</span></h1>\n<p><span style=\"font-weight: 400;\">Each day, Uber moves millions of people around the world and delivers tens of millions of food and grocery orders. This generates a large number of financial transactions that need to be stored with provable completeness, consistency, and compliance.  </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/dynamodb-to-docstore-migration/\">How Uber Migrated Financial Data from DynamoDB to Docstore</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-11-10 17:00:50+00:00","OriginURL":"https://eng.uber.com/dynamodb-to-docstore-migration/","SourceName":"Uber"}},{"node":{"ID":1130,"Title":"Instant Delivery: Report on Autonomous Delivery Robots","Description":"<p>Hello! This is Pramendra from the Advanced Technology Team. In the Advanced Technology Team, we research business and technology trends around the world. We’re excited to bring you another trend report based on our findings. Previously, we have discussed Social Commerce and in this post, we will be looking into Autonomous Delivery Robots and their [&hellip;]</p>\n","PublishedAt":"2021-11-09 18:07:25+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211109-instant-delivery-report-on-autonomous-delivery-robots/","SourceName":"Mercari"}},{"node":{"ID":1248,"Title":"Blog: Non-root Containers And Devices","Description":"<p><strong>Author:</strong> Mikko Ylinen (Intel)</p>\n<p>The user/group ID related security settings in Pod's <code>securityContext</code> trigger a problem when users want to\ndeploy containers that use accelerator devices (via <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/\">Kubernetes Device Plugins</a>) on Linux. In this blog\npost I talk about the problem and describe the work done so far to address it. It's not meant to be a long story about getting the <a href=\"https://github.com/kubernetes/kubernetes/issues/92211\">k/k issue</a> fixed.</p>\n<p>Instead, this post aims to raise awareness of the issue and to highlight important device use-cases too. This is needed as Kubernetes works on new related features such as support for user namespaces.</p>\n<h2 id=\"why-non-root-containers-can-t-use-devices-and-why-it-matters\">Why non-root containers can't use devices and why it matters</h2>\n<p>One of the key security principles for running containers in Kubernetes is the\nprinciple of least privilege. The Pod/container <code>securityContext</code> specifies the config\noptions to set, e.g., Linux capabilities, MAC policies, and user/group ID values to achieve this.</p>\n<p>Furthermore, the cluster admins are supported with tools like <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-policy/\">PodSecurityPolicy</a> (deprecated) or\n<a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/\">Pod Security Admission</a> (alpha) to enforce the desired security settings for pods that are being deployed in\nthe cluster. These settings could, for instance, require that containers must be <code>runAsNonRoot</code> or\nthat they are forbidden from running with root's group ID in <code>runAsGroup</code> or <code>supplementalGroups</code>.</p>\n<p>In Kubernetes, the kubelet builds the list of <a href=\"https://pkg.go.dev/k8s.io/cri-api@v0.22.1/pkg/apis/runtime/v1#Device\"><code>Device</code></a> resources to be made available to a container\n(based on inputs from the Device Plugins) and the list is included in the CreateContainer CRI message\nsent to the CRI container runtime. Each <code>Device</code> contains little information: host/container device\npaths and the desired devices cgroups permissions.</p>\n<p>The <a href=\"https://github.com/opencontainers/runtime-spec/blob/master/config-linux.md\">OCI Runtime Spec for Linux Container Configuration</a>\nexpects that in addition to the devices cgroup fields, more detailed information about the devices\nmust be provided:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span>{<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;type&#34;: </span><span style=\"color:#b44\">&#34;&lt;string&gt;&#34;</span>,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;path&#34;: </span><span style=\"color:#b44\">&#34;&lt;string&gt;&#34;</span>,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;major&#34;: </span>&lt;int64&gt;,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;minor&#34;: </span>&lt;int64&gt;,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;fileMode&#34;: </span>&lt;uint32&gt;,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;uid&#34;: </span>&lt;uint32&gt;,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;gid&#34;: </span>&lt;uint32&gt;<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span>},<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>The CRI container runtimes (containerd, CRI-O) are responsible for obtaining this information\nfrom the host for each <code>Device</code>. By default, the runtimes copy the host device's user and group IDs:</p>\n<ul>\n<li><code>uid</code> (uint32, OPTIONAL) - id of device owner in the container namespace.</li>\n<li><code>gid</code> (uint32, OPTIONAL) - id of device group in the container namespace.</li>\n</ul>\n<p>Similarly, the runtimes prepare other mandatory <code>config.json</code> sections based on the CRI fields,\nincluding the ones defined in <code>securityContext</code>: <code>runAsUser</code>/<code>runAsGroup</code>, which become part of the POSIX\nplatforms user structure via:</p>\n<ul>\n<li><code>uid</code> (int, REQUIRED) specifies the user ID in the container namespace.</li>\n<li><code>gid</code> (int, REQUIRED) specifies the group ID in the container namespace.</li>\n<li><code>additionalGids</code> (array of ints, OPTIONAL) specifies additional group IDs in the container namespace to be added to the process.</li>\n</ul>\n<p>However, the resulting <code>config.json</code> triggers a problem when trying to run containers with\nboth devices added and with non-root uid/gid set via <code>runAsUser</code>/<code>runAsGroup</code>: the container user process\nhas no permission to use the device even when its group id (gid, copied from host) was permissive to\nnon-root groups. This is because the container user does not belong to that host group (e.g., via <code>additionalGids</code>).</p>\n<p>Being able to run applications that use devices as non-root user is normal and expected to work so that\nthe security principles can be met. Therefore, several alternatives were considered to get the gap filled with what the PodSec/CRI/OCI supports today.</p>\n<h2 id=\"what-was-done-to-solve-the-issue\">What was done to solve the issue?</h2>\n<p>You might have noticed from the problem definition that it would at least be possible to workaround\nthe problem by manually adding the device gid(s) to <code>supplementalGroups</code>, or in\nthe case of just one device, set <code>runAsGroup</code> to the device's group id. However, this is problematic because the device gid(s) may have\ndifferent values depending on the nodes' distro/version in the cluster. For example, with GPUs the following commands for different distros and versions return different gids:</p>\n<p>Fedora 33:</p>\n<pre tabindex=\"0\"><code>$ ls -l /dev/dri/\ntotal 0\ndrwxr-xr-x. 2 root root 80 19.10. 10:21 by-path\ncrw-rw----+ 1 root video 226, 0 19.10. 10:42 card0\ncrw-rw-rw-. 1 root render 226, 128 19.10. 10:21 renderD128\n$ grep -e video -e render /etc/group\nvideo:x:39:\nrender:x:997:\n</code></pre><p>Ubuntu 20.04:</p>\n<pre tabindex=\"0\"><code>$ ls -l /dev/dri/\ntotal 0\ndrwxr-xr-x 2 root root 80 19.10. 17:36 by-path\ncrw-rw---- 1 root video 226, 0 19.10. 17:36 card0\ncrw-rw---- 1 root render 226, 128 19.10. 17:36 renderD128\n$ grep -e video -e render /etc/group\nvideo:x:44:\nrender:x:133:\n</code></pre><p>Which number to choose in your <code>securityContext</code>? Also, what if the <code>runAsGroup</code>/<code>runAsUser</code> values cannot be hard-coded because\nthey are automatically assigned during pod admission time via external security policies?</p>\n<p>Unlike volumes with <code>fsGroup</code>, the devices have no official notion of <code>deviceGroup</code>/<code>deviceUser</code> that the CRI runtimes (or kubelet)\nwould be able to use. We considered using container annotations set by the device plugins (e.g., <code>io.kubernetes.cri.hostDeviceSupplementalGroup/</code>) to get custom OCI <code>config.json</code> uid/gid values.\nThis would have required changes to all existing device plugins which was not ideal.</p>\n<p>Instead, a solution that is <em>seamless</em> to end-users without getting the device plugin vendors involved was preferred. The selected approach was\nto re-use <code>runAsUser</code> and <code>runAsGroup</code> values in <code>config.json</code> for devices:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span>{<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;type&#34;: </span><span style=\"color:#b44\">&#34;c&#34;</span>,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;path&#34;: </span><span style=\"color:#b44\">&#34;/dev/foo&#34;</span>,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;major&#34;: </span><span style=\"color:#666\">123</span>,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;minor&#34;: </span><span style=\"color:#666\">4</span>,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;fileMode&#34;: </span><span style=\"color:#666\">438</span>,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;uid&#34;: </span>&lt;runAsUser&gt;,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;gid&#34;: </span>&lt;runAsGroup&gt;<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span>},<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>With <code>runc</code> OCI runtime (in non-rootless mode), the device is created (<code>mknod(2)</code>) in\nthe container namespace and the ownership is changed to <code>runAsUser</code>/<code>runAsGroup</code> using <code>chmod(2)</code>.</p>\n<p><div class=\"alert alert-info note callout\" role=\"alert\">\n<strong>Note:</strong> <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-in-userns/\">Rootless mode</a> and devices is not supported.\n</div>\nHaving the ownership updated in the container namespace is justified as the user process is the only one accessing the device. Only <code>runAsUser</code>/<code>runAsGroup</code>\nare taken into account, and, e.g., the <code>USER</code> setting in the container is currently ignored.</p>\n<p>While it is likely that the &quot;faulty&quot; deployments (i.e., non-root <code>securityContext</code> + devices) do not exist, to be absolutely sure no\ndeployments break, an opt-in config entry in both containerd and CRI-O to enable the new behavior was added. The following:</p>\n<p><code>device_ownership_from_security_context (bool)</code></p>\n<p>defaults to <code>false</code> and must be enabled to use the feature.</p>\n<h2 id=\"see-non-root-containers-using-devices-after-the-fix\">See non-root containers using devices after the fix</h2>\n<p>To demonstrate the new behavior, let's use a Data Plane Development Kit (DPDK) application using hardware accelerators, Kubernetes CPU manager, and HugePages as an example. The cluster runs containerd with:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-toml\" data-lang=\"toml\"><span style=\"display:flex;\"><span>[plugins]\n</span></span><span style=\"display:flex;\"><span> [plugins.<span style=\"color:#b44\">&#34;io.containerd.grpc.v1.cri&#34;</span>]\n</span></span><span style=\"display:flex;\"><span> device_ownership_from_security_context = <span style=\"color:#a2f;font-weight:bold\">true</span>\n</span></span></code></pre></div><p>or CRI-O with:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-toml\" data-lang=\"toml\"><span style=\"display:flex;\"><span>[crio.runtime]\n</span></span><span style=\"display:flex;\"><span>device_ownership_from_security_context = <span style=\"color:#a2f;font-weight:bold\">true</span>\n</span></span></code></pre></div><p>and the <code>Guaranteed</code> QoS Class Pod that runs DPDK's crypto-perf test utility with this YAML:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#00f;font-weight:bold\">...</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>qat-dpdk<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">securityContext</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">runAsUser</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">1000</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">runAsGroup</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">2000</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">fsGroup</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">3000</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">containers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>crypto-perf<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>intel/crypto-perf:devel<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>...<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">cpu</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;3&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">memory</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;128Mi&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">qat.intel.com/generic</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#39;4&#39;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">hugepages-2Mi</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;128Mi&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">limits</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">cpu</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;3&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">memory</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;128Mi&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">qat.intel.com/generic</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#39;4&#39;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">hugepages-2Mi</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;128Mi&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>...<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>To verify the results, check the user and group ID that the container runs as:</p>\n<pre tabindex=\"0\"><code>$ kubectl exec -it qat-dpdk -c crypto-perf -- id\n</code></pre><p>They are set to non-zero values as expected:</p>\n<pre tabindex=\"0\"><code>uid=1000 gid=2000 groups=2000,3000\n</code></pre><p>Next, check the device node permissions (<code>qat.intel.com/generic</code> exposes <code>/dev/vfio/</code> devices) are accessible to <code>runAsUser</code>/<code>runAsGroup</code>:</p>\n<pre tabindex=\"0\"><code>$ kubectl exec -it qat-dpdk -c crypto-perf -- ls -la /dev/vfio\ntotal 0\ndrwxr-xr-x 2 root root 140 Sep 7 10:55 .\ndrwxr-xr-x 7 root root 380 Sep 7 10:55 ..\ncrw------- 1 1000 2000 241, 0 Sep 7 10:55 58\ncrw------- 1 1000 2000 241, 2 Sep 7 10:55 60\ncrw------- 1 1000 2000 241, 10 Sep 7 10:55 68\ncrw------- 1 1000 2000 241, 11 Sep 7 10:55 69\ncrw-rw-rw- 1 1000 2000 10, 196 Sep 7 10:55 vfio\n</code></pre><p>Finally, check the non-root container is also allowed to create HugePages:</p>\n<pre tabindex=\"0\"><code>$ kubectl exec -it qat-dpdk -c crypto-perf -- ls -la /dev/hugepages/\n</code></pre><p><code>fsGroup</code> gives a <code>runAsUser</code> writable HugePages emptyDir mountpoint:</p>\n<pre tabindex=\"0\"><code>total 0\ndrwxrwsr-x 2 root 3000 0 Sep 7 10:55 .\ndrwxr-xr-x 7 root root 380 Sep 7 10:55 ..\n</code></pre><h2 id=\"help-us-test-it-and-provide-feedback\">Help us test it and provide feedback!</h2>\n<p>The functionality described here is expected to help with cluster security and the configurability of device permissions. To allow\nnon-root containers to use devices requires cluster admins to opt-in to the functionality by setting\n<code>device_ownership_from_security_context = true</code>. To make it a default setting, please test it and provide your feedback (via SIG-Node meetings or issues)!\nThe flag is available in CRI-O v1.22 release and queued for containerd v1.6.</p>\n<p>More work is needed to get it <em>properly</em> supported. It is known to work with <code>runc</code> but it also needs to be made to function\nwith other OCI runtimes too, where applicable. For instance, Kata Containers supports device passthrough and allows it to make devices\navailable to containers in VM sandboxes too.</p>\n<p>Moreover, the additional challenge comes with support of user names and devices. This problem is still <a href=\"https://github.com/kubernetes/enhancements/pull/2101\">open</a>\nand requires more brainstorming.</p>\n<p>Finally, it needs to be understood whether <code>runAsUser</code>/<code>runAsGroup</code> are enough or if device specific settings similar to <code>fsGroups</code> are needed in PodSpec/CRI v2.</p>\n<h2 id=\"thanks\">Thanks</h2>\n<p>My thanks goes to Mike Brown (IBM, containerd), Peter Hunt (Redhat, CRI-O), and Alexander Kanevskiy (Intel) for providing all the feedback and good conversations.</p>","PublishedAt":"2021-11-09 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/11/09/non-root-containers-and-devices/","SourceName":"Kubernetes"}},{"node":{"ID":470,"Title":"Using product analytics to find metrics that connect to retention","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/11/Blog-34-1-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>Let me jump right in: With product analytics, customer retention isn’t just something you measure after the fact; it should be something you can learn to find specific metric connections for (and then improve). I get it—data and analytics sound technical and scary, something only “really smart analytical people” should touch. How could a product</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/product-analytics-predict-retention/\">Using product analytics to find metrics that connect to retention</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-11-08 21:09:00+00:00","OriginURL":"https://mixpanel.com/blog/product-analytics-predict-retention/","SourceName":"Mixpanel"}},{"node":{"ID":1249,"Title":"Blog: Announcing the 2021 Steering Committee Election Results","Description":"<p><strong>Author</strong>: Kaslin Fields</p>\n<p>The <a href=\"https://github.com/kubernetes/community/tree/master/events/elections/2021\">2021 Steering Committee Election</a> is now complete. The Kubernetes Steering Committee consists of 7 seats, 4 of which were up for election in 2021. Incoming committee members serve a term of 2 years, and all members are elected by the Kubernetes Community.</p>\n<p>This community body is significant since it oversees the governance of the entire Kubernetes project. With that great power comes great responsibility. You can learn more about the steering committee’s role in their <a href=\"https://github.com/kubernetes/steering/blob/master/charter.md\">charter</a>.</p>\n<h2 id=\"results\">Results</h2>\n<p>Congratulations to the elected committee members whose two year terms begin immediately (listed in alphabetical order by GitHub handle):</p>\n<ul>\n<li><strong>Christoph Blecker (<a href=\"https://github.com/cblecker\">@cblecker</a>), Red Hat</strong></li>\n<li><strong>Stephen Augustus (<a href=\"https://github.com/justaugustus\">@justaugustus</a>), Cisco</strong></li>\n<li><strong>Paris Pittman (<a href=\"https://github.com/parispittman\">@parispittman</a>), Apple</strong></li>\n<li><strong>Tim Pepper (<a href=\"https://github.com/tpepper\">@tpepper</a>), VMware</strong></li>\n</ul>\n<p>They join continuing members:</p>\n<ul>\n<li><strong>Davanum Srinivas (<a href=\"https://github.com/dims\">@dims</a>), VMware</strong></li>\n<li><strong>Jordan Liggitt (<a href=\"https://github.com/liggitt\">@liggitt</a>), Google</strong></li>\n<li><strong>Bob Killen (<a href=\"https://github.com/mrbobbytables\">@mrbobbytables</a>), Google</strong></li>\n</ul>\n<p>Paris Pittman and Christoph Blecker are returning Steering Committee Members.</p>\n<h2 id=\"big-thanks\">Big Thanks</h2>\n<p>Thank you and congratulations on a successful election to this round’s election officers:</p>\n<ul>\n<li>Alison Dowdney, (<a href=\"https://github.com/alisondy\">@alisondy</a>)</li>\n<li>Noah Kantrowitz (<a href=\"https://github.com/coderanger\">@coderanger</a>)</li>\n<li>Josh Berkus (<a href=\"https://github.com/jberkus\">@jberkus</a>)</li>\n</ul>\n<p>Special thanks to Arnaud Meukam (<a href=\"https://github.com/ameukam\">@ameukam</a>), k8s-infra liaison, who enabled our voting software on community-owned infrastructure.</p>\n<p>Thanks to the Emeritus Steering Committee Members. Your prior service is appreciated by the community:</p>\n<ul>\n<li>Derek Carr (<a href=\"https://github.com/derekwaynecarr\">@derekwaynecarr</a>)</li>\n<li>Nikhita Raghunath (<a href=\"https://github.com/nikhita\">@nikhita</a>)</li>\n</ul>\n<p>And thank you to all the candidates who came forward to run for election.</p>\n<h2 id=\"get-involved-with-the-steering-committee\">Get Involved with the Steering Committee</h2>\n<p>This governing body, like all of Kubernetes, is open to all. You can follow along with Steering Committee <a href=\"https://github.com/kubernetes/steering/projects/1\">backlog items</a> and weigh in by filing an issue or creating a PR against their <a href=\"https://github.com/kubernetes/steering\">repo</a>. They have an open meeting on <a href=\"https://github.com/kubernetes/steering\">the first Monday at 9:30am PT of every month</a> and regularly attend Meet Our Contributors. They can also be contacted at their public mailing list <a href=\"mailto:steering@kubernetes.io\">steering@kubernetes.io</a>.</p>\n<p>You can see what the Steering Committee meetings are all about by watching past meetings on the <a href=\"https://www.youtube.com/playlist?list=PL69nYSiGNLP1yP1B_nd9-drjoxp0Q14qM\">YouTube Playlist</a>.</p>\n<hr>\n<p><em>This post was written by the <a href=\"https://github.com/kubernetes/community/tree/master/communication/marketing-team#contributor-marketing\">Upstream Marketing Working Group</a>. If you want to write stories about the Kubernetes community, learn more about us.</em></p>","PublishedAt":"2021-11-08 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/11/08/steering-committee-results-2021/","SourceName":"Kubernetes"}},{"node":{"ID":531,"Title":"Modernizing Our Search Stack","Description":"","PublishedAt":"2021-11-02 14:10:44+00:00","OriginURL":"https://engblog.nextdoor.com/modernizing-our-search-stack-6a56ab87db4e?source=rss----5e54f11cdfdf---4","SourceName":"Nextdoor"}},{"node":{"ID":397,"Title":"Catalog Localization: more than just a translation!","Description":"","PublishedAt":"2021-11-01 17:43:52+00:00","OriginURL":"https://tech.instacart.com/catalog-localization-more-than-just-a-translation-7251675dc12b?source=rss----587883b5d2ee---4","SourceName":"Instacart"}},{"node":{"ID":84,"Title":"Pinion — The Load Framework Part-2","Description":"","PublishedAt":"2021-10-29 16:50:24+00:00","OriginURL":"https://medium.com/groupon-eng/pinion-the-load-framework-part-2-e6a47586e7be?source=rss----5c13a88f9872---4","SourceName":"Groupon"}},{"node":{"ID":532,"Title":"Running ML Inference Services in Shared Hosting Environments","Description":"","PublishedAt":"2021-10-29 15:25:38+00:00","OriginURL":"https://engblog.nextdoor.com/running-ml-inference-services-in-shared-hosting-environments-6176b39bc9b7?source=rss----5e54f11cdfdf---4","SourceName":"Nextdoor"}},{"node":{"ID":611,"Title":"trivago Tech Week 2021 in Review","Description":"","PublishedAt":"2021-10-27 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2021-10-27-trivagotechweek2021hybridedition/","SourceName":"Trivago"}},{"node":{"ID":471,"Title":"Being more ‘self-serve’ using product analytics","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/10/Chameleon.png@2x-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>Imagine your ideal customer discovering your product for the first time. It&#8217;s exactly the kind of tool they want to include in their tech stack. They&#8217;re eager to give it a try before they invite their teammates, so they opt for a free trial only to realize it’s not quite clear where to start.&#160; There</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/make-your-product-self-serve-with-product-analytics/\">Being more ‘self-serve’ using product analytics</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-10-25 19:05:00+00:00","OriginURL":"https://mixpanel.com/blog/make-your-product-self-serve-with-product-analytics/","SourceName":"Mixpanel"}},{"node":{"ID":766,"Title":"Introducing uGroup: Uber’s Consumer Management Framework","Description":"<h1><b>Background</b></h1>\n<p><span style=\"font-weight: 400;\">Apache Kafka<sup>®</sup></span><span style=\"font-weight: 400;\"> is widely used across Uber’s multiple business lines. Take the example of an Uber ride: When a user opens up the Uber app, demand and supply data are aggregated in Kafka queues to serve fare calculations. </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/introducing-ugroup-ubers-consumer-management-framework/\">Introducing uGroup: Uber’s Consumer Management Framework</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-10-21 16:00:52+00:00","OriginURL":"https://eng.uber.com/introducing-ugroup-ubers-consumer-management-framework/","SourceName":"Uber"}},{"node":{"ID":1269,"Title":"Fluent setter: breaking the convention","Description":"","PublishedAt":"2021-10-18 07:52:17+00:00","OriginURL":"https://medium.com/miro-engineering/fluent-setter-breaking-the-convention-33ce3433126e?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":1250,"Title":"Blog: Use KPNG to Write Specialized kube-proxiers","Description":"<p><strong>Author</strong>: Lars Ekman (Ericsson)</p>\n<p>The post will show you how to create a specialized service kube-proxy\nstyle network proxier using Kubernetes Proxy NG\n<a href=\"https://github.com/kubernetes-sigs/kpng\">kpng</a> without interfering\nwith the existing kube-proxy. The kpng project aims at renewing the\nthe default Kubernetes Service implementation, the &quot;kube-proxy&quot;. An\nimportant feature of kpng is that it can be used as a library to\ncreate proxiers outside K8s. While this is useful for CNI-plugins that\nreplaces the kube-proxy it also opens the possibility for anyone to\ncreate a proxier for a special purpose.</p>\n<h2 id=\"define-a-service-that-uses-a-specialized-proxier\">Define a service that uses a specialized proxier</h2>\n<pre tabindex=\"0\"><code>apiVersion: v1\nkind: Service\nmetadata:\nname: kpng-example\nlabels:\nservice.kubernetes.io/service-proxy-name: kpng-example\nspec:\nclusterIP: None\nipFamilyPolicy: RequireDualStack\nexternalIPs:\n- 10.0.0.55\n- 1000::55\nselector:\napp: kpng-alpine\nports:\n- port: 6000\n</code></pre><p>If the <code>service.kubernetes.io/service-proxy-name</code> label is defined the\n<code>kube-proxy</code> will ignore the service. A custom controller can watch\nservices with the label set to it's own name, &quot;kpng-example&quot; in\nthis example, and setup specialized load-balancing.</p>\n<p>The <code>service.kubernetes.io/service-proxy-name</code> label is <a href=\"https://kubernetes.io/docs/reference/labels-annotations-taints/#servicekubernetesioservice-proxy-name\">not\nnew</a>,\nbut so far is has been quite hard to write a specialized proxier.</p>\n<p>The common use for a specialized proxier is assumed to be handling\nexternal traffic for some use-case not supported by K8s. In that\ncase <code>ClusterIP</code> is not needed, so we use a &quot;headless&quot; service in this\nexample.</p>\n<h2 id=\"specialized-proxier-using-kpng\">Specialized proxier using kpng</h2>\n<p>A <a href=\"https://github.com/kubernetes-sigs/kpng\">kpng</a> based proxier\nconsists of the <code>kpng</code> controller handling all the K8s api related\nfunctions, and a &quot;backend&quot; implementing the load-balancing. The\nbackend can be linked with the <code>kpng</code> controller binary or be a\nseparate program communicating with the controller using gRPC.</p>\n<pre tabindex=\"0\"><code>kpng kube --service-proxy-name=kpng-example to-api\n</code></pre><p>This starts the <code>kpng</code> controller and tell it to watch only services\nwith the &quot;kpng-example&quot; service proxy name. The &quot;to-api&quot; parameter\nwill open a gRPC server for backends.</p>\n<p>You can test this yourself outside your cluster. Please see the example\nbelow.</p>\n<p>Now we start a backend that simply prints the updates from the\ncontroller.</p>\n<pre tabindex=\"0\"><code>$ kubectl apply -f kpng-example.yaml\n$ kpng-json | jq # (this is the backend)\n{\n&#34;Service&#34;: {\n&#34;Namespace&#34;: &#34;default&#34;,\n&#34;Name&#34;: &#34;kpng-example&#34;,\n&#34;Type&#34;: &#34;ClusterIP&#34;,\n&#34;IPs&#34;: {\n&#34;ClusterIPs&#34;: {},\n&#34;ExternalIPs&#34;: {\n&#34;V4&#34;: [\n&#34;10.0.0.55&#34;\n],\n&#34;V6&#34;: [\n&#34;1000::55&#34;\n]\n},\n&#34;Headless&#34;: true\n},\n&#34;Ports&#34;: [\n{\n&#34;Protocol&#34;: 1,\n&#34;Port&#34;: 6000,\n&#34;TargetPort&#34;: 6000\n}\n]\n},\n&#34;Endpoints&#34;: [\n{\n&#34;IPs&#34;: {\n&#34;V6&#34;: [\n&#34;1100::202&#34;\n]\n},\n&#34;Local&#34;: true\n},\n{\n&#34;IPs&#34;: {\n&#34;V4&#34;: [\n&#34;11.0.2.2&#34;\n]\n},\n&#34;Local&#34;: true\n},\n{\n&#34;IPs&#34;: {\n&#34;V4&#34;: [\n&#34;11.0.1.2&#34;\n]\n}\n},\n{\n&#34;IPs&#34;: {\n&#34;V6&#34;: [\n&#34;1100::102&#34;\n]\n}\n}\n]\n}\n</code></pre><p>A real backend would use some mechanism to load-balance traffic from\nthe external IPs to the endpoints.</p>\n<h2 id=\"writing-a-backend\">Writing a backend</h2>\n<p>The <code>kpng-json</code> backend looks like this:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-go\" data-lang=\"go\"><span style=\"display:flex;\"><span><span style=\"color:#a2f;font-weight:bold\">package</span> main\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#a2f;font-weight:bold\">import</span> (\n</span></span><span style=\"display:flex;\"><span> <span style=\"color:#b44\">&#34;os&#34;</span>\n</span></span><span style=\"display:flex;\"><span> <span style=\"color:#b44\">&#34;encoding/json&#34;</span>\n</span></span><span style=\"display:flex;\"><span> <span style=\"color:#b44\">&#34;sigs.k8s.io/kpng/client&#34;</span>\n</span></span><span style=\"display:flex;\"><span>)\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#a2f;font-weight:bold\">func</span> <span style=\"color:#00a000\">main</span>() {\n</span></span><span style=\"display:flex;\"><span> client.<span style=\"color:#00a000\">Run</span>(jsonPrint)\n</span></span><span style=\"display:flex;\"><span>}\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#a2f;font-weight:bold\">func</span> <span style=\"color:#00a000\">jsonPrint</span>(items []<span style=\"color:#666\">*</span>client.ServiceEndpoints) {\n</span></span><span style=\"display:flex;\"><span> enc <span style=\"color:#666\">:=</span> json.<span style=\"color:#00a000\">NewEncoder</span>(os.Stdout)\n</span></span><span style=\"display:flex;\"><span> <span style=\"color:#a2f;font-weight:bold\">for</span> _, item <span style=\"color:#666\">:=</span> <span style=\"color:#a2f;font-weight:bold\">range</span> items {\n</span></span><span style=\"display:flex;\"><span> _ = enc.<span style=\"color:#00a000\">Encode</span>(item)\n</span></span><span style=\"display:flex;\"><span> }\n</span></span><span style=\"display:flex;\"><span>}\n</span></span></code></pre></div><p>(yes, that is the entire program)</p>\n<p>A real backend would of course be much more complex, but this\nillustrates how <code>kpng</code> let you focus on load-balancing.</p>\n<p>You can have several backends connected to a <code>kpng</code> controller, so\nduring development or debug it can be useful to let something like the\n<code>kpng-json</code> backend run in parallel with your real backend.</p>\n<h2 id=\"example\">Example</h2>\n<p>The complete example can be found <a href=\"https://github.com/kubernetes-sigs/kpng/tree/master/examples/pipe-exec\">here</a>.</p>\n<p>As an example we implement an &quot;all-ip&quot; backend. It direct all traffic\nfor the externalIPs to a local endpoint, regardless of ports and upper\nlayer protocols. There is a\n<a href=\"https://github.com/kubernetes/enhancements/pull/2611\">KEP</a> for this\nfunction and this example is a much simplified version.</p>\n<p>To direct all traffic from an external address to a local POD <a href=\"https://github.com/kubernetes/enhancements/pull/2611#issuecomment-895061013\">only\none iptables rule is\nneeded</a>,\nfor instance;</p>\n<pre tabindex=\"0\"><code>ip6tables -t nat -A PREROUTING -d 1000::55/128 -j DNAT --to-destination 1100::202\n</code></pre><p>As you can see the addresses are in the call to the backend and all it\nhave to do is:</p>\n<ul>\n<li>Extract the addresses with <code>Local: true</code></li>\n<li>Setup iptables rules for the <code>ExternalIPs</code></li>\n</ul>\n<p>A script doing that may look like:</p>\n<pre tabindex=\"0\"><code>xip=$(cat /tmp/out | jq -r .Service.IPs.ExternalIPs.V6[0])\npodip=$(cat /tmp/out | jq -r &#39;.Endpoints[]|select(.Local == true)|select(.IPs.V6 != null)|.IPs.V6[0]&#39;)\nip6tables -t nat -A PREROUTING -d $xip/128 -j DNAT --to-destination $podip\n</code></pre><p>Assuming the JSON output above is stored in <code>/tmp/out</code> (<a href=\"https://stedolan.github.io/jq/\">jq</a> is an <em>awesome</em> program!).</p>\n<p>As this is an example we make it really simple for ourselves by using\na minor variation of the <code>kpng-json</code> backend above. Instead of just\nprinting, a program is called and the JSON output is passed as <code>stdin</code>\nto that program. The backend can be tested stand-alone:</p>\n<pre tabindex=\"0\"><code>CALLOUT=jq kpng-callout\n</code></pre><p>Where <code>jq</code> can be replaced with your own program or script. A script\nmay look like the example above. For more info and the complete\nexample please see <a href=\"https://github.com/kubernetes-sigs/kpng/tree/master/examples/pipe-exec\">https://github.com/kubernetes-sigs/kpng/tree/master/examples/pipe-exec</a>.</p>\n<h2 id=\"summary\">Summary</h2>\n<p>While <a href=\"https://github.com/kubernetes-sigs/kpng\">kpng</a> is in early\nstage of development this post wants to show how you may build your\nown specialized K8s proxiers in the future. The only thing your\napplications need to do is to add the\n<code>service.kubernetes.io/service-proxy-name</code> label in the Service\nmanifest.</p>\n<p>It is a tedious process to get new features into the <code>kube-proxy</code> and\nit is not unlikely that they will be rejected, so to write a\nspecialized proxier may be the only option.</p>","PublishedAt":"2021-10-18 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/10/18/use-kpng-to-write-specialized-kube-proxiers/","SourceName":"Kubernetes"}},{"node":{"ID":472,"Title":"Product analytics improves patient experience","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/10/Healthcare-blog@2x-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>Healthcare brands that practice A/B testing and personalization are 5x more likely to report faster growth than those that do not, according to a study by the A/B testing and personalization platform Kameleoon and Forrester Research. What holds so many brands back are the three Vs: Volume: They feel overwhelmed by the amount of data</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/how-healthcare-companies-use-analytics-and-optimization-patient-experience/\">Product analytics improves patient experience</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-10-15 21:13:00+00:00","OriginURL":"https://mixpanel.com/blog/how-healthcare-companies-use-analytics-and-optimization-patient-experience/","SourceName":"Mixpanel"}},{"node":{"ID":1131,"Title":"Natural views for self-supervised learning","Description":"<p>Creating labels for machine learning is hard and time consuming, wouldn&#8217;t it be nice to train a model without any? We can with self-supervised learning! I&#8217;m Paul Willot from the AI/ML team and in this post I&#8217;ll introduce an experiment we did to get rid of labels by leveraging the structure of Mercari&#8217;s data. Let&#8217;s [&hellip;]</p>\n","PublishedAt":"2021-10-15 16:44:53+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211015-natural-views-self-supervised-learning/","SourceName":"Mercari"}},{"node":{"ID":767,"Title":"Improving HDFS I/O Utilization for Efficiency","Description":"<p><span style=\"font-weight: 400;\">Scaling our data infrastructure with lower hardware costs while maintaining high performance and service reliability has been no easy feat. To accommodate the exponential growth in both Data Storage and Analytics Compute at Uber, the Data Infrastructure team massively overhauled </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/improving-hdfs-i-o-utilization-for-efficiency/\">Improving HDFS I/O Utilization for Efficiency</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-10-13 16:00:31+00:00","OriginURL":"https://eng.uber.com/improving-hdfs-i-o-utilization-for-efficiency/","SourceName":"Uber"}}]}},"pageContext":{"limit":30,"skip":5130,"numPages":193,"currentPage":172}},"staticQueryHashes":["3649515864"]}