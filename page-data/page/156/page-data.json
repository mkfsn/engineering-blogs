{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/156","result":{"data":{"allPost":{"edges":[{"node":{"ID":92,"Title":"GitHub Availability Report: June 2022","Description":"In June, we experienced four incidents resulting in significant impact to multiple GitHub.com services. This report also sheds light into an incident that impacted several GitHub.com services in May.","PublishedAt":"2022-07-06 16:00:13+00:00","OriginURL":"https://github.blog/2022-07-06-github-availability-report-june-2022/","SourceName":"GitHub"}},{"node":{"ID":60,"Title":"How many shards should I have in my Elasticsearch cluster?","Description":"<p><span id=\"docs-internal-guid-b0236a47-5143-865d-24cf-f34cd7724e89\"></span><span style=\"color: rgb(52, 55, 65);\"><strong></strong></span><span style=\"color: rgb(52, 55, 65);\"></span>Elasticsearch is a very versatile platform that supports a variety of use cases and provides great flexibility around data organisation and replication strategies. This flexibility can, however, sometimes make it hard to determine up-front how to best organize your data into indices and shards, especially if you are new to the Elastic Stack. While suboptimal choices will not necessarily cause problems when first starting out, they have the potential to cause performance problems as data volumes grow over time. The more data the cluster holds, the more difficult it also becomes to correct the problem, as reindexing of large amounts of data can sometimes be required.</p><p>When we come across users that are experiencing performance problems, it is not uncommon that this can be traced back to issues around how data is indexed and number of shards in the cluster. This is especially true for use-cases involving multi-tenancy and/or use of time-based indices. When discussing this with users, either in person at events or meetings or via our <a href=\"https://discuss.elastic.co\" target=\"_self\">forum</a>, some of the most common questions are “How many shards should I have?” and “How large should my shards be?”</p><p>This blog post aims to help you answer these questions and provide practical guidelines for use cases that involve the use of time-based indices (e.g., logging or security analytics) in a single place.</p><h2 dir=\"ltr\">What is a shard?</h2><p>Before we start, we need to establish some facts and terminology that we will need in later sections.</p><p>Data in Elasticsearch is organized into <a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/2.x/_add_an_index.html\" target=\"_self\">indices</a>. Each index is made up of one or more shards. Each shard is an instance of a Lucene index, which you can think of as a self-contained search engine that indexes and handles queries for a subset of the data in an Elasticsearch cluster.</p><p>As data is written to a shard, it is periodically published into new immutable Lucene segments on disk, and it is at this time it becomes available for querying. This is referred to as a refresh. How this works is described in greater detail in <a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/inside-a-shard.html\" target=\"_self\">Elasticsearch: the Definitive Guide</a>.</p><p>As the number of segments grow, these are periodically consolidated into larger segments. This process is referred to as <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.5/index-modules-merge.html\" target=\"_self\">merging</a>. As all segments are immutable, this means that the disk space used will typically fluctuate during indexing, as new, merged segments need to be created before the ones they replace can be deleted. Merging can be quite resource intensive, especially with respect to disk I/O.</p><p>The shard is the unit at which Elasticsearch distributes data around the cluster. The speed at which Elasticsearch can move shards around when rebalancing data, e.g. following a failure, will depend on the size and number of shards as well as network and disk performance.</p><table><tbody><tr><td><span style=\"font-weight: 700;\"><em>TIP:</em></span><span style=\"font-weight: 700;\"><em>&nbsp;</em></span><span style=\"color: rgb(49, 133, 155);\"><em></em></span><em>Avoid having very large shards as this can negatively affect the cluster's ability to recover from failure. There is no fixed limit on how large shards can be, but a shard size of 50GB is often quoted as a limit that has been seen to work for a variety of use-cases.</em></td></tr></tbody></table><h2 dir=\"ltr\">Index by retention period</h2><p>As segments are immutable, <a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/2.x/update-doc.html\" target=\"_self\">updating a document</a> requires Elasticsearch to first find the existing document, then mark it as deleted and add the updated version. <a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/2.x/delete-doc.html\" target=\"_self\">Deleting a document</a> also requires the document to be found and marked as deleted. For this reason, deleted documents <a href=\"https://www.elastic.co/blog/lucenes-handling-of-deleted-documents\" target=\"_self\">will continue to tie up disk space and some system resources until they are merged out</a>, which can consume a lot of system resources.</p><p>Elasticsearch allows complete indices to be deleted very efficiently directly from the file system, without explicitly having to delete all records individually. This is by far the most efficient way to delete data from Elasticsearch.</p><hr/><p style=\"margin-left: 20px;\"><em><strong>TIP: </strong></em><em>Try to use </em><a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/2.x/time-based.html\" target=\"_self\"><em>time-based indices</em></a><em> for managing data retention whenever possible. Group data into indices based on the retention period. Time-based indices also make it easy to vary the number of primary shards and replicas over time, as this can be changed for the next index to be generated. This simplifies adapting to changing data volumes and requirements.</em></p><hr/><h2 dir=\"ltr\">Are indices and shards not free?</h2><p>For each Elasticsearch index, information about mappings and state is stored in the cluster state. This is kept in memory for fast access. Having a large number of indices and shards in a cluster can therefore result in a large cluster state, especially if mappings are large. This can become slow to update as all updates need to be done through a single thread in order to guarantee consistency before the changes are distributed across the cluster.</p><hr/><p style=\"margin-left: 20px;\"><em><strong>TIP: </strong></em><em>In order to reduce the number of indices and avoid large and sprawling mappings, consider storing data with similar structure in the same index rather than splitting into separate indices based on where the data comes from. It is important to find a good balance between the number of indices and shards, and the mapping size for each individual index. Because the </em><a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/2.x/finite-scale.html#finite-scale\" target=\"_blank\"><em>cluster state</em></a><em> is loaded into the heap on every node (including the masters), and the amount of heap is directly proportional to the number of indices, fields per index and shards, it is important to also monitor the heap usage on master nodes and make sure they are sized appropriately. &nbsp;</em></p><hr/><p>Each shard has data that need to be kept in memory and use heap space. This includes data structures holding information at the shard level, but also at the segment level in order to define where data reside on disk. The size of these data structures is not fixed and will vary depending on the use-case.</p><p>One important characteristic of the segment related overhead is however that it is not strictly proportional to the size of the segment. This means that larger segments have less overhead per data volume compared to smaller segments. The difference can be substantial.</p><p>In order to be able to store as much data as possible per node, it becomes important to manage heap usage and reduce the amount of overhead as much as possible. The more heap space a node has, the more data and shards it can handle.</p><p>Indices and shards are therefore not free from a cluster perspective, as there is some level of resource overhead for each index and shard.</p><hr/><p style=\"margin-left: 20px;\"><em><strong>TIP: </strong></em><em>Small shards result in small segments, which increases overhead. Aim to keep the average shard size between at least a few GB and a few tens of GB. For use-cases with time-based data, it is common to see shards between 20GB and 40GB in size.</em></p><p style=\"margin-left: 20px;\"><em><strong>TIP: </strong></em><em>As the overhead per shard depends on the segment count and size, forcing smaller segments to merge into larger ones through a </em><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.5/indices-forcemerge.html\" target=\"_self\"><em>forcemerge</em></a><em> operation can reduce overhead and improve query performance. This should ideally be done once no more data is written to the index. Be aware that this is an expensive operation that should ideally be performed during off-peak hours.</em></p><p style=\"margin-left: 20px;\"><em><strong>TIP: </strong></em><em>The number of shards you can hold on a node will be proportional to the amount of heap you have available, but there is no fixed limit enforced by Elasticsearch. A good rule-of-thumb is to ensure you keep the number of shards per node below 20 per GB heap it has configured. A node with a 30GB heap should therefore have a maximum of 600&nbsp;shards, but the further below this limit you can keep it the better. This will generally help the cluster stay in good health. </em><span style=\"color: rgb(52, 55, 65);\"><em><strong>(Editor’s note: As of 8.3, we have drastically reduced the heap usage per shard, thus updating the rule of thumb in this blog. Please follow TIP below for 8.3+ versions of Elasticsearch.)</strong></em></span></p><p style=\"margin-left: 20px;\"><em><strong>NEW TIP: </strong></em><span style=\"color: rgb(52, 55, 65);\"><em><strong>Allow 1kB of heap per field per index on data nodes, plus overheads</strong></em><em><strong><br/></strong></em></span><span style=\"color: rgb(52, 55, 65);\"><em>The exact resource usage of each mapped field depends on its type, but a rule of thumb is to allow for approximately 1kB of heap overhead per mapped field per index held by each data node. You must also allow enough heap for Elasticsearch’s baseline usage as well as your workload, such as indexing, searches, and aggregations. Extra heap of 0.5GB will suffice for many reasonable workloads, and you may need even less if your workload is very light while heavy workloads may require more.</em></span></p><p style=\"margin-left: 20px;\"><span style=\"color: rgb(52, 55, 65);\"><em>For example, if a data node holds shards from 1000 indices, each containing 4000 mapped fields, then you should allow approximately 1000 × 4000 × 1kB = 4GB of heap for the fields and another 0.5GB of heap for its workload and other overheads, and therefore this node will need a heap size of at least 4.5GB.</em></span><span style=\"color: rgb(52, 55, 65);\"><em><strong></strong></em></span></p><hr/><h2 dir=\"ltr\">How does shard size affect performance?</h2><p>In Elasticsearch, each query is executed in a single thread per shard. Multiple shards can however be processed in parallel, as can multiple queries and aggregations against the same shard.</p><p>This means that the minimum query latency, when no caching is involved, will depend on the data, the type of query, as well as the size of the shard. Querying lots of small shards will make the processing per shard faster, but as many more tasks need to be queued up and processed in sequence, it is not necessarily going to be faster than querying a smaller number of larger shards. Having lots of small shards can also reduce the query throughput if there are multiple concurrent queries.</p><hr/><p style=\"margin-left: 20px;\"><em><strong>TIP: </strong></em><em>The best way to determine the maximum shard size from a query performance perspective is to </em><a href=\"https://www.elastic.co/elasticon/conf/2016/sf/quantitative-cluster-sizing\" target=\"_self\"><em>benchmark using realistic data and queries</em></a><em>. Always benchmark with a query and indexing load representative of what the node would need to handle in production, as optimizing for a single query might give misleading results.</em></p><hr/><h2 dir=\"ltr\">How do I manage shard size?</h2><p>When using time-based indices, each index has traditionally been associated with a fixed time period. Daily indices are very common, and often used for holding data with short retention period or large daily volumes. These allow retention period to be managed with good granularity and makes it easy to adjust for changing volumes on a daily basis. Data with a longer retention period, especially if the daily volumes do not warrant the use of daily indices, often use weekly or monthly indices in order to keep the shard size up. This reduces the number of indices and shards that need to be stored in the cluster over time.</p><hr/><p style=\"margin-left: 20px;\"><em>TIP: If using time-based indices covering a fixed period, adjust the period each index covers based on the retention period and expected data volumes in order to reach the target shard size.</em></p><hr/><p>Time-based indices with a fixed time interval works well when data volumes are reasonably predictable and change slowly. If the indexing rate can vary quickly, it is very difficult to maintain a uniform target shard size.</p><p>In order to be able to better handle this type of scenarios, the <a href=\"https://www.elastic.co/blog/managing-time-based-indices-efficiently\" target=\"_self\">Rollover and Shrink APIs</a> were introduced. These add a lot of flexibility to how indices and shards are managed, specifically for time-based indices.</p><p>The <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.5/indices-rollover-index.html\" target=\"_self\">rollover index API</a> makes it possible to specify the number of documents an index should contain and/or the maximum period documents should be written to it. Once one of these criteria has been exceeded, Elasticsearch can trigger a new index to be created for writing without downtime. Instead of having each index cover a specific time-period, it is now possible to switch to a new index at a specific size, which makes it possible to more easily achieve an even shard size for all indices.</p><p>In cases where data might be updated, there is no longer a distinct link between the timestamp of the event and the index it resides in when using this API, which may make updates significantly less efficient as each update may need to be preceded by a search.</p><hr/><p style=\"margin-left: 20px;\"><em><strong>TIP: </strong></em><em>If you have time-based, immutable data where volumes can vary significantly over time, consider using the rollover index API to achieve an optimal target shard size by dynamically varying the time-period each index covers. This gives great flexibility and can help avoid having too large or too small shards when volumes are unpredictable.</em><br/></p><hr/><p>The <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/5.5/indices-shrink-index.html\" target=\"_self\">shrink index API</a> allows you to shrink an existing index into a new index with fewer primary shards. If an even spread of shards across nodes is desired during indexing, but this will result in too small shards, this API can be used to reduce the number of primary shards once the index is no longer indexed into. This will result in larger shards, better suited for longer term storage of data.<br/></p><hr/><p style=\"margin-left: 20px;\"><em><strong>TIP: </strong></em><em>If you need to have each index cover a specific time period but still want to be able to spread indexing out across a large number of nodes, consider using the shrink API to reduce the number of primary shards once the index is no longer indexed into. This API can also be used to reduce the number of shards in case you have initially configured too many shards.</em><br/></p><hr/><h2 dir=\"ltr\">Conclusions</h2><p>This blog post has provided tips and practical guidelines around how to best manage data in Elasticsearch. If you are interested in learning more, \"Elasticsearch: the definitive guide\" contains a section about <a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/2.x/scale.html\" target=\"_self\">designing for scale</a>, which is well worth reading even though it is a bit old.</p><p>A lot of the decisions around how to best distribute your data across indices and shards will however depend on the use-case specifics, and it can sometimes be hard to determine how to best apply the advice available. For more in-depth and personal advice you can engage with us <a href=\"https://www.elastic.co/subscriptions\" target=\"_self\">commercially through a subscription</a> and let our Support and Consulting teams help accelerate your project. If you are happy to discuss your use-case in the open, you can also get help from <a href=\"https://www.elastic.co/community\" target=\"_self\">our community</a> and through our public <a href=\"https://discuss.elastic.co\" target=\"_self\">forum</a>.</p><p><br/><em>This post was originally published on September 18, 2017. It was updated on July 6, 2022.</em></p>","PublishedAt":"2022-07-06 15:46:16+00:00","OriginURL":"https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster","SourceName":"Elastic"}},{"node":{"ID":559,"Title":"Why Perl is still relevant in 2022","Description":"<p>While Perl might seem like an outdated scripting language, it still has plenty of relevant uses today. </p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/07/06/why-perl-is-still-relevant-in-2022/\">Why Perl is still relevant in 2022</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-07-06 14:30:31+00:00","OriginURL":"https://stackoverflow.blog/2022/07/06/why-perl-is-still-relevant-in-2022/","SourceName":"Stack Overflow"}},{"node":{"ID":77,"Title":"Start, Finish, Repeat: Introducing Recurring Tasks","Description":"<p>Tasks in Evernote is now even better at helping you stay organized and on-track, thanks to the addition of one of your most requested features: recurring tasks.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://evernote.com/blog/introducing-recurring-tasks/\">Start, Finish, Repeat: Introducing Recurring Tasks</a> appeared first on <a rel=\"nofollow\" href=\"https://evernote.com/blog\">evernote.com | Blog</a>.</p>\n","PublishedAt":"2022-07-05 20:41:00+00:00","OriginURL":"https://evernote.com/blog/introducing-recurring-tasks/","SourceName":"Evernote"}},{"node":{"ID":442,"Title":"Mobile app user journeys: definitions, analysis, and best practices","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2022/06/MXP-Blog-AppUserJourneys-1920x1080-1-1-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>User journeys are one of the most powerful tools for building great mobile apps. And when employed with thoughtfulness and rigor, they can be your golden ticket to first-class rates of conversion, retention, and engagement. The problem is user journeys are often misunderstood and conflated with other industry concepts like user flows and funnels, leading</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/mobile-app-user-journeys-best-practices-mixpanel/\">Mobile app user journeys: definitions, analysis, and best practices</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2022-07-05 15:50:52+00:00","OriginURL":"https://mixpanel.com/blog/mobile-app-user-journeys-best-practices-mixpanel/","SourceName":"Mixpanel"}},{"node":{"ID":560,"Title":"Developers vs the difficulty bomb (Ep. 459)","Description":"<p>Developers on a deadline. Failure to ship means an explosion of complexity. Finish the project...or just find a way to delay the boom.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/07/05/developers-vs-the-difficulty-bomb-ep-459/\">Developers vs the difficulty bomb (Ep. 459)</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-07-05 04:40:00+00:00","OriginURL":"https://stackoverflow.blog/2022/07/05/developers-vs-the-difficulty-bomb-ep-459/","SourceName":"Stack Overflow"}},{"node":{"ID":1017,"Title":"Proactively monitor service performance with SLO alerts","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/monitor-service-performance-with-slo-alerts/slo-alerting-feature-hero.png\" width=\"100%\"/>Service level objectives (SLOs) state your team&rsquo;s goals for maintaining the reliability of your services. Adopting SLOs is an SRE best practice because it can help you ensure that your services perform well and consistently deliver value to users. But to gain the greatest benefit from your SLOs, you need ongoing visibility into how well your services are performing relative to your objectives.SLO alerts automatically notify your team if a service&rsquo;s performance might result in an SLO breach.","PublishedAt":"2022-07-05 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/monitor-service-performance-with-slo-alerts/","SourceName":"Datadog"}},{"node":{"ID":23,"Title":"AWS Week in Review – July 4, 2022","Description":"This post is part of our Week in Review series. Check back each week for a quick roundup of interesting news and announcements from AWS! Summer has arrived in Finland, and these last few days have been hotter than in the Canary Islands! Today in the US it is Independence Day. I hope that if […]","PublishedAt":"2022-07-04 18:06:23+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/aws-week-in-review-july-04-2022/","SourceName":"AWS"}},{"node":{"ID":1037,"Title":"An Example of Applying DDL to MySQL DBs with Special Structures","Description":"<p>This article is a translation of the Japanese article published on February 17th, 2022. This article is part of our &quot;Blog Series of Introduction of Developer Productivity Engineering at Mercari.&quot; Author: @ichirin2501 (Core SRE Team) In this article, I explain how I was able to overcome some constraints on special replica DBs, and apply DDL [&hellip;]</p>\n","PublishedAt":"2022-07-04 14:00:38+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20220217-d0d6aa21fe/","SourceName":"Mercari"}},{"node":{"ID":561,"Title":"How Stack Overflow is leveling up its unit testing game","Description":"<p>We neglected unit tests for a long time because our code base made them difficult. But now we're putting in the work to change that. </p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/07/04/how-stack-overflow-is-leveling-up-its-unit-testing-game/\">How Stack Overflow is leveling up its unit testing game</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-07-04 14:00:00+00:00","OriginURL":"https://stackoverflow.blog/2022/07/04/how-stack-overflow-is-leveling-up-its-unit-testing-game/","SourceName":"Stack Overflow"}},{"node":{"ID":443,"Title":"Creating a great product onboarding experience","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2019/11/MXP-Blog-GreatProductOnboardingExp-1920x1080-1-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>First impressions are critical for a successful product. The moments after someone opens a new app influence future retention and usage. A good product onboarding experience can help achieve product-market fit and drive revenue, while a poor experience can drive customers away.&#160; We use the terms “product onboarding” and “user onboarding” interchangeably; you can read</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/elements-successful-onboarding/\">Creating a great product onboarding experience</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2022-07-02 15:00:00+00:00","OriginURL":"https://mixpanel.com/blog/elements-successful-onboarding/","SourceName":"Mixpanel"}},{"node":{"ID":562,"Title":"Seeing is believing: The Stack Overflow Podcast now available as video","Description":"<p>Listen up, you can see us now. The Stack Overflow podcast is coming to video.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/07/01/seeing-is-believing-the-stack-overflow-podcast-now-available-as-video/\">Seeing is believing: The Stack Overflow Podcast now available as video</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-07-01 14:47:54+00:00","OriginURL":"https://stackoverflow.blog/2022/07/01/seeing-is-believing-the-stack-overflow-podcast-now-available-as-video/","SourceName":"Stack Overflow"}},{"node":{"ID":563,"Title":"The Overflow #132: The 2022 Dev Survey results!","Description":"<p>WWDC 2022, first operating system, and 3D scenes from 2D images</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/07/01/the-overflow-132-the-2022-dev-survey-results/\">The Overflow #132: The 2022 Dev Survey results!</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-07-01 14:00:00+00:00","OriginURL":"https://stackoverflow.blog/2022/07/01/the-overflow-132-the-2022-dev-survey-results/","SourceName":"Stack Overflow"}},{"node":{"ID":158,"Title":"#ClouderaLife Spotlight: Autymn Harris and Jonathan Sanford","Description":"<p>Celebrating Pride Month, reflecting on work that still needs to be done</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/clouderalife-spotlight-autymn-harris-and-jonathan-sanford/\">#ClouderaLife Spotlight: Autymn Harris and Jonathan Sanford</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-07-01 11:06:30+00:00","OriginURL":"https://blog.cloudera.com/clouderalife-spotlight-autymn-harris-and-jonathan-sanford/","SourceName":"Cloudera"}},{"node":{"ID":564,"Title":"Exploring the interesting and strange results from our 2022 Developer Survey (Ep. 458)","Description":"<p>Ben and Matt unpack the results of the 2022 Stack Overflow Developer Survey.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/07/01/exploring-the-interesting-and-strange-results-from-our-2022-developer-survey-ep-458/\">Exploring the interesting and strange results from our 2022 Developer Survey (Ep. 458)</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-07-01 04:40:00+00:00","OriginURL":"https://stackoverflow.blog/2022/07/01/exploring-the-interesting-and-strange-results-from-our-2022-developer-survey-ep-458/","SourceName":"Stack Overflow"}},{"node":{"ID":1018,"Title":"Catch attacks at the network layer with DNS-based threat detection","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/dns-based-threat-detection/dns-based-threat-detection-hero.png\" width=\"100%\"/>The Domain Name System (DNS) is responsible for mapping client-facing domain names to their corresponding IP addresses, making it a fundamental element of the internet. DNS-level events provide valuable information about network traffic that can be used to identify malicious activity. For instance, monitoring DNS lookups can help you see whether a host on your network attempted to connect to a site known to contain malware. That&rsquo;s why we&rsquo;re pleased to announce that Datadog&rsquo;s eBPF-powered Cloud Workload Security (CWS) now analyzes DNS activity—in addition to file and process activity— to detect security threats in real time.","PublishedAt":"2022-07-01 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/dns-based-threat-detection/","SourceName":"Datadog"}},{"node":{"ID":1019,"Title":"Join us at Datadog Summit Sydney","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/datadog-summit-sydney-2022/dd_summit_sydney_hero_04.png\" width=\"100%\"/>Datadog is built on community—from the engineers and SREs whose feedback helps us constantly improve, to the developers who share integrations that broaden the Datadog ecosystem. Datadog Summit is our celebration of community.We&rsquo;re excited to be back in person! Our next Datadog Summit will be held on August 16 in Sydney. We hope you&rsquo;ll join us to meet and learn from others in the community, as well as from the Datadog team.","PublishedAt":"2022-07-01 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/datadog-summit-sydney-2022/","SourceName":"Datadog"}},{"node":{"ID":1020,"Title":"Monitor Azure Functions with the Datadog extension for Azure App Service","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/azure-app-service-extension-support-for-azure-functions/azure-functions-apm-hero.png\" width=\"100%\"/>Azure Functions is an on-demand serverless compute offering built on top of Azure App Service that enables you to deploy event-driven code without the need to provision and manage infrastructure. Because applications rely on Azure Functions to handle business-critical tasks such as processing orders or logging in users, it&rsquo;s important to ensure that your functions respond quickly when they&rsquo;re invoked.Earlier this year, we released the Datadog extension for Azure App Service which collects traces and automatically correlates telemetry from resources running in Azure App Service.","PublishedAt":"2022-07-01 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/azure-app-service-extension-support-for-azure-functions/","SourceName":"Datadog"}},{"node":{"ID":93,"Title":"Write Better Commits, Build Better Projects","Description":"High-quality Git commits are the key to a maintainable and collaborative open- or closed-source project. Learn strategies to improve and use commits to streamline your development process.","PublishedAt":"2022-06-30 19:34:33+00:00","OriginURL":"https://github.blog/2022-06-30-write-better-commits-build-better-projects/","SourceName":"GitHub"}},{"node":{"ID":742,"Title":"Introducing Shadower: A Minimalistic Load Testing Tool","Description":"<h1><span style=\"font-weight: 400;\">Introduction</span></h1>\n<p><span style=\"font-weight: 400;\">Shadower is a load testing tool that allows us to provide load testing as a service to any microservice at Uber.</span></p>\n<p><span style=\"font-weight: 400;\">Shadower started as a command line application that allowed us to read a local file to load test </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/introducing-shadower-a-minimalistic-load-testing-tool/\">Introducing Shadower: A Minimalistic Load Testing Tool</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2022-06-30 16:30:08+00:00","OriginURL":"https://eng.uber.com/introducing-shadower-a-minimalistic-load-testing-tool/","SourceName":"Uber"}},{"node":{"ID":1038,"Title":"What it’s like to work as an embedded microservices SRE","Description":"<p>Hello! This is shmizumo, an SRE at Mercari. In this article, I will introduce several improvements being made by the Microservices SRE Team, embedded with other teams. You can read more about the Microservices SRE Team here: Embedded SRE at Mercari. Working embedded I joined Mercari in May 2021. I first started working with the [&hellip;]</p>\n","PublishedAt":"2022-06-30 16:00:49+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20220228-work-as-an-embedded-microservices-sre/","SourceName":"Mercari"}},{"node":{"ID":106,"Title":"Waypoint 0.9 Adds New Runner Commands","Description":"HashiCorp Waypoint 0.9 introduces on-demand runner introspection, a runner install command, and support for HCP Waypoint.","PublishedAt":"2022-06-30 16:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/waypoint-0-9-adds-new-runner-commands","SourceName":"HashiCorp"}},{"node":{"ID":78,"Title":"Home at Work, Not Just ‘Work From Home’","Description":"<p>Top tips to manage your productivity when you work from home and how to master a work-life balance that meets your professional and personal needs.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://evernote.com/blog/beyond-work-from-home/\">Home at Work, Not Just &#8216;Work From Home&#8217;</a> appeared first on <a rel=\"nofollow\" href=\"https://evernote.com/blog\">evernote.com | Blog</a>.</p>\n","PublishedAt":"2022-06-30 13:30:00+00:00","OriginURL":"https://evernote.com/blog/beyond-work-from-home/","SourceName":"Evernote"}},{"node":{"ID":159,"Title":"Supercharge Your Data Lakehouse with Apache Iceberg in Cloudera Data Platform","Description":"<p>Cloudera Technology Spotlight</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/supercharge-your-data-lakehouse-with-apache-iceberg-in-cloudera-data-platform/\">Supercharge Your Data Lakehouse with Apache Iceberg in Cloudera Data Platform</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-06-30 13:00:39+00:00","OriginURL":"https://blog.cloudera.com/supercharge-your-data-lakehouse-with-apache-iceberg-in-cloudera-data-platform/","SourceName":"Cloudera"}},{"node":{"ID":1021,"Title":"Analyze wait events and in-flight queries with the Datadog Database List","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/database-troubleshooting-with-datadog-database-list/database_list_hero.png\" width=\"100%\"/>When you&rsquo;re operating databases at scale, being able to get real-time insights across all your databases is essential for addressing issues and identifying areas for optimization. Datadog Database Monitoring’s Database List allows you to monitor your entire database fleet in one place, so you can quickly identify and troubleshoot overloaded hosts and gauge the impact of problematic queries throughout your infrastructure. With active connection information, you can easily analyze the specific queries affecting database performance.","PublishedAt":"2022-06-30 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/database-troubleshooting-with-datadog-database-list/","SourceName":"Datadog"}},{"node":{"ID":536,"Title":"How Tinder Solves Complex Lottie Localizations with Server Driven UI","Description":"","PublishedAt":"2022-06-29 19:14:52+00:00","OriginURL":"https://medium.com/tinder/how-tinder-solves-complex-lottie-localizations-with-server-driven-ui-e307c6bab137?source=rss----906928af8599---4","SourceName":"Tinder"}},{"node":{"ID":412,"Title":"Career stories: Next plays, jungle gyms, and Python","Description":"Since she was a child, Deepti has been motivated to help people. This drive led her on a career journey with many pivots and moves — akin to navigating a children’s jungle gym — between industries and around the world. Based in Bangalore, this biomedical engineer turned data scientist shares how LinkedIn helped her gain new technical skills, dive into meaningful work, and grow. Growing up in Mumbai, India, I always imagined myself in a career where I could give back. I once dreamed of becoming a neurosurgeon, but early in my career, I took a different path and earned a bachelor’s in [&#8230;]","PublishedAt":"2022-06-29 18:14:00+00:00","OriginURL":"https://engineering.linkedin.com/blog/2022/career-stories--next-plays--jungle-gyms--and-python","SourceName":"Linkedin"}},{"node":{"ID":94,"Title":"Improve Git monorepo performance with a file system monitor","Description":"Monorepo performance can suffer due to the sheer number of files in your working directory. Git’s new builtin file system monitor makes it easy to speed up monorepo performance.","PublishedAt":"2022-06-29 17:00:02+00:00","OriginURL":"https://github.blog/2022-06-29-improve-git-monorepo-performance-with-a-file-system-monitor/","SourceName":"GitHub"}},{"node":{"ID":107,"Title":"Reflections on Juneteenth","Description":"Eight members of the HashiCorp Blacksmiths’ employee resource group share how they spent Juneteenth this year, and reflect on what they learned.","PublishedAt":"2022-06-29 17:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/reflections-on-juneteenth","SourceName":"HashiCorp"}},{"node":{"ID":565,"Title":"Skilling up to architect: What you need to land high-paying IT roles","Description":"<p>﻿If you want to climb the career ladder to architect roles, you're going to have a broad base of competencies. ﻿Whether it's in cloud, security, or data science, we break down how you can land architect roles and the skills you need to learn to pay the bills.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/06/29/skilling-up-to-architect-what-you-need-to-land-high-paying-it-roles/\">Skilling up to architect: What you need to land high-paying IT roles</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-06-29 14:47:48+00:00","OriginURL":"https://stackoverflow.blog/2022/06/29/skilling-up-to-architect-what-you-need-to-land-high-paying-it-roles/","SourceName":"Stack Overflow"}}]}},"pageContext":{"limit":30,"skip":4650,"numPages":193,"currentPage":156}},"staticQueryHashes":["3649515864"]}