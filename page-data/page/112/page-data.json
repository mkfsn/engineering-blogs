{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/112","result":{"data":{"allPost":{"edges":[{"node":{"ID":2434,"Title":"You Can’t Hit What You Can’t See","Description":"<p>Bringing Better Data Observability Into the Enterprise Stack</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/you-cant-hit-what-you-cant-see/\">You Can’t Hit What You Can’t See</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-12-01 14:00:17+00:00","OriginURL":"https://blog.cloudera.com/you-cant-hit-what-you-cant-see/","SourceName":"Cloudera"}},{"node":{"ID":2433,"Title":"Mercari Hack Fest : Unlimited Hacktivity &#8211; The Result!","Description":"<p>Hello everyone, this is Yoza from the Engineering Office. This post is for Day 1 of Mercari Advent Calendar 2022. As I shared in a previous blog, Mercari holds a regular Technology festival where Mercari Employees are able to devote time to creating their own “Innovations”. The most recent event was successfully held on November [&hellip;]</p>\n","PublishedAt":"2022-12-01 11:00:59+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20221118-mercari-hack-fest-unlimited-hacktivity-the-result/","SourceName":"Mercari"}},{"node":{"ID":2432,"Title":"Blog: Boosting Kubernetes container runtime observability with OpenTelemetry","Description":"<p><strong>Authors:</strong> Sascha Grunert</p>\n<p>When speaking about observability in the cloud native space, then probably\neveryone will mention <a href=\"https://opentelemetry.io\">OpenTelemetry (OTEL)</a> at some point in the\nconversation. That's great, because the community needs standards to rely on\nfor developing all cluster components into the same direction. OpenTelemetry\nenables us to combine logs, metrics, traces and other contextual information\n(called baggage) into a single resource. Cluster administrators or software\nengineers can use this resource to get a viewport about what is going on in the\ncluster over a defined period of time. But how can Kubernetes itself make use of\nthis technology stack?</p>\n<p>Kubernetes consists of multiple components where some are independent and others\nare stacked together. Looking at the architecture from a container runtime\nperspective, then there are from the top to the bottom:</p>\n<ul>\n<li><strong>kube-apiserver</strong>: Validates and configures data for the API objects</li>\n<li><strong>kubelet</strong>: Agent running on each node</li>\n<li><strong>CRI runtime</strong>: Container Runtime Interface (CRI) compatible container runtime\nlike <a href=\"https://cri-o.io\">CRI-O</a> or <a href=\"https://containerd.io\">containerd</a></li>\n<li><strong>OCI runtime</strong>: Lower level <a href=\"https://opencontainers.org\">Open Container Initiative (OCI)</a> runtime\nlike <a href=\"https://github.com/opencontainers/runc\">runc</a> or <a href=\"https://github.com/containers/crun\">crun</a></li>\n<li><strong>Linux kernel</strong> or <strong>Microsoft Windows</strong>: Underlying operating system</li>\n</ul>\n<p>That means if we encounter a problem with running containers in Kubernetes, then\nwe start looking at one of those components. Finding the root cause for problems\nis one of the most time consuming actions we face with the increased\narchitectural complexity from today's cluster setups. Even if we know the\ncomponent which seems to cause the issue, we still have to take the others into\naccount to maintain a mental timeline of events which are going on. How do we\nachieve that? Well, most folks will probably stick to scraping logs, filtering\nthem and assembling them together over the components borders. We also have\nmetrics, right? Correct, but bringing metrics values in correlation with plain\nlogs makes it even harder to track what is going on. Some metrics are also not\nmade for debugging purposes. They have been defined based on the end user\nperspective of the cluster for linking usable alerts and not for developers\ndebugging a cluster setup.</p>\n<p>OpenTelemetry to the rescue: the project aims to combine signals such as\n<a href=\"https://opentelemetry.io/docs/concepts/signals/traces\">traces</a>, <a href=\"https://opentelemetry.io/docs/concepts/signals/metrics\">metrics</a> and <a href=\"https://opentelemetry.io/docs/concepts/signals/logs\">logs</a> together to maintain the\nright viewport on the cluster state.</p>\n<p>What is the current state of OpenTelemetry tracing in Kubernetes? From an API\nserver perspective, we have alpha support for tracing since Kubernetes v1.22,\nwhich will graduate to beta in one of the upcoming releases. Unfortunately the\nbeta graduation has missed the v1.26 Kubernetes release. The design proposal can\nbe found in the <a href=\"https://github.com/kubernetes/enhancements/issues/647\"><em>API Server Tracing</em> Kubernetes Enhancement Proposal\n(KEP)</a> which provides more information about it.</p>\n<p>The kubelet tracing part is tracked <a href=\"https://github.com/kubernetes/enhancements/issues/2831\">in another KEP</a>, which was\nimplemented in an alpha state in Kubernetes v1.25. A beta graduation is not\nplanned as time of writing, but more may come in the v1.27 release cycle.\nThere are other side-efforts going on beside both KEPs, for example <a href=\"https://github.com/kubernetes/klog/issues/356\">klog is\nconsidering OTEL support</a>, which would boost the observability by\nlinking log messages to existing traces. Within SIG Instrumentation and SIG Node,\nwe're also discussing <a href=\"https://github.com/kubernetes/kubernetes/issues/113414\">how to link the\nkubelet traces together</a>, because right now they're focused on the\n<a href=\"https://grpc.io\">gRPC</a> calls between the kubelet and the CRI container runtime.</p>\n<p>CRI-O features OpenTelemetry tracing support <a href=\"https://github.com/cri-o/cri-o/pull/4883\">since v1.23.0</a> and is\nworking on continuously improving them, for example by <a href=\"https://github.com/cri-o/cri-o/pull/6294\">attaching the logs to the\ntraces</a> or extending the <a href=\"https://github.com/cri-o/cri-o/pull/6343\">spans to logical parts of the\napplication</a>. This helps users of the traces to gain the same\ninformation like parsing the logs, but with enhanced capabilities of scoping and\nfiltering to other OTEL signals. The CRI-O maintainers are also working on a\ncontainer monitoring replacement for <a href=\"https://github.com/containers/conmon\">conmon</a>, which is called\n<a href=\"https://github.com/containers/conmon-rs\">conmon-rs</a> and is purely written in <a href=\"https://www.rust-lang.org\">Rust</a>. One benefit of\nhaving a Rust implementation is to be able to add features like OpenTelemetry\nsupport, because the crates (libraries) for those already exist. This allows a\ntight integration with CRI-O and lets consumers see the most low level tracing\ndata from their containers.</p>\n<p>The <a href=\"https://containerd.io\">containerd</a> folks added tracing support since v1.6.0, which is\navailable <a href=\"https://github.com/containerd/containerd/blob/7def13d/docs/tracing.md\">by using a plugin</a>. Lower level OCI runtimes like\n<a href=\"https://github.com/opencontainers/runc\">runc</a> or <a href=\"https://github.com/containers/crun\">crun</a> feature no support for OTEL at all and it does not\nseem to exist a plan for that. We always have to consider that there is a\nperformance overhead when collecting the traces as well as exporting them to a\ndata sink. I still think it would be worth an evaluation on how extended\ntelemetry collection could look like in OCI runtimes. Let's see if the Rust OCI\nruntime <a href=\"https://github.com/containers/youki/issues/1348\">youki</a> is considering something like that in the future.</p>\n<p>I'll show you how to give it a try. For my demo I'll stick to a stack with a single local node\nthat has runc, conmon-rs, CRI-O, and a kubelet. To enable tracing in the kubelet, I need to\napply the following <code>KubeletConfiguration</code>:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>kubelet.config.k8s.io/v1beta1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>KubeletConfiguration<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">featureGates</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">KubeletTracing</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#a2f;font-weight:bold\">true</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">tracing</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">samplingRatePerMillion</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">1000000</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>A <code>samplingRatePerMillion</code> equally to one million will internally translate to\nsampling everything. A similar configuration has to be applied to CRI-O; I can\neither start the <code>crio</code> binary with <code>--enable-tracing</code> and\n<code>--tracing-sampling-rate-per-million 1000000</code> or we use a drop-in configuration\nlike this:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat /etc/crio/crio.conf.d/99-tracing.conf\n</span></span></code></pre></div><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-toml\" data-lang=\"toml\"><span style=\"display:flex;\"><span>[crio.tracing]\n</span></span><span style=\"display:flex;\"><span>enable_tracing = <span style=\"color:#a2f;font-weight:bold\">true</span>\n</span></span><span style=\"display:flex;\"><span>tracing_sampling_rate_per_million = <span style=\"color:#666\">1000000</span>\n</span></span></code></pre></div><p>To configure CRI-O to use conmon-rs, you require at least the latest CRI-O\nv1.25.x and conmon-rs v0.4.0. Then a configuration drop-in like this can be used\nto make CRI-O use conmon-rs:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat /etc/crio/crio.conf.d/99-runtimes.conf\n</span></span></code></pre></div><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-toml\" data-lang=\"toml\"><span style=\"display:flex;\"><span>[crio.runtime]\n</span></span><span style=\"display:flex;\"><span>default_runtime = <span style=\"color:#b44\">&#34;runc&#34;</span>\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span>[crio.runtime.runtimes.runc]\n</span></span><span style=\"display:flex;\"><span>runtime_type = <span style=\"color:#b44\">&#34;pod&#34;</span>\n</span></span><span style=\"display:flex;\"><span>monitor_path = <span style=\"color:#b44\">&#34;/path/to/conmonrs&#34;</span> <span style=\"color:#080;font-style:italic\"># or will be looked up in $PATH</span>\n</span></span></code></pre></div><p>That's it, the default configuration will point to an <a href=\"https://opentelemetry.io/docs/collector/getting-started\">OpenTelemetry\ncollector</a> <a href=\"https://grpc.io\">gRPC</a> endpoint of <code>localhost:4317</code>, which has to be up and\nrunning as well. There are multiple ways to run OTLP as <a href=\"https://opentelemetry.io/docs/collector/getting-started\">described in the\ndocs</a>, but it's also possible to <code>kubectl proxy</code> into an existing\ninstance running within Kubernetes.</p>\n<p>If everything is set up, then the collector should log that there are incoming\ntraces:</p>\n<pre tabindex=\"0\"><code>ScopeSpans #0\nScopeSpans SchemaURL:\nInstrumentationScope go.opentelemetry.io/otel/sdk/tracer\nSpan #0\nTrace ID : 71896e69f7d337730dfedb6356e74f01\nParent ID : a2a7714534c017e6\nID : 1d27dbaf38b9da8b\nName : github.com/cri-o/cri-o/server.(*Server).filterSandboxList\nKind : SPAN_KIND_INTERNAL\nStart time : 2022-11-15 09:50:20.060325562 +0000 UTC\nEnd time : 2022-11-15 09:50:20.060326291 +0000 UTC\nStatus code : STATUS_CODE_UNSET\nStatus message :\nSpan #1\nTrace ID : 71896e69f7d337730dfedb6356e74f01\nParent ID : a837a005d4389579\nID : a2a7714534c017e6\nName : github.com/cri-o/cri-o/server.(*Server).ListPodSandbox\nKind : SPAN_KIND_INTERNAL\nStart time : 2022-11-15 09:50:20.060321973 +0000 UTC\nEnd time : 2022-11-15 09:50:20.060330602 +0000 UTC\nStatus code : STATUS_CODE_UNSET\nStatus message :\nSpan #2\nTrace ID : fae6742709d51a9b6606b6cb9f381b96\nParent ID : 3755d12b32610516\nID : 0492afd26519b4b0\nName : github.com/cri-o/cri-o/server.(*Server).filterContainerList\nKind : SPAN_KIND_INTERNAL\nStart time : 2022-11-15 09:50:20.0607746 +0000 UTC\nEnd time : 2022-11-15 09:50:20.060795505 +0000 UTC\nStatus code : STATUS_CODE_UNSET\nStatus message :\nEvents:\nSpanEvent #0\n-&gt; Name: log\n-&gt; Timestamp: 2022-11-15 09:50:20.060778668 +0000 UTC\n-&gt; DroppedAttributesCount: 0\n-&gt; Attributes::\n-&gt; id: Str(adf791e5-2eb8-4425-b092-f217923fef93)\n-&gt; log.message: Str(No filters were applied, returning full container list)\n-&gt; log.severity: Str(DEBUG)\n-&gt; name: Str(/runtime.v1.RuntimeService/ListContainers)\n</code></pre><p>I can see that the spans have a trace ID and typically have a parent attached.\nEvents such as logs are part of the output as well. In the above case, the kubelet is\nperiodically triggering a <code>ListPodSandbox</code> RPC to CRI-O caused by the Pod\nLifecycle Event Generator (PLEG). Displaying those traces can be done via,\nfor example, <a href=\"https://www.jaegertracing.io/\">Jaeger</a>. When running the tracing stack locally, then a Jaeger\ninstance should be exposed on <code>http://localhost:16686</code> per default.</p>\n<p>The <code>ListPodSandbox</code> requests are directly visible within the Jaeger UI:</p>\n<p><img src=\"list_pod_sandbox.png\" alt=\"ListPodSandbox RPC in the Jaeger UI\"></p>\n<p>That's not too exciting, so I'll run a workload directly via <code>kubectl</code>:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl run -it --rm --restart<span style=\"color:#666\">=</span>Never --image<span style=\"color:#666\">=</span>alpine alpine -- <span style=\"color:#a2f\">echo</span> hi\n</span></span></code></pre></div><pre tabindex=\"0\"><code>hi\npod &#34;alpine&#34; deleted\n</code></pre><p>Looking now at Jaeger, we can see that we have traces for <code>conmonrs</code>, <code>crio</code> as\nwell as the <code>kubelet</code> for the <code>RunPodSandbox</code> and <code>CreateContainer</code> CRI RPCs:</p>\n<p><img src=\"create_container.png\" alt=\"Container creation in the Jaeger UI\"></p>\n<p>The kubelet and CRI-O spans are connected to each other to make investigation\neasier. If we now take a closer look at the spans, then we can see that CRI-O's\nlogs are correctly accosted with the corresponding functionality. For example we\ncan extract the container user from the traces like this:</p>\n<p><img src=\"crio_spans.png\" alt=\"CRI-O in the Jaeger UI\"></p>\n<p>The lower level spans of conmon-rs are also part of this trace. For example\nconmon-rs maintains an internal <code>read_loop</code> for handling IO between the\ncontainer and the end user. The logs for reading and writing bytes are part of\nthe span. The same applies to the <code>wait_for_exit_code</code> span, which tells us that\nthe container exited successfully with code <code>0</code>:</p>\n<p><img src=\"conmonrs_spans.png\" alt=\"conmon-rs in the Jaeger UI\"></p>\n<p>Having all that information at hand side by side to the filtering capabilities\nof Jaeger makes the whole stack a great solution for debugging container issues!\nMentioning the &quot;whole stack&quot; also shows the biggest downside of the overall\napproach: Compared to parsing logs it adds a noticeable overhead on top of the\ncluster setup. Users have to maintain a sink like <a href=\"https://www.elastic.co\">Elasticsearch</a> to\npersist the data, expose the Jaeger UI and possibly take the performance\ndrawback into account. Anyways, it's still one of the best ways to increase the\nobservability aspect of Kubernetes.</p>\n<p>Thank you for reading this blog post, I'm pretty sure we're looking into a\nbright future for OpenTelemetry support in Kubernetes to make troubleshooting\nsimpler.</p>","PublishedAt":"2022-12-01 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/12/01/runtime-observability-opentelemetry/","SourceName":"Kubernetes"}},{"node":{"ID":2435,"Title":"Elastic named a Major Player in the IDC MarketScape: Worldwide SIEM 2022 Vendor Assessment","Description":"","PublishedAt":"2022-12-01 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/elastic-named-major-player-idc-marketscape-worldwide-siem-2022","SourceName":"Elastic"}},{"node":{"ID":2442,"Title":"An embeddable and customizable fiat-to-crypto onramp","Description":"Introducing an embeddable and customizable fiat-to-crypto onramp. Let customers buy crypto within your Web3 app with one click. Tailor the onramp to match your brand, and we’ll take care of the rest: KYC, fraud, and disputes.","PublishedAt":"2022-12-01 00:00:00+00:00","OriginURL":"https://stripe.com/blog/crypto-onramp","SourceName":"Stripe"}},{"node":{"ID":2431,"Title":"AWS Marketplace Vendor Insights – Simplify Third-Party Software Risk Assessments","Description":"AWS Marketplace Vendor Insights is a new capability of AWS Marketplace. It simplifies third-party software risk assessments when procuring solutions from the AWS Marketplace. It helps you to ensure that the third-party software continuously meets your industry standards by compiling security and compliance information, such as data privacy and residency, application security, and access control, […]","PublishedAt":"2022-11-30 23:49:57+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/aws-marketplace-vendor-insights-simplify-third-party-software-risk-assessments/","SourceName":"AWS"}},{"node":{"ID":2430,"Title":"How to Deploy Transaction Support on Cloudera Operational Database (COD)","Description":"<p>What is Cloudera Operational Database (COD) Cloudera Operational Database enables developers to quickly build future-proof applications that are architected to handle data evolution. It helps developers automate and simplify database management with capabilities like auto-scale, and is fully integrated with Cloudera Data Platform (CDP). For more information and to get started with COD, refer to [&#8230;]</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/how-to-deploy-transaction-support-on-cloudera-operational-database-cod/\">How to Deploy Transaction Support on Cloudera Operational Database (COD)</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-11-30 21:36:06+00:00","OriginURL":"https://blog.cloudera.com/how-to-deploy-transaction-support-on-cloudera-operational-database-cod/","SourceName":"Cloudera"}},{"node":{"ID":2429,"Title":"CEO Ash Kulkarni's email to Elastic employees","Description":"","PublishedAt":"2022-11-30 21:00:00+00:00","OriginURL":"https://www.elastic.co/blog/ceo-ash-kulkarni-email-to-elastic-employees","SourceName":"Elastic"}},{"node":{"ID":2428,"Title":"Transaction Support in Cloudera Operational Database (COD)","Description":"<p>What is CDP Operational Database (COD) CDP Operational Database enables developers to quickly build future-proof applications that are architected to handle data evolution. It helps developers automate and simplify database management with capabilities like auto-scale, and is fully integrated with Cloudera Data Platform (CDP). For more information and to get started with COD, refer to [&#8230;]</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/transaction-support-in-cloudera-operational-database-cod/\">Transaction Support in Cloudera Operational Database (COD)</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-11-30 20:57:02+00:00","OriginURL":"https://blog.cloudera.com/transaction-support-in-cloudera-operational-database-cod/","SourceName":"Cloudera"}},{"node":{"ID":2427,"Title":"HashiCorp Terraform and AWS: re:Invent Caps Off a Big Year","Description":"AWS re:Invent 2022 is here. We highlighted what’s new with Terraform and AWS — like Launch Day support for new AWS services in the Terraform AWS Provider.","PublishedAt":"2022-11-30 20:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/hashicorp-terraform-and-aws-re-invent-caps-off-a-big-year","SourceName":"HashiCorp"}},{"node":{"ID":2416,"Title":"New for Amazon SageMaker – Perform Shadow Tests to Compare Inference Performance Between ML Model Variants","Description":"As you move your machine learning (ML) workloads into production, you need to continuously monitor your deployed models and iterate when you observe a deviation in your model performance. When you build a new model, you typically start validating the model offline using historical inference request data. But this data sometimes fails to account for […]","PublishedAt":"2022-11-30 18:36:48+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-for-amazon-sagemaker-perform-shadow-tests-to-compare-inference-performance-between-ml-model-variants/","SourceName":"AWS"}},{"node":{"ID":2417,"Title":"Next Generation SageMaker Notebooks – Now with Built-in Data Preparation, Real-Time Collaboration, and Notebook Automation","Description":"In 2019, we introduced Amazon SageMaker Studio, the first fully integrated development environment (IDE) for data science and machine learning (ML). SageMaker Studio gives you access to fully managed Jupyter Notebooks that integrate with purpose-built tools to perform all ML steps, from preparing data to training and debugging models, tracking experiments, deploying and monitoring models, […]","PublishedAt":"2022-11-30 18:34:59+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/next-generation-sagemaker-notebooks-now-with-built-in-data-preparation-real-time-collaboration-and-notebook-automation/","SourceName":"AWS"}},{"node":{"ID":2418,"Title":"New – Share ML Models and Notebooks More Easily Within Your Organization with Amazon SageMaker JumpStart","Description":"Amazon SageMaker JumpStart is a machine learning (ML) hub that can help you accelerate your ML journey. SageMaker JumpStart gives you access to built-in algorithms with pre-trained models from popular model hubs, pre-trained foundation models to help you perform tasks such as article summarization and image generation, and end-to-end solutions to solve common use cases. […]","PublishedAt":"2022-11-30 18:32:44+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-share-ml-models-and-notebooks-more-easily-within-your-organization-with-amazon-sagemaker-jumpstart/","SourceName":"AWS"}},{"node":{"ID":2419,"Title":"AWS Machine Learning University New Educator Enablement Program to Build Diverse Talent for ML/AI Jobs","Description":"AWS Machine Learning University is now providing a free educator enablement program. This program provides faculty at community colleges, minority-serving institutions (MSIs), and historically Black colleges and universities (HBCUs) with the skills and resources to teach data analytics, artificial intelligence (AI), and machine learning (ML) concepts to build a diverse pipeline for in-demand jobs of […]","PublishedAt":"2022-11-30 18:21:37+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/aws-machine-learning-university-new-educator-enablement-program-to-build-diverse-talent-for-ml-ai-jobs/","SourceName":"AWS"}},{"node":{"ID":2420,"Title":"New for Amazon Redshift – Simplify Data Ingestion and Make Your Data Warehouse More Secure and Reliable","Description":"When we talk with customers, we hear that they want to be able to harness insights from data in order to make timely, impactful, and actionable business decisions. A common pattern with data-driven organizations is that they have many diﬀerent data sources they need to ingest into their analytics systems. This requires them to build […]","PublishedAt":"2022-11-30 18:18:42+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-for-amazon-redshift-simplify-data-ingestion-and-make-your-data-warehouse-more-secure-and-reliable/","SourceName":"AWS"}},{"node":{"ID":2421,"Title":"New — Introducing Support for Real-Time and Batch Inference in Amazon SageMaker Data Wrangler","Description":"To build machine learning models, machine learning engineers need to develop a data transformation pipeline to prepare the data. The process of designing this pipeline is time-consuming and requires a cross-team collaboration between machine learning engineers, data engineers, and data scientists to implement the data preparation pipeline into a production environment. The main objective of […]","PublishedAt":"2022-11-30 18:14:14+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-introducing-support-for-real-time-and-batch-inference-in-amazon-sagemaker-data-wrangler/","SourceName":"AWS"}},{"node":{"ID":2422,"Title":"New — Amazon SageMaker Data Wrangler Supports SaaS Applications as Data Sources","Description":"Data fuels machine learning. In machine learning, data preparation is the process of transforming raw data into a format that is suitable for further processing and analysis. The common process for data preparation starts with collecting data, then cleaning it, labeling it, and finally validating and visualizing it. Getting the data right with high quality […]","PublishedAt":"2022-11-30 18:12:05+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-amazon-sagemaker-data-wrangler-supports-saas-applications-as-data-sources/","SourceName":"AWS"}},{"node":{"ID":2423,"Title":"Announcing Additional Data Connectors for Amazon AppFlow","Description":"Gathering insights from data is a more effective process if that data isn’t fragmented across multiple systems and data stores, whether on premises or in the cloud. Amazon AppFlow provides bidirectional data integration between on-premises systems and applications, SaaS applications, and AWS services. It helps customers break down data silos using a low- or no-code, […]","PublishedAt":"2022-11-30 18:09:37+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/announcing-additional-data-connectors-for-amazon-appflow/","SourceName":"AWS"}},{"node":{"ID":2424,"Title":"New ML Governance Tools for Amazon SageMaker – Simplify Access Control and Enhance Transparency Over Your ML Projects","Description":"As companies increasingly adopt machine learning (ML) for their business applications, they are looking for ways to improve governance of their ML projects with simplified access control and enhanced visibility across the ML lifecycle. A common challenge in that effort is managing the right set of user permissions across different groups and ML activities. For […]","PublishedAt":"2022-11-30 17:51:02+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-ml-governance-tools-for-amazon-sagemaker-simplify-access-control-and-enhance-transparency-over-your-ml-projects/","SourceName":"AWS"}},{"node":{"ID":2425,"Title":"Join the Preview – AWS Glue Data Quality","Description":"Back in 1980, at my second professional programming job, I was working on a project that analyzed driver’s license data from a bunch of US states. At that time data of that type was generally stored in fixed-length records, with values carefully (or not) encoded into each field. Although we were given schemas for the […]","PublishedAt":"2022-11-30 17:49:38+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/join-the-preview-aws-glue-data-quality/","SourceName":"AWS"}},{"node":{"ID":2411,"Title":"New – Trusted Language Extensions for PostgreSQL on Amazon Aurora and Amazon RDS","Description":"PostgreSQL has become the preferred open-source relational database for many enterprises and start-ups with its extensible design for developers. One of the reasons developers use PostgreSQL is it allows them to add database functionality by building extensions with their preferred programming languages. You can already install and use PostgreSQL extensions in Amazon Aurora PostgreSQL-Compatible Edition […]","PublishedAt":"2022-11-30 17:28:12+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-trusted-language-extensions-for-postgresql-on-amazon-aurora-and-amazon-rds/","SourceName":"AWS"}},{"node":{"ID":2412,"Title":"Preview: Use Amazon SageMaker to Build, Train, and Deploy ML Models Using Geospatial Data","Description":"You use map apps every day to find your favorite restaurant or travel the fastest route using geospatial data. There are two types of geospatial data: vector data that uses two-dimensional geometries such as a building location (points), roads (lines), or land boundary (polygons), and raster data such as satellite and aerial images. Last year, […]","PublishedAt":"2022-11-30 17:15:43+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/preview-use-amazon-sagemaker-to-build-train-and-deploy-ml-models-using-geospatial-data/","SourceName":"AWS"}},{"node":{"ID":2413,"Title":"New – Redesigned UI for Amazon SageMaker Studio","Description":"Today, I’m excited to announce a new, redesigned user interface (UI) for Amazon SageMaker Studio. SageMaker Studio provides a single, web-based visual interface where you can perform all machine learning (ML) development steps with a comprehensive set of ML tools. For example, you can prepare data using SageMaker Data Wrangler, build ML models with fully […]","PublishedAt":"2022-11-30 17:14:20+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-redesigned-ui-for-amazon-sagemaker-studio/","SourceName":"AWS"}},{"node":{"ID":2410,"Title":"Enabling static analysis of SQL queries at Meta","Description":"<p>UPM is our internal standalone library to perform static analysis of SQL code and enhance SQL authoring.  UPM takes SQL code as input and represents it as a data structure called a semantic tree. Infrastructure teams at Meta leverage UPM to build SQL linters, catch user mistakes in SQL code, and perform data lineage analysis [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2022/11/30/data-infrastructure/static-analysis-sql-queries/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2022/11/30/data-infrastructure/static-analysis-sql-queries/\">Enabling static analysis of SQL queries at Meta</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n","PublishedAt":"2022-11-30 17:00:10+00:00","OriginURL":"https://engineering.fb.com/2022/11/30/data-infrastructure/static-analysis-sql-queries/","SourceName":"Facebook"}},{"node":{"ID":2426,"Title":"Building LinkedIn's Skills Graph to Power a Skills-First World","Description":"Co-authors: Sofus Macskássy, Yi Pan, Ji Yan, Yanen Li, Di Zhou, Shiyong Lin As industries rapidly evolve, so do the skills necessary for success. Skill sets for jobs globally have changed by 25% since 2015 and this number is expected to double by 2027. Yet, we’ve long relied on insufficient and unequal signals when evaluating talent and predicting success - who you know, where you went to school, or who your last employer was. If we look at the labor market instead through the lens of skills - the skills you have and the skills a role or industry demands - we can create a [&#8230;]","PublishedAt":"2022-11-30 17:00:00+00:00","OriginURL":"https://engineering.linkedin.com/blog/2022/building-linkedin-s-skills-graph-to-power-a-skills-first-world","SourceName":"Linkedin"}},{"node":{"ID":2414,"Title":"Announcing Amazon DocumentDB Elastic Clusters","Description":"Amazon DocumentDB (with MongoDB compatibility) is a scalable, highly durable, and fully managed database service for operating mission-critical JSON workloads. It is one of AWS fast-growing services with customers including BBC, Dow Jones, and Samsung relying on Amazon DocumentDB to run their JSON workloads at scale. Today I am excited to announce the general availability […]","PublishedAt":"2022-11-30 16:58:50+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/announcing-amazon-documentdb-elastic-clusters/","SourceName":"AWS"}},{"node":{"ID":2415,"Title":"New — Amazon Athena for Apache Spark","Description":"When Jeff Barr first announced Amazon Athena in 2016, it changed my perspective on interacting with data. With Amazon Athena, I can interact with my data in just a few steps—starting from creating a table in Athena, loading data using connectors, and querying using the ANSI SQL standard. Over time, various industries, such as financial […]","PublishedAt":"2022-11-30 16:55:19+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-amazon-athena-for-apache-spark/","SourceName":"AWS"}},{"node":{"ID":2408,"Title":"Evernote’s Parade of Features, Part One: Find More Focus on iOS","Description":"<p>Let&#8217;s say you&#8217;re a passionate Evernote desktop or web user, but haven&#8217;t tried it on your iPhone yet. Or maybe you have it on your iPhone, but haven&#8217;t used it to its fullest. We’re here to remedy that, with a quick review of a few Evernote for iOS features that help you to focus better and get more done.&#160; (Mild disclaimer: Some features are only available with certain Evernote plans.</p>\n<p><a class=\"continue-reading\" href=\"https://evernote.com/blog/find-more-focus-on-ios/\">Continue reading...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://evernote.com/blog/find-more-focus-on-ios/\">Evernote&#8217;s Parade of Features, Part One: Find More Focus on iOS</a> appeared first on <a rel=\"nofollow\" href=\"https://evernote.com/blog\"></a>.</p>\n","PublishedAt":"2022-11-30 14:30:00+00:00","OriginURL":"https://evernote.com/blog/find-more-focus-on-ios/","SourceName":"Evernote"}},{"node":{"ID":2409,"Title":"Continuous delivery, meet continuous security","Description":"<p>Dynamic application security testing (DAST) can help catch security flaws in your code. And it can do it automatically in your build process. </p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2022/11/30/continuous-delivery-meet-continuous-security/\">Continuous delivery, meet continuous security</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2022-11-30 14:00:00+00:00","OriginURL":"https://stackoverflow.blog/2022/11/30/continuous-delivery-meet-continuous-security/","SourceName":"Stack Overflow"}},{"node":{"ID":2401,"Title":"Adjusting pricing, introducing annual plans, and accelerating innovation","Description":"After not raising prices in our history, this was something we thought carefully about before deciding to do. While we have over a decade of network expansion and innovation under our belts, what may not be intuitive is that our goal is not to increase revenue from this change.","PublishedAt":"2022-11-30 01:04:42+00:00","OriginURL":"https://blog.cloudflare.com/adjusting-pricing-introducing-annual-plans-and-accelerating-innovation/","SourceName":"Cloudflare"}}]}},"pageContext":{"limit":30,"skip":3330,"numPages":193,"currentPage":112}},"staticQueryHashes":["3649515864"]}